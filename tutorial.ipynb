{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import pandas as pd\n",
    "\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert import Indexer, Searcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26882/17807022.py:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_models = pd.read_csv(pth_models, sep=\";\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>average_price</th>\n",
       "      <th>name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>comment</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>920-005619</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>Logitech 920-005619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>721952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zipper Bag</td>\n",
       "      <td>Hama</td>\n",
       "      <td>Hama Zipper Bag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>721970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC-3064</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>Nokia CC-3064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751488</td>\n",
       "      <td>990.0</td>\n",
       "      <td>CKS-X7/R</td>\n",
       "      <td>Sony</td>\n",
       "      <td>Sony CKS-X7/R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>751989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EP-031023</td>\n",
       "      <td>Era Pro</td>\n",
       "      <td>Era Pro EP-031023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103209</th>\n",
       "      <td>7049424</td>\n",
       "      <td>16459.0</td>\n",
       "      <td>MD-108</td>\n",
       "      <td>Mivo</td>\n",
       "      <td>Mivo MD-108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103210</th>\n",
       "      <td>7049425</td>\n",
       "      <td>8812.0</td>\n",
       "      <td>MD-165</td>\n",
       "      <td>Mivo</td>\n",
       "      <td>Mivo MD-165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103211</th>\n",
       "      <td>7049426</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>Boost 20W</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Rocket Boost 20W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103212</th>\n",
       "      <td>7049427</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>Motion 10W</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Rocket Motion 10W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103213</th>\n",
       "      <td>7049428</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>Z1</td>\n",
       "      <td>SmartBuy</td>\n",
       "      <td>SmartBuy Z1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103214 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_id  average_price        name brand_name            full_name  \\\n",
       "0         623742            NaN  920-005619   Logitech  Logitech 920-005619   \n",
       "1         721952            NaN  Zipper Bag       Hama      Hama Zipper Bag   \n",
       "2         721970            NaN     CC-3064      Nokia        Nokia CC-3064   \n",
       "3         751488          990.0    CKS-X7/R       Sony        Sony CKS-X7/R   \n",
       "4         751989            NaN   EP-031023    Era Pro    Era Pro EP-031023   \n",
       "...          ...            ...         ...        ...                  ...   \n",
       "103209   7049424        16459.0      MD-108       Mivo          Mivo MD-108   \n",
       "103210   7049425         8812.0      MD-165       Mivo          Mivo MD-165   \n",
       "103211   7049426         4240.0   Boost 20W     Rocket     Rocket Boost 20W   \n",
       "103212   7049427         2990.0  Motion 10W     Rocket    Rocket Motion 10W   \n",
       "103213   7049428         8900.0          Z1   SmartBuy          SmartBuy Z1   \n",
       "\n",
       "       comment                                      category_name  category_id  \n",
       "0          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "1          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "2          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "3          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "4          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "...        ...                                                ...          ...  \n",
       "103209     NaN                               портативная акустика         3904  \n",
       "103210     NaN                               портативная акустика         3904  \n",
       "103211     NaN                               портативная акустика         3904  \n",
       "103212     NaN                               портативная акустика         3904  \n",
       "103213     NaN                               портативная акустика         3904  \n",
       "\n",
       "[103214 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth_models = \"/home/sondors/Documents/price/ColBERT_data/18_categories/test/models_18_categories.csv\"\n",
    "df_models = pd.read_csv(pth_models, sep=\";\")\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tsv(df, pth, category_id):\n",
    "    \"\"\"\n",
    "    Делим модели по full_name и соответствующие им model_id на два tsv файла \n",
    "\n",
    "    {category_id}_models.tsv:\n",
    "\n",
    "    0   model0\n",
    "    1   model1\n",
    "    2   model2\n",
    "\n",
    "    {category_id}_models_id.tsv:\n",
    "\n",
    "    0   model_id0\n",
    "    1   model_id1\n",
    "    2   model_id2\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def df_split(df):\n",
    "        df1 = pd.DataFrame()\n",
    "        df1[\"id\"], df1[\"full_name\"] = [i for i in range(len(df))], df[\"full_name\"]\n",
    "        \n",
    "        df2 = pd.DataFrame()\n",
    "        df2[\"id\"], df2[\"model_id\"] = [i for i in range(len(df))], df[\"model_id\"]\n",
    "\n",
    "        return df1, df2\n",
    "    \n",
    "    models, models_id = df_split(df)\n",
    "    models.to_csv(os.path.join(pth,f\"{category_id}_models.tsv\"), sep='\\t', header=False, index=False)\n",
    "    models_id.to_csv(os.path.join(pth,f\"{category_id}_models_id.tsv\"), sep='\\t', header=False, index=False)\n",
    "\n",
    "categories = [\n",
    "    \"диктофоны, портативные рекордеры\",\n",
    "    \"электронные книги\",\n",
    "    \"автомобильные телевизоры, мониторы\",\n",
    "    \"смарт-часы и браслеты\",\n",
    "    \"портативные медиаплееры\",\n",
    "    # \"чехлы, обложки для гаджетов (телефонов, планшетов etc)\",\n",
    "    \"портативная акустика\",\n",
    "    \"мобильные телефоны\",\n",
    "    \"VR-гарнитуры (VR-очки, шлемы, очки виртуальной реальности, FPV очки для квадрокоптеров)\",\n",
    "    \"планшетные компьютеры и мини-планшеты\",\n",
    "    \"наушники, гарнитуры, наушники c микрофоном\",\n",
    "    \"радиоприемники, радиобудильники, радиочасы\",\n",
    "    \"магнитолы\",\n",
    "    \"GPS-навигаторы\"\n",
    "    ]\n",
    "\n",
    "categories_id = [\n",
    "    3902,\n",
    "    510402,\n",
    "    4302,\n",
    "    2815,\n",
    "    3901,\n",
    "    # 3994,\n",
    "    3904,\n",
    "    2801,\n",
    "    3908,\n",
    "    510401,\n",
    "    2102,\n",
    "    3903,\n",
    "    3907,\n",
    "    280801\n",
    "    ]\n",
    "\n",
    "dst_fld = \"/home/sondors/Documents/price/ColBERT/tmp_tutorial\"\n",
    "for cat_id in categories_id:\n",
    "    category_models = df_models[df_models.category_id == cat_id].reset_index(drop=True)\n",
    "    prepare_tsv(category_models, dst_fld, cat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Индексируем модели и сохраняем индекс на диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:49:23] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 06, 17:49:23] #> Note: Output directory /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3902_2bits already exists\n",
      "\n",
      "\n",
      "[Feb 06, 17:49:23] #> Will delete 10 files already at /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3902_2bits in 20 seconds...\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 2998,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 768,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/bert-base-multilingual-cased_dim_768_bsize_230_lr04_use_ib_negatives\\/none\\/2024-01\\/27\\/16.55.29\\/checkpoints\\/colbert-2998-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tmp_tutorial\\/3902_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_3902_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"tutorial\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/06\\/17.49.21\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 06, 17:49:45] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:49:46] [0] \t\t # of sampled PIDs = 488 \t sampled_pids[:3] = [213, 375, 5]\n",
      "[Feb 06, 17:49:46] [0] \t\t #> Encoding 488 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n",
      "WARNING clustering 4691 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:49:50] [0] \t\t avg_doclen_est = 10.116803169250488 \t len(local_sample) = 488\n",
      "[Feb 06, 17:49:50] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 06, 17:49:50] [0] \t\t *Estimated* 4,936 embeddings.\n",
      "[Feb 06, 17:49:50] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3902_2bits/plan.json ..\n",
      "Clustering 4691 points in 768D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.07 s, search 0.06 s): objective=392.74 imbalance=1.505 nsplit=0        \n",
      "[0.009, 0.008, 0.01, 0.007, 0.011, 0.008, 0.01, 0.01, 0.009, 0.009, 0.008, 0.009, 0.008, 0.007, 0.008, 0.008, 0.01, 0.008, 0.01, 0.008, 0.009, 0.01, 0.009, 0.009, 0.008, 0.011, 0.008, 0.008, 0.007, 0.009, 0.01, 0.01, 0.008, 0.009, 0.009, 0.009, 0.008, 0.008, 0.009, 0.007, 0.011, 0.009, 0.009, 0.01, 0.01, 0.009, 0.008, 0.008, 0.007, 0.007, 0.009, 0.007, 0.009, 0.008, 0.008, 0.008, 0.008, 0.01, 0.009, 0.007, 0.009, 0.007, 0.009, 0.01, 0.008, 0.008, 0.008, 0.01, 0.007, 0.008, 0.009, 0.009, 0.008, 0.007, 0.008, 0.01, 0.009, 0.009, 0.008, 0.008, 0.008, 0.009, 0.009, 0.007, 0.008, 0.008, 0.007, 0.008, 0.01, 0.009, 0.009, 0.008, 0.008, 0.007, 0.009, 0.01, 0.007, 0.009, 0.009, 0.008, 0.008, 0.008, 0.01, 0.009, 0.008, 0.009, 0.008, 0.008, 0.009, 0.008, 0.008, 0.008, 0.007, 0.009, 0.009, 0.009, 0.008, 0.01, 0.009, 0.008, 0.009, 0.009, 0.008, 0.008, 0.009, 0.009, 0.009, 0.009, 0.008, 0.009, 0.008, 0.009, 0.008, 0.009, 0.009, 0.01, 0.01, 0.009, 0.008, 0.008, 0.009, 0.01, 0.008, 0.007, 0.01, 0.009, 0.009, 0.008, 0.008, 0.008, 0.009, 0.01, 0.008, 0.008, 0.01, 0.008, 0.008, 0.009, 0.008, 0.008, 0.01, 0.009, 0.009, 0.011, 0.009, 0.009, 0.009, 0.009, 0.007, 0.011, 0.008, 0.008, 0.009, 0.009, 0.008, 0.008, 0.01, 0.009, 0.009, 0.01, 0.009, 0.008, 0.008, 0.008, 0.009, 0.009, 0.009, 0.009, 0.008, 0.009, 0.008, 0.008, 0.009, 0.008, 0.008, 0.009, 0.007, 0.009, 0.01, 0.009, 0.009, 0.009, 0.009, 0.008, 0.01, 0.008, 0.008, 0.008, 0.009, 0.007, 0.008, 0.01, 0.006, 0.01, 0.008, 0.007, 0.009, 0.009, 0.008, 0.008, 0.008, 0.009, 0.008, 0.009, 0.009, 0.009, 0.008, 0.009, 0.007, 0.009, 0.008, 0.009, 0.009, 0.008, 0.009, 0.009, 0.009, 0.011, 0.008, 0.009, 0.008, 0.007, 0.011, 0.009, 0.009, 0.009, 0.009, 0.009, 0.007, 0.008, 0.009, 0.008, 0.01, 0.009, 0.009, 0.009, 0.009, 0.009, 0.01, 0.007, 0.009, 0.008, 0.008, 0.009, 0.006, 0.009, 0.007, 0.009, 0.008, 0.009, 0.009, 0.008, 0.009, 0.008, 0.01, 0.009, 0.009, 0.008, 0.01, 0.01, 0.008, 0.008, 0.008, 0.009, 0.008, 0.009, 0.009, 0.008, 0.007, 0.008, 0.009, 0.01, 0.008, 0.009, 0.008, 0.008, 0.009, 0.009, 0.008, 0.009, 0.009, 0.01, 0.008, 0.01, 0.01, 0.008, 0.011, 0.008, 0.01, 0.008, 0.008, 0.009, 0.009, 0.008, 0.01, 0.01, 0.008, 0.01, 0.007, 0.008, 0.009, 0.008, 0.009, 0.009, 0.009, 0.009, 0.009, 0.009, 0.008, 0.007, 0.009, 0.007, 0.009, 0.009, 0.008, 0.008, 0.01, 0.009, 0.009, 0.008, 0.009, 0.009, 0.007, 0.007, 0.01, 0.008, 0.008, 0.007, 0.01, 0.008, 0.008, 0.008, 0.009, 0.007, 0.008, 0.009, 0.008, 0.009, 0.008, 0.009, 0.008, 0.009, 0.008, 0.009, 0.009, 0.009, 0.008, 0.011, 0.008, 0.008, 0.009, 0.009, 0.009, 0.009, 0.007, 0.009, 0.008, 0.007, 0.009, 0.009, 0.01, 0.009, 0.012, 0.008, 0.01, 0.009, 0.01, 0.008, 0.008, 0.009, 0.008, 0.009, 0.008, 0.008, 0.011, 0.008, 0.009, 0.01, 0.007, 0.01, 0.007, 0.011, 0.008, 0.008, 0.008, 0.009, 0.007, 0.008, 0.009, 0.009, 0.009, 0.009, 0.007, 0.01, 0.01, 0.007, 0.012, 0.008, 0.008, 0.01, 0.008, 0.009, 0.01, 0.011, 0.009, 0.008, 0.009, 0.009, 0.008, 0.008, 0.008, 0.01, 0.008, 0.006, 0.008, 0.009, 0.008, 0.009, 0.009, 0.008, 0.01, 0.008, 0.01, 0.008, 0.008, 0.007, 0.009, 0.008, 0.009, 0.009, 0.008, 0.008, 0.009, 0.008, 0.008, 0.008, 0.008, 0.008, 0.009, 0.009, 0.009, 0.007, 0.01, 0.008, 0.01, 0.008, 0.008, 0.008, 0.008, 0.008, 0.009, 0.008, 0.009, 0.009, 0.01, 0.009, 0.009, 0.008, 0.008, 0.007, 0.008, 0.007, 0.008, 0.007, 0.008, 0.009, 0.008, 0.008, 0.008, 0.008, 0.01, 0.008, 0.008, 0.009, 0.009, 0.009, 0.009, 0.011, 0.01, 0.009, 0.008, 0.01, 0.008, 0.007, 0.009, 0.009, 0.009, 0.009, 0.007, 0.008, 0.008, 0.009, 0.009, 0.008, 0.009, 0.008, 0.008, 0.008, 0.008, 0.009, 0.01, 0.01, 0.007, 0.009, 0.008, 0.009, 0.008, 0.008, 0.011, 0.009, 0.009, 0.009, 0.01, 0.009, 0.009, 0.009, 0.008, 0.009, 0.009, 0.008, 0.009, 0.009, 0.009, 0.009, 0.011, 0.008, 0.008, 0.008, 0.009, 0.008, 0.007, 0.009, 0.008, 0.009, 0.01, 0.009, 0.009, 0.009, 0.007, 0.008, 0.01, 0.009, 0.008, 0.01, 0.01, 0.007, 0.009, 0.01, 0.007, 0.008, 0.009, 0.01, 0.008, 0.008, 0.008, 0.008, 0.009, 0.01, 0.009, 0.009, 0.007, 0.009, 0.008, 0.01, 0.009, 0.009, 0.009, 0.009, 0.009, 0.008, 0.009, 0.009, 0.008, 0.009, 0.009, 0.007, 0.008, 0.007, 0.009, 0.009, 0.007, 0.009, 0.009, 0.01, 0.009, 0.007, 0.008, 0.009, 0.009, 0.008, 0.009, 0.008, 0.01, 0.009, 0.009, 0.009, 0.008, 0.009, 0.008, 0.008, 0.008, 0.007, 0.009, 0.009, 0.009, 0.01, 0.009, 0.009, 0.008, 0.008, 0.008, 0.009, 0.007, 0.009, 0.008, 0.009, 0.009, 0.008, 0.011, 0.007, 0.01, 0.009, 0.007, 0.009, 0.008, 0.01, 0.008, 0.009, 0.01, 0.008, 0.009, 0.007, 0.009, 0.009, 0.008, 0.007, 0.008, 0.009, 0.008, 0.008, 0.008, 0.01, 0.009, 0.009, 0.009, 0.008, 0.008, 0.008, 0.008, 0.007, 0.008, 0.01, 0.009, 0.008, 0.009, 0.008, 0.009, 0.008, 0.009, 0.009, 0.008, 0.008, 0.008, 0.01, 0.008, 0.007, 0.008, 0.007, 0.01, 0.01, 0.008, 0.009, 0.008, 0.007, 0.008, 0.008, 0.009, 0.009, 0.01, 0.008, 0.009, 0.01, 0.01, 0.009, 0.009, 0.009, 0.009, 0.01, 0.007, 0.008, 0.008, 0.009, 0.008, 0.009, 0.009, 0.007, 0.008, 0.008, 0.009, 0.009, 0.009, 0.008, 0.008, 0.009, 0.01, 0.007, 0.008, 0.008, 0.008, 0.01, 0.008, 0.009, 0.009, 0.009, 0.009, 0.008, 0.01, 0.01, 0.008, 0.009, 0.008, 0.008, 0.009, 0.007, 0.009, 0.008, 0.009, 0.008, 0.008, 0.008, 0.01, 0.009, 0.008, 0.009, 0.01, 0.008, 0.009, 0.008, 0.008, 0.007, 0.009, 0.009, 0.008, 0.008, 0.009, 0.009, 0.008, 0.008]\n",
      "[Feb 06, 17:49:50] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 06, 17:49:50] #> Got bucket_cutoffs = tensor([-5.3006e-03, -2.9246e-05,  5.1356e-03]) and bucket_weights = tensor([-0.0118, -0.0021,  0.0020,  0.0116])\n",
      "[Feb 06, 17:49:50] avg_residual = 0.008613561280071735\n",
      "[Feb 06, 17:49:50] [0] \t\t #> Encoding 488 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▎        | 1/8 [00:00<00:02,  2.34it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:00<00:02,  2.37it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  2.39it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:01<00:01,  2.38it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  2.20it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:02<00:00,  2.13it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:03<00:00,  2.09it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\u001b[A\n",
      "1it [00:03,  3.56s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2513.06it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 156157.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:49:53] [0] \t\t #> Saving chunk 0: \t 488 passages and 4,937 embeddings. From #0 onward.\n",
      "[Feb 06, 17:49:53] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 06, 17:49:53] [0] \t\t Found all files!\n",
      "[Feb 06, 17:49:53] [0] \t\t #> Building IVF...\n",
      "[Feb 06, 17:49:53] [0] \t\t #> Loading codes...\n",
      "[Feb 06, 17:49:53] [0] \t\t Sorting codes...\n",
      "[Feb 06, 17:49:53] [0] \t\t Getting unique codes...\n",
      "[Feb 06, 17:49:53] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 06, 17:49:53] #> Building the emb2pid mapping..\n",
      "[Feb 06, 17:49:53] len(emb2pid) = 4937\n",
      "[Feb 06, 17:49:53] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3902_2bits/ivf.pid.pt\n",
      "[Feb 06, 17:49:53] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3902_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 06, 17:49:54] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 06, 17:49:54] #> Note: Output directory /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_510402_2bits already exists\n",
      "\n",
      "\n",
      "[Feb 06, 17:49:54] #> Will delete 10 files already at /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_510402_2bits in 20 seconds...\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 2998,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 768,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/bert-base-multilingual-cased_dim_768_bsize_230_lr04_use_ib_negatives\\/none\\/2024-01\\/27\\/16.55.29\\/checkpoints\\/colbert-2998-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tmp_tutorial\\/510402_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_510402_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"tutorial\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/06\\/17.49.21\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 06, 17:50:16] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:50:17] [0] \t\t # of sampled PIDs = 680 \t sampled_pids[:3] = [426, 10, 305]\n",
      "[Feb 06, 17:50:17] [0] \t\t #> Encoding 680 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:05<00:00,  1.90it/s]\n",
      "WARNING clustering 6031 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:50:23] [0] \t\t avg_doclen_est = 9.335293769836426 \t len(local_sample) = 680\n",
      "[Feb 06, 17:50:23] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 06, 17:50:23] [0] \t\t *Estimated* 6,347 embeddings.\n",
      "[Feb 06, 17:50:23] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_510402_2bits/plan.json ..\n",
      "Clustering 6031 points in 768D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.08 s, search 0.08 s): objective=767.196 imbalance=1.570 nsplit=0       \n",
      "[0.012, 0.011, 0.012, 0.011, 0.014, 0.011, 0.012, 0.012, 0.012, 0.014, 0.01, 0.011, 0.01, 0.01, 0.011, 0.011, 0.011, 0.011, 0.011, 0.012, 0.01, 0.012, 0.01, 0.012, 0.011, 0.011, 0.011, 0.01, 0.01, 0.012, 0.011, 0.013, 0.012, 0.01, 0.011, 0.009, 0.01, 0.011, 0.01, 0.01, 0.013, 0.011, 0.011, 0.009, 0.012, 0.01, 0.011, 0.01, 0.009, 0.01, 0.011, 0.01, 0.011, 0.011, 0.012, 0.01, 0.012, 0.013, 0.01, 0.01, 0.012, 0.009, 0.01, 0.013, 0.012, 0.011, 0.011, 0.012, 0.01, 0.01, 0.012, 0.011, 0.01, 0.011, 0.009, 0.011, 0.012, 0.012, 0.01, 0.01, 0.01, 0.012, 0.012, 0.011, 0.011, 0.011, 0.01, 0.01, 0.013, 0.01, 0.012, 0.01, 0.01, 0.01, 0.01, 0.012, 0.01, 0.011, 0.011, 0.011, 0.01, 0.012, 0.012, 0.01, 0.011, 0.011, 0.01, 0.01, 0.012, 0.01, 0.01, 0.01, 0.01, 0.011, 0.011, 0.011, 0.01, 0.012, 0.01, 0.01, 0.012, 0.009, 0.011, 0.011, 0.014, 0.012, 0.012, 0.01, 0.01, 0.011, 0.011, 0.01, 0.01, 0.011, 0.011, 0.011, 0.012, 0.01, 0.011, 0.011, 0.012, 0.011, 0.01, 0.01, 0.011, 0.01, 0.011, 0.01, 0.011, 0.01, 0.012, 0.011, 0.011, 0.01, 0.012, 0.01, 0.01, 0.011, 0.01, 0.011, 0.012, 0.011, 0.011, 0.012, 0.011, 0.01, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.013, 0.011, 0.009, 0.011, 0.011, 0.012, 0.011, 0.012, 0.011, 0.011, 0.011, 0.011, 0.012, 0.011, 0.011, 0.012, 0.01, 0.011, 0.01, 0.01, 0.012, 0.01, 0.011, 0.012, 0.01, 0.01, 0.011, 0.009, 0.011, 0.012, 0.011, 0.011, 0.013, 0.01, 0.01, 0.01, 0.009, 0.009, 0.009, 0.012, 0.009, 0.009, 0.012, 0.009, 0.01, 0.011, 0.011, 0.01, 0.01, 0.01, 0.012, 0.012, 0.012, 0.012, 0.012, 0.011, 0.01, 0.01, 0.011, 0.011, 0.012, 0.011, 0.011, 0.011, 0.01, 0.014, 0.01, 0.01, 0.011, 0.01, 0.012, 0.011, 0.01, 0.013, 0.012, 0.012, 0.009, 0.01, 0.01, 0.01, 0.012, 0.011, 0.012, 0.012, 0.012, 0.011, 0.013, 0.01, 0.011, 0.01, 0.01, 0.01, 0.01, 0.009, 0.01, 0.011, 0.011, 0.012, 0.012, 0.01, 0.01, 0.009, 0.012, 0.011, 0.01, 0.01, 0.012, 0.013, 0.012, 0.011, 0.012, 0.012, 0.01, 0.013, 0.01, 0.012, 0.011, 0.01, 0.011, 0.011, 0.01, 0.013, 0.011, 0.011, 0.011, 0.011, 0.01, 0.012, 0.01, 0.012, 0.01, 0.012, 0.01, 0.01, 0.012, 0.012, 0.01, 0.01, 0.011, 0.01, 0.012, 0.01, 0.011, 0.012, 0.009, 0.012, 0.01, 0.011, 0.01, 0.011, 0.01, 0.011, 0.012, 0.009, 0.011, 0.011, 0.01, 0.009, 0.011, 0.01, 0.01, 0.012, 0.009, 0.011, 0.012, 0.01, 0.013, 0.01, 0.01, 0.011, 0.009, 0.01, 0.01, 0.009, 0.009, 0.01, 0.011, 0.01, 0.01, 0.01, 0.011, 0.009, 0.01, 0.01, 0.011, 0.011, 0.01, 0.013, 0.01, 0.013, 0.01, 0.01, 0.012, 0.011, 0.01, 0.012, 0.01, 0.011, 0.011, 0.011, 0.011, 0.01, 0.01, 0.012, 0.011, 0.011, 0.011, 0.012, 0.011, 0.011, 0.013, 0.012, 0.012, 0.011, 0.012, 0.009, 0.01, 0.011, 0.011, 0.01, 0.01, 0.011, 0.012, 0.01, 0.011, 0.012, 0.01, 0.011, 0.011, 0.012, 0.011, 0.01, 0.011, 0.011, 0.01, 0.01, 0.011, 0.011, 0.012, 0.011, 0.01, 0.011, 0.011, 0.011, 0.013, 0.012, 0.011, 0.011, 0.01, 0.012, 0.011, 0.014, 0.011, 0.011, 0.011, 0.011, 0.011, 0.012, 0.011, 0.01, 0.011, 0.009, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.012, 0.01, 0.012, 0.009, 0.01, 0.011, 0.013, 0.009, 0.012, 0.011, 0.01, 0.01, 0.011, 0.011, 0.01, 0.011, 0.01, 0.01, 0.011, 0.012, 0.012, 0.01, 0.013, 0.01, 0.011, 0.011, 0.011, 0.009, 0.01, 0.011, 0.011, 0.011, 0.01, 0.012, 0.012, 0.011, 0.011, 0.01, 0.01, 0.011, 0.011, 0.01, 0.011, 0.01, 0.009, 0.012, 0.01, 0.009, 0.01, 0.011, 0.011, 0.01, 0.01, 0.012, 0.01, 0.01, 0.01, 0.013, 0.012, 0.011, 0.011, 0.012, 0.01, 0.009, 0.011, 0.01, 0.012, 0.013, 0.009, 0.011, 0.01, 0.011, 0.011, 0.01, 0.01, 0.012, 0.011, 0.011, 0.011, 0.012, 0.012, 0.011, 0.011, 0.011, 0.011, 0.009, 0.009, 0.01, 0.011, 0.012, 0.011, 0.012, 0.012, 0.01, 0.013, 0.011, 0.011, 0.011, 0.01, 0.01, 0.011, 0.011, 0.011, 0.011, 0.013, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.013, 0.01, 0.011, 0.013, 0.011, 0.011, 0.012, 0.01, 0.011, 0.012, 0.011, 0.008, 0.011, 0.012, 0.01, 0.011, 0.011, 0.011, 0.01, 0.01, 0.013, 0.01, 0.01, 0.01, 0.01, 0.011, 0.011, 0.01, 0.014, 0.01, 0.01, 0.01, 0.011, 0.011, 0.011, 0.01, 0.01, 0.012, 0.011, 0.012, 0.011, 0.009, 0.012, 0.01, 0.009, 0.012, 0.009, 0.01, 0.012, 0.009, 0.011, 0.011, 0.011, 0.01, 0.01, 0.011, 0.011, 0.012, 0.011, 0.01, 0.012, 0.011, 0.012, 0.011, 0.01, 0.01, 0.012, 0.011, 0.011, 0.009, 0.009, 0.01, 0.012, 0.012, 0.01, 0.012, 0.01, 0.011, 0.011, 0.01, 0.01, 0.01, 0.012, 0.01, 0.011, 0.011, 0.012, 0.012, 0.011, 0.012, 0.011, 0.01, 0.012, 0.01, 0.013, 0.01, 0.011, 0.012, 0.01, 0.01, 0.012, 0.012, 0.01, 0.01, 0.011, 0.009, 0.011, 0.011, 0.01, 0.011, 0.011, 0.011, 0.01, 0.009, 0.012, 0.01, 0.01, 0.01, 0.01, 0.01, 0.013, 0.01, 0.012, 0.01, 0.01, 0.013, 0.01, 0.01, 0.012, 0.01, 0.011, 0.01, 0.011, 0.012, 0.009, 0.01, 0.011, 0.012, 0.012, 0.011, 0.01, 0.011, 0.011, 0.011, 0.01, 0.01, 0.01, 0.012, 0.012, 0.01, 0.011, 0.011, 0.011, 0.01, 0.011, 0.012, 0.012, 0.01, 0.011, 0.01, 0.012, 0.009, 0.01, 0.012, 0.01, 0.01, 0.012, 0.011, 0.01, 0.012, 0.01, 0.011, 0.012, 0.011, 0.009, 0.011, 0.01, 0.01, 0.012, 0.011, 0.012, 0.013, 0.012, 0.01, 0.01, 0.012, 0.014, 0.011, 0.011, 0.012, 0.009, 0.011, 0.01, 0.011, 0.011, 0.012, 0.01, 0.01, 0.01, 0.013, 0.011, 0.011, 0.011, 0.013, 0.01, 0.012, 0.01, 0.012, 0.01, 0.012, 0.011, 0.012, 0.01, 0.01, 0.01, 0.01, 0.012]\n",
      "[Feb 06, 17:50:23] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 06, 17:50:23] #> Got bucket_cutoffs = tensor([-7.3699e-03,  3.0249e-05,  7.3755e-03]) and bucket_weights = tensor([-0.0153, -0.0029,  0.0029,  0.0153])\n",
      "[Feb 06, 17:50:23] avg_residual = 0.010851368308067322\n",
      "[Feb 06, 17:50:23] [0] \t\t #> Encoding 680 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 1/11 [00:00<00:05,  1.87it/s]\u001b[A\n",
      " 18%|█▊        | 2/11 [00:01<00:04,  1.91it/s]\u001b[A\n",
      " 27%|██▋       | 3/11 [00:01<00:04,  1.92it/s]\u001b[A\n",
      " 36%|███▋      | 4/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 45%|████▌     | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|█████▍    | 6/11 [00:03<00:02,  1.92it/s]\u001b[A\n",
      " 64%|██████▎   | 7/11 [00:03<00:02,  1.92it/s]\u001b[A\n",
      " 73%|███████▎  | 8/11 [00:04<00:01,  1.91it/s]\u001b[A\n",
      " 82%|████████▏ | 9/11 [00:04<00:01,  1.90it/s]\u001b[A\n",
      " 91%|█████████ | 10/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "100%|██████████| 11/11 [00:05<00:00,  1.97it/s]\u001b[A\n",
      "1it [00:05,  5.66s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2542.00it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 164880.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:50:28] [0] \t\t #> Saving chunk 0: \t 680 passages and 6,348 embeddings. From #0 onward.\n",
      "[Feb 06, 17:50:28] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 06, 17:50:28] [0] \t\t Found all files!\n",
      "[Feb 06, 17:50:28] [0] \t\t #> Building IVF...\n",
      "[Feb 06, 17:50:28] [0] \t\t #> Loading codes...\n",
      "[Feb 06, 17:50:28] [0] \t\t Sorting codes...\n",
      "[Feb 06, 17:50:28] [0] \t\t Getting unique codes...\n",
      "[Feb 06, 17:50:28] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 06, 17:50:28] #> Building the emb2pid mapping..\n",
      "[Feb 06, 17:50:28] len(emb2pid) = 6348\n",
      "[Feb 06, 17:50:28] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_510402_2bits/ivf.pid.pt\n",
      "[Feb 06, 17:50:28] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_510402_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 06, 17:50:29] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 06, 17:50:29] #> Note: Output directory /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_4302_2bits already exists\n",
      "\n",
      "\n",
      "[Feb 06, 17:50:29] #> Will delete 10 files already at /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_4302_2bits in 20 seconds...\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 2998,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 768,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/bert-base-multilingual-cased_dim_768_bsize_230_lr04_use_ib_negatives\\/none\\/2024-01\\/27\\/16.55.29\\/checkpoints\\/colbert-2998-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tmp_tutorial\\/4302_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_4302_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"tutorial\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/06\\/17.49.21\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 06, 17:50:52] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:50:53] [0] \t\t # of sampled PIDs = 790 \t sampled_pids[:3] = [426, 750, 10]\n",
      "[Feb 06, 17:50:53] [0] \t\t #> Encoding 790 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:06<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:50:59] [0] \t\t avg_doclen_est = 9.383543968200684 \t len(local_sample) = 790\n",
      "[Feb 06, 17:51:00] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 06, 17:51:00] [0] \t\t *Estimated* 7,412 embeddings.\n",
      "[Feb 06, 17:51:00] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_4302_2bits/plan.json ..\n",
      "Clustering 7043 points in 768D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.10 s, search 0.09 s): objective=962.952 imbalance=1.495 nsplit=0       \n",
      "[0.013, 0.012, 0.013, 0.01, 0.016, 0.01, 0.012, 0.012, 0.012, 0.012, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.011, 0.011, 0.011, 0.012, 0.012, 0.014, 0.011, 0.012, 0.013, 0.013, 0.011, 0.011, 0.011, 0.012, 0.012, 0.013, 0.012, 0.012, 0.011, 0.012, 0.01, 0.011, 0.01, 0.01, 0.013, 0.012, 0.011, 0.011, 0.013, 0.011, 0.012, 0.011, 0.011, 0.011, 0.012, 0.01, 0.013, 0.012, 0.011, 0.012, 0.011, 0.014, 0.01, 0.01, 0.012, 0.01, 0.011, 0.013, 0.011, 0.012, 0.011, 0.013, 0.011, 0.012, 0.012, 0.012, 0.011, 0.011, 0.01, 0.012, 0.013, 0.012, 0.012, 0.011, 0.011, 0.013, 0.011, 0.011, 0.011, 0.011, 0.01, 0.011, 0.014, 0.011, 0.011, 0.012, 0.01, 0.011, 0.011, 0.012, 0.011, 0.011, 0.011, 0.012, 0.011, 0.011, 0.015, 0.01, 0.012, 0.012, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.01, 0.011, 0.01, 0.012, 0.011, 0.012, 0.01, 0.012, 0.013, 0.01, 0.01, 0.011, 0.013, 0.013, 0.011, 0.013, 0.01, 0.012, 0.011, 0.011, 0.01, 0.012, 0.011, 0.012, 0.013, 0.012, 0.011, 0.011, 0.012, 0.011, 0.011, 0.009, 0.012, 0.012, 0.011, 0.011, 0.012, 0.011, 0.012, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.013, 0.012, 0.01, 0.012, 0.011, 0.011, 0.011, 0.011, 0.01, 0.012, 0.011, 0.01, 0.013, 0.01, 0.01, 0.012, 0.012, 0.012, 0.011, 0.012, 0.013, 0.012, 0.011, 0.012, 0.013, 0.012, 0.011, 0.012, 0.011, 0.012, 0.009, 0.011, 0.011, 0.011, 0.011, 0.014, 0.01, 0.011, 0.011, 0.011, 0.011, 0.012, 0.012, 0.012, 0.013, 0.012, 0.011, 0.011, 0.01, 0.011, 0.011, 0.012, 0.009, 0.011, 0.01, 0.009, 0.01, 0.011, 0.009, 0.011, 0.01, 0.012, 0.012, 0.013, 0.011, 0.013, 0.013, 0.012, 0.011, 0.011, 0.012, 0.012, 0.013, 0.011, 0.012, 0.012, 0.011, 0.015, 0.01, 0.011, 0.011, 0.01, 0.012, 0.01, 0.012, 0.012, 0.013, 0.013, 0.011, 0.011, 0.011, 0.011, 0.012, 0.011, 0.011, 0.011, 0.012, 0.011, 0.014, 0.01, 0.012, 0.011, 0.011, 0.012, 0.01, 0.01, 0.01, 0.011, 0.011, 0.013, 0.012, 0.01, 0.011, 0.01, 0.012, 0.01, 0.011, 0.01, 0.012, 0.012, 0.012, 0.011, 0.012, 0.012, 0.009, 0.013, 0.012, 0.011, 0.009, 0.01, 0.011, 0.013, 0.011, 0.011, 0.011, 0.012, 0.011, 0.011, 0.011, 0.012, 0.011, 0.012, 0.012, 0.013, 0.012, 0.011, 0.012, 0.011, 0.01, 0.01, 0.011, 0.012, 0.014, 0.01, 0.011, 0.013, 0.01, 0.013, 0.01, 0.011, 0.011, 0.01, 0.011, 0.013, 0.011, 0.01, 0.012, 0.011, 0.012, 0.009, 0.011, 0.01, 0.012, 0.012, 0.012, 0.012, 0.012, 0.011, 0.012, 0.011, 0.013, 0.01, 0.01, 0.01, 0.011, 0.01, 0.01, 0.01, 0.012, 0.01, 0.01, 0.011, 0.01, 0.01, 0.011, 0.011, 0.012, 0.012, 0.011, 0.011, 0.011, 0.011, 0.01, 0.011, 0.012, 0.012, 0.012, 0.012, 0.011, 0.011, 0.011, 0.012, 0.012, 0.011, 0.011, 0.012, 0.012, 0.012, 0.011, 0.01, 0.012, 0.013, 0.013, 0.012, 0.014, 0.011, 0.012, 0.01, 0.01, 0.011, 0.01, 0.011, 0.01, 0.012, 0.012, 0.01, 0.012, 0.014, 0.01, 0.012, 0.011, 0.013, 0.011, 0.011, 0.012, 0.01, 0.011, 0.011, 0.012, 0.012, 0.013, 0.01, 0.011, 0.012, 0.012, 0.01, 0.015, 0.011, 0.012, 0.012, 0.01, 0.011, 0.012, 0.014, 0.011, 0.012, 0.011, 0.011, 0.012, 0.012, 0.012, 0.012, 0.011, 0.009, 0.011, 0.011, 0.011, 0.01, 0.01, 0.01, 0.013, 0.011, 0.012, 0.01, 0.01, 0.011, 0.013, 0.01, 0.012, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.011, 0.011, 0.009, 0.011, 0.011, 0.012, 0.011, 0.013, 0.011, 0.012, 0.011, 0.012, 0.01, 0.011, 0.012, 0.012, 0.012, 0.011, 0.012, 0.012, 0.011, 0.012, 0.011, 0.011, 0.011, 0.012, 0.009, 0.011, 0.011, 0.009, 0.012, 0.011, 0.011, 0.012, 0.011, 0.013, 0.011, 0.012, 0.013, 0.011, 0.011, 0.011, 0.013, 0.013, 0.011, 0.012, 0.013, 0.011, 0.01, 0.011, 0.012, 0.012, 0.013, 0.01, 0.012, 0.012, 0.011, 0.011, 0.01, 0.01, 0.012, 0.012, 0.01, 0.011, 0.011, 0.011, 0.012, 0.011, 0.013, 0.011, 0.01, 0.011, 0.011, 0.013, 0.011, 0.012, 0.011, 0.013, 0.011, 0.013, 0.01, 0.012, 0.013, 0.01, 0.012, 0.011, 0.011, 0.011, 0.011, 0.014, 0.011, 0.011, 0.01, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.012, 0.011, 0.013, 0.013, 0.01, 0.012, 0.012, 0.011, 0.01, 0.011, 0.011, 0.009, 0.012, 0.012, 0.012, 0.01, 0.012, 0.013, 0.011, 0.011, 0.01, 0.011, 0.011, 0.012, 0.012, 0.012, 0.01, 0.011, 0.011, 0.013, 0.011, 0.012, 0.01, 0.011, 0.012, 0.012, 0.012, 0.011, 0.01, 0.013, 0.011, 0.009, 0.011, 0.011, 0.011, 0.012, 0.01, 0.011, 0.012, 0.012, 0.011, 0.011, 0.01, 0.01, 0.012, 0.013, 0.012, 0.012, 0.011, 0.013, 0.013, 0.012, 0.011, 0.013, 0.011, 0.011, 0.01, 0.01, 0.01, 0.011, 0.011, 0.012, 0.011, 0.012, 0.012, 0.011, 0.011, 0.013, 0.01, 0.013, 0.01, 0.012, 0.012, 0.011, 0.012, 0.011, 0.012, 0.011, 0.01, 0.011, 0.01, 0.012, 0.008, 0.012, 0.012, 0.011, 0.01, 0.013, 0.013, 0.012, 0.011, 0.01, 0.011, 0.012, 0.011, 0.01, 0.01, 0.012, 0.012, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.011, 0.013, 0.012, 0.012, 0.01, 0.011, 0.015, 0.011, 0.012, 0.011, 0.011, 0.01, 0.01, 0.012, 0.011, 0.01, 0.011, 0.011, 0.013, 0.011, 0.012, 0.012, 0.012, 0.011, 0.01, 0.011, 0.011, 0.013, 0.011, 0.011, 0.01, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.012, 0.01, 0.011, 0.011, 0.013, 0.009, 0.011, 0.013, 0.01, 0.01, 0.012, 0.012, 0.011, 0.012, 0.012, 0.012, 0.013, 0.012, 0.01, 0.011, 0.01, 0.01, 0.011, 0.01, 0.011, 0.013, 0.012, 0.011, 0.011, 0.012, 0.012, 0.012, 0.011, 0.012, 0.009, 0.012, 0.012, 0.012, 0.01, 0.012, 0.01, 0.01, 0.011, 0.014, 0.012, 0.011, 0.011, 0.014, 0.01, 0.011, 0.011, 0.012, 0.01, 0.012, 0.013, 0.012, 0.012, 0.01, 0.011, 0.011, 0.011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 7043 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:51:00] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 06, 17:51:00] #> Got bucket_cutoffs = tensor([-7.4085e-03,  5.5323e-06,  7.3854e-03]) and bucket_weights = tensor([-0.0161, -0.0029,  0.0029,  0.0161])\n",
      "[Feb 06, 17:51:00] avg_residual = 0.011337448842823505\n",
      "[Feb 06, 17:51:00] [0] \t\t #> Encoding 790 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 1/13 [00:00<00:05,  2.06it/s]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:00<00:05,  2.12it/s]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:01<00:04,  2.09it/s]\u001b[A\n",
      " 31%|███       | 4/13 [00:01<00:04,  1.98it/s]\u001b[A\n",
      " 38%|███▊      | 5/13 [00:02<00:04,  2.00it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:02<00:03,  2.05it/s]\u001b[A\n",
      " 54%|█████▍    | 7/13 [00:03<00:02,  2.11it/s]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:03<00:02,  2.14it/s]\u001b[A\n",
      " 69%|██████▉   | 9/13 [00:04<00:01,  2.13it/s]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:04<00:01,  2.06it/s]\u001b[A\n",
      " 85%|████████▍ | 11/13 [00:05<00:00,  2.00it/s]\u001b[A\n",
      " 92%|█████████▏| 12/13 [00:05<00:00,  1.95it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:06<00:00,  2.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:51:06] [0] \t\t #> Saving chunk 0: \t 790 passages and 7,413 embeddings. From #0 onward.\n",
      "[Feb 06, 17:51:06] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 06, 17:51:06] [0] \t\t Found all files!\n",
      "[Feb 06, 17:51:06] [0] \t\t #> Building IVF...\n",
      "[Feb 06, 17:51:06] [0] \t\t #> Loading codes...\n",
      "[Feb 06, 17:51:06] [0] \t\t Sorting codes...\n",
      "[Feb 06, 17:51:06] [0] \t\t Getting unique codes...\n",
      "[Feb 06, 17:51:06] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 06, 17:51:06] #> Building the emb2pid mapping..\n",
      "[Feb 06, 17:51:06] len(emb2pid) = 7413\n",
      "[Feb 06, 17:51:06] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_4302_2bits/ivf.pid.pt\n",
      "[Feb 06, 17:51:06] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_4302_2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.22s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1704.31it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 90781.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Feb 06, 17:51:07] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 06, 17:51:07] #> Note: Output directory /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_2815_2bits already exists\n",
      "\n",
      "\n",
      "[Feb 06, 17:51:07] #> Will delete 10 files already at /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_2815_2bits in 20 seconds...\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 2998,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 768,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/bert-base-multilingual-cased_dim_768_bsize_230_lr04_use_ib_negatives\\/none\\/2024-01\\/27\\/16.55.29\\/checkpoints\\/colbert-2998-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tmp_tutorial\\/2815_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_2815_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"tutorial\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/06\\/17.49.21\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 06, 17:51:30] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:51:30] [0] \t\t # of sampled PIDs = 2577 \t sampled_pids[:3] = [1706, 41, 1223]\n",
      "[Feb 06, 17:51:30] [0] \t\t #> Encoding 2577 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:25<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:51:56] [0] \t\t avg_doclen_est = 10.490104675292969 \t len(local_sample) = 2,577\n",
      "[Feb 06, 17:51:56] [0] \t\t Creaing 2,048 partitions.\n",
      "[Feb 06, 17:51:56] [0] \t\t *Estimated* 27,032 embeddings.\n",
      "[Feb 06, 17:51:56] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_2815_2bits/plan.json ..\n",
      "Clustering 25682 points in 768D to 2048 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 25682 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration 3 (0.66 s, search 0.64 s): objective=5036.17 imbalance=1.456 nsplit=0       \n",
      "[0.014, 0.013, 0.017, 0.013, 0.016, 0.013, 0.013, 0.014, 0.014, 0.015, 0.013, 0.012, 0.013, 0.012, 0.013, 0.014, 0.013, 0.014, 0.014, 0.014, 0.012, 0.014, 0.013, 0.014, 0.015, 0.014, 0.012, 0.012, 0.013, 0.014, 0.014, 0.016, 0.014, 0.013, 0.012, 0.012, 0.012, 0.014, 0.012, 0.012, 0.014, 0.014, 0.015, 0.013, 0.015, 0.012, 0.014, 0.013, 0.013, 0.012, 0.012, 0.012, 0.014, 0.015, 0.012, 0.013, 0.014, 0.016, 0.012, 0.012, 0.014, 0.013, 0.013, 0.016, 0.014, 0.013, 0.014, 0.016, 0.013, 0.013, 0.014, 0.013, 0.012, 0.012, 0.013, 0.014, 0.014, 0.013, 0.014, 0.012, 0.012, 0.016, 0.012, 0.012, 0.012, 0.013, 0.013, 0.012, 0.017, 0.012, 0.013, 0.014, 0.014, 0.012, 0.013, 0.015, 0.012, 0.014, 0.014, 0.012, 0.012, 0.015, 0.015, 0.013, 0.014, 0.014, 0.014, 0.014, 0.013, 0.012, 0.013, 0.012, 0.013, 0.013, 0.012, 0.014, 0.014, 0.015, 0.013, 0.013, 0.014, 0.012, 0.013, 0.013, 0.014, 0.014, 0.014, 0.014, 0.013, 0.013, 0.013, 0.014, 0.011, 0.014, 0.013, 0.014, 0.014, 0.014, 0.013, 0.012, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.012, 0.013, 0.015, 0.012, 0.014, 0.013, 0.012, 0.013, 0.014, 0.013, 0.012, 0.012, 0.015, 0.015, 0.013, 0.014, 0.012, 0.013, 0.013, 0.014, 0.012, 0.015, 0.014, 0.013, 0.014, 0.012, 0.013, 0.014, 0.015, 0.013, 0.013, 0.014, 0.014, 0.013, 0.014, 0.013, 0.015, 0.013, 0.014, 0.014, 0.013, 0.014, 0.012, 0.013, 0.013, 0.012, 0.013, 0.015, 0.012, 0.013, 0.013, 0.013, 0.013, 0.014, 0.013, 0.015, 0.016, 0.012, 0.013, 0.013, 0.013, 0.011, 0.013, 0.014, 0.011, 0.013, 0.013, 0.012, 0.011, 0.012, 0.013, 0.014, 0.012, 0.012, 0.014, 0.014, 0.013, 0.014, 0.014, 0.013, 0.012, 0.013, 0.013, 0.015, 0.014, 0.013, 0.013, 0.014, 0.013, 0.017, 0.011, 0.013, 0.013, 0.012, 0.013, 0.013, 0.014, 0.014, 0.014, 0.014, 0.012, 0.011, 0.014, 0.012, 0.014, 0.013, 0.013, 0.013, 0.013, 0.013, 0.015, 0.011, 0.013, 0.012, 0.013, 0.012, 0.013, 0.012, 0.012, 0.013, 0.013, 0.014, 0.014, 0.012, 0.013, 0.012, 0.013, 0.013, 0.013, 0.012, 0.014, 0.015, 0.014, 0.013, 0.012, 0.014, 0.014, 0.015, 0.013, 0.014, 0.012, 0.012, 0.014, 0.014, 0.013, 0.014, 0.014, 0.013, 0.012, 0.013, 0.012, 0.015, 0.013, 0.016, 0.012, 0.014, 0.014, 0.013, 0.014, 0.014, 0.013, 0.011, 0.014, 0.015, 0.015, 0.012, 0.013, 0.016, 0.012, 0.013, 0.012, 0.013, 0.014, 0.012, 0.013, 0.014, 0.012, 0.012, 0.013, 0.014, 0.012, 0.012, 0.013, 0.013, 0.013, 0.014, 0.013, 0.013, 0.014, 0.014, 0.015, 0.012, 0.013, 0.012, 0.011, 0.012, 0.014, 0.013, 0.013, 0.012, 0.014, 0.012, 0.012, 0.012, 0.013, 0.013, 0.014, 0.013, 0.014, 0.013, 0.013, 0.014, 0.014, 0.014, 0.013, 0.014, 0.014, 0.015, 0.013, 0.013, 0.013, 0.012, 0.014, 0.013, 0.014, 0.012, 0.013, 0.014, 0.013, 0.013, 0.013, 0.014, 0.014, 0.013, 0.014, 0.013, 0.013, 0.013, 0.014, 0.012, 0.011, 0.013, 0.013, 0.012, 0.013, 0.013, 0.015, 0.012, 0.014, 0.016, 0.011, 0.013, 0.013, 0.015, 0.015, 0.012, 0.015, 0.012, 0.012, 0.013, 0.013, 0.014, 0.013, 0.013, 0.013, 0.014, 0.014, 0.013, 0.014, 0.013, 0.012, 0.013, 0.013, 0.013, 0.013, 0.017, 0.013, 0.013, 0.013, 0.013, 0.014, 0.014, 0.012, 0.013, 0.013, 0.011, 0.014, 0.013, 0.013, 0.013, 0.013, 0.012, 0.015, 0.013, 0.015, 0.011, 0.013, 0.013, 0.014, 0.012, 0.012, 0.013, 0.013, 0.013, 0.013, 0.012, 0.013, 0.013, 0.012, 0.012, 0.012, 0.013, 0.014, 0.013, 0.014, 0.012, 0.015, 0.013, 0.013, 0.012, 0.013, 0.013, 0.012, 0.014, 0.013, 0.013, 0.015, 0.013, 0.013, 0.013, 0.014, 0.013, 0.013, 0.011, 0.013, 0.012, 0.013, 0.015, 0.013, 0.011, 0.014, 0.013, 0.014, 0.012, 0.012, 0.015, 0.013, 0.013, 0.013, 0.014, 0.014, 0.012, 0.014, 0.014, 0.013, 0.011, 0.013, 0.014, 0.014, 0.015, 0.011, 0.014, 0.011, 0.014, 0.013, 0.013, 0.012, 0.015, 0.013, 0.014, 0.013, 0.013, 0.013, 0.014, 0.012, 0.014, 0.014, 0.013, 0.013, 0.013, 0.014, 0.014, 0.014, 0.013, 0.014, 0.013, 0.015, 0.013, 0.013, 0.015, 0.012, 0.013, 0.014, 0.013, 0.012, 0.013, 0.015, 0.013, 0.013, 0.012, 0.013, 0.013, 0.013, 0.013, 0.012, 0.015, 0.014, 0.012, 0.015, 0.014, 0.012, 0.013, 0.013, 0.013, 0.012, 0.013, 0.012, 0.011, 0.014, 0.013, 0.012, 0.011, 0.013, 0.015, 0.013, 0.012, 0.013, 0.012, 0.013, 0.014, 0.014, 0.015, 0.011, 0.013, 0.013, 0.014, 0.013, 0.013, 0.014, 0.013, 0.013, 0.015, 0.014, 0.013, 0.011, 0.014, 0.013, 0.011, 0.014, 0.011, 0.013, 0.014, 0.012, 0.013, 0.015, 0.014, 0.013, 0.013, 0.012, 0.013, 0.015, 0.015, 0.013, 0.014, 0.013, 0.014, 0.013, 0.012, 0.013, 0.014, 0.013, 0.013, 0.012, 0.012, 0.013, 0.014, 0.014, 0.013, 0.014, 0.013, 0.013, 0.013, 0.013, 0.013, 0.011, 0.015, 0.014, 0.013, 0.013, 0.014, 0.014, 0.013, 0.015, 0.014, 0.012, 0.015, 0.012, 0.014, 0.011, 0.014, 0.014, 0.012, 0.012, 0.014, 0.014, 0.014, 0.013, 0.012, 0.013, 0.015, 0.013, 0.013, 0.013, 0.014, 0.014, 0.013, 0.012, 0.012, 0.013, 0.013, 0.013, 0.013, 0.013, 0.015, 0.013, 0.014, 0.012, 0.013, 0.015, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.014, 0.013, 0.012, 0.013, 0.014, 0.014, 0.014, 0.013, 0.013, 0.013, 0.013, 0.013, 0.014, 0.013, 0.013, 0.015, 0.014, 0.013, 0.014, 0.013, 0.013, 0.013, 0.012, 0.014, 0.014, 0.01, 0.013, 0.013, 0.014, 0.012, 0.014, 0.014, 0.012, 0.013, 0.013, 0.013, 0.012, 0.014, 0.013, 0.014, 0.013, 0.014, 0.012, 0.013, 0.012, 0.013, 0.014, 0.013, 0.014, 0.014, 0.013, 0.013, 0.012, 0.013, 0.015, 0.013, 0.014, 0.013, 0.012, 0.014, 0.012, 0.014, 0.012, 0.013, 0.014, 0.014, 0.013, 0.015, 0.014, 0.013, 0.014, 0.014, 0.014, 0.014, 0.012, 0.014, 0.011, 0.013, 0.014, 0.014, 0.014, 0.012, 0.013, 0.012, 0.013]\n",
      "[Feb 06, 17:51:57] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 06, 17:51:57] #> Got bucket_cutoffs = tensor([-9.7640e-03,  8.7796e-06,  9.7949e-03]) and bucket_weights = tensor([-0.0185, -0.0042,  0.0043,  0.0187])\n",
      "[Feb 06, 17:51:57] avg_residual = 0.013215147890150547\n",
      "[Feb 06, 17:51:57] [0] \t\t #> Encoding 2577 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/41 [00:00<00:23,  1.67it/s]\u001b[A\n",
      "  5%|▍         | 2/41 [00:01<00:23,  1.65it/s]\u001b[A\n",
      "  7%|▋         | 3/41 [00:01<00:23,  1.61it/s]\u001b[A\n",
      " 10%|▉         | 4/41 [00:02<00:22,  1.66it/s]\u001b[A\n",
      " 12%|█▏        | 5/41 [00:03<00:21,  1.67it/s]\u001b[A\n",
      " 15%|█▍        | 6/41 [00:03<00:20,  1.69it/s]\u001b[A\n",
      " 17%|█▋        | 7/41 [00:04<00:20,  1.69it/s]\u001b[A\n",
      " 20%|█▉        | 8/41 [00:05<00:22,  1.49it/s]\u001b[A\n",
      " 22%|██▏       | 9/41 [00:05<00:20,  1.56it/s]\u001b[A\n",
      " 24%|██▍       | 10/41 [00:06<00:19,  1.62it/s]\u001b[A\n",
      " 27%|██▋       | 11/41 [00:06<00:18,  1.65it/s]\u001b[A\n",
      " 29%|██▉       | 12/41 [00:07<00:17,  1.68it/s]\u001b[A\n",
      " 32%|███▏      | 13/41 [00:07<00:16,  1.66it/s]\u001b[A\n",
      " 34%|███▍      | 14/41 [00:08<00:15,  1.69it/s]\u001b[A\n",
      " 37%|███▋      | 15/41 [00:09<00:15,  1.71it/s]\u001b[A\n",
      " 39%|███▉      | 16/41 [00:09<00:14,  1.73it/s]\u001b[A\n",
      " 41%|████▏     | 17/41 [00:10<00:13,  1.74it/s]\u001b[A\n",
      " 44%|████▍     | 18/41 [00:10<00:13,  1.74it/s]\u001b[A\n",
      " 46%|████▋     | 19/41 [00:11<00:12,  1.75it/s]\u001b[A\n",
      " 49%|████▉     | 20/41 [00:11<00:11,  1.75it/s]\u001b[A\n",
      " 51%|█████     | 21/41 [00:12<00:11,  1.75it/s]\u001b[A\n",
      " 54%|█████▎    | 22/41 [00:13<00:10,  1.75it/s]\u001b[A\n",
      " 56%|█████▌    | 23/41 [00:13<00:10,  1.75it/s]\u001b[A\n",
      " 59%|█████▊    | 24/41 [00:14<00:09,  1.75it/s]\u001b[A\n",
      " 61%|██████    | 25/41 [00:14<00:09,  1.75it/s]\u001b[A\n",
      " 63%|██████▎   | 26/41 [00:15<00:08,  1.75it/s]\u001b[A\n",
      " 66%|██████▌   | 27/41 [00:15<00:08,  1.75it/s]\u001b[A\n",
      " 68%|██████▊   | 28/41 [00:16<00:07,  1.75it/s]\u001b[A\n",
      " 71%|███████   | 29/41 [00:17<00:06,  1.75it/s]\u001b[A\n",
      " 73%|███████▎  | 30/41 [00:17<00:06,  1.74it/s]\u001b[A\n",
      " 76%|███████▌  | 31/41 [00:18<00:05,  1.72it/s]\u001b[A\n",
      " 78%|███████▊  | 32/41 [00:18<00:05,  1.71it/s]\u001b[A\n",
      " 80%|████████  | 33/41 [00:19<00:04,  1.72it/s]\u001b[A\n",
      " 83%|████████▎ | 34/41 [00:19<00:04,  1.72it/s]\u001b[A\n",
      " 85%|████████▌ | 35/41 [00:20<00:03,  1.72it/s]\u001b[A\n",
      " 88%|████████▊ | 36/41 [00:21<00:02,  1.73it/s]\u001b[A\n",
      " 90%|█████████ | 37/41 [00:21<00:02,  1.73it/s]\u001b[A\n",
      " 93%|█████████▎| 38/41 [00:22<00:01,  1.73it/s]\u001b[A\n",
      " 95%|█████████▌| 39/41 [00:22<00:01,  1.73it/s]\u001b[A\n",
      " 98%|█████████▊| 40/41 [00:23<00:00,  1.67it/s]\u001b[A\n",
      "100%|██████████| 41/41 [00:23<00:00,  1.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:52:21] [0] \t\t #> Saving chunk 0: \t 2,577 passages and 27,033 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:24, 24.26s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1550.57it/s]\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 156736.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:52:21] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 06, 17:52:21] [0] \t\t Found all files!\n",
      "[Feb 06, 17:52:21] [0] \t\t #> Building IVF...\n",
      "[Feb 06, 17:52:21] [0] \t\t #> Loading codes...\n",
      "[Feb 06, 17:52:21] [0] \t\t Sorting codes...\n",
      "[Feb 06, 17:52:21] [0] \t\t Getting unique codes...\n",
      "[Feb 06, 17:52:21] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 06, 17:52:21] #> Building the emb2pid mapping..\n",
      "[Feb 06, 17:52:21] len(emb2pid) = 27033\n",
      "[Feb 06, 17:52:21] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_2815_2bits/ivf.pid.pt\n",
      "[Feb 06, 17:52:21] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_2815_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 06, 17:52:22] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 06, 17:52:22] #> Note: Output directory /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3901_2bits already exists\n",
      "\n",
      "\n",
      "[Feb 06, 17:52:22] #> Will delete 10 files already at /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3901_2bits in 20 seconds...\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 2998,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 768,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/bert-base-multilingual-cased_dim_768_bsize_230_lr04_use_ib_negatives\\/none\\/2024-01\\/27\\/16.55.29\\/checkpoints\\/colbert-2998-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tmp_tutorial\\/3901_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_3901_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"tutorial\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/06\\/17.49.21\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 06, 17:52:45] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:52:45] [0] \t\t # of sampled PIDs = 847 \t sampled_pids[:3] = [426, 750, 10]\n",
      "[Feb 06, 17:52:45] [0] \t\t #> Encoding 847 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:05<00:00,  2.49it/s]\n",
      "WARNING clustering 8372 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:52:51] [0] \t\t avg_doclen_est = 10.403778076171875 \t len(local_sample) = 847\n",
      "[Feb 06, 17:52:51] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 06, 17:52:51] [0] \t\t *Estimated* 8,812 embeddings.\n",
      "[Feb 06, 17:52:51] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3901_2bits/plan.json ..\n",
      "Clustering 8372 points in 768D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 3 (0.14 s, search 0.13 s): objective=1212.59 imbalance=1.478 nsplit=0       \n",
      "[0.013, 0.013, 0.012, 0.01, 0.013, 0.011, 0.013, 0.012, 0.013, 0.013, 0.011, 0.012, 0.011, 0.011, 0.01, 0.011, 0.011, 0.011, 0.012, 0.012, 0.01, 0.012, 0.012, 0.013, 0.012, 0.012, 0.011, 0.01, 0.01, 0.014, 0.012, 0.012, 0.012, 0.011, 0.011, 0.011, 0.01, 0.012, 0.01, 0.011, 0.012, 0.013, 0.012, 0.012, 0.014, 0.01, 0.011, 0.011, 0.01, 0.009, 0.012, 0.01, 0.013, 0.01, 0.011, 0.011, 0.012, 0.013, 0.011, 0.009, 0.012, 0.01, 0.011, 0.012, 0.012, 0.011, 0.011, 0.012, 0.011, 0.011, 0.012, 0.012, 0.01, 0.011, 0.011, 0.012, 0.012, 0.011, 0.012, 0.011, 0.01, 0.012, 0.01, 0.009, 0.011, 0.01, 0.01, 0.011, 0.013, 0.011, 0.013, 0.011, 0.011, 0.01, 0.012, 0.011, 0.01, 0.01, 0.01, 0.011, 0.01, 0.012, 0.013, 0.01, 0.011, 0.01, 0.011, 0.011, 0.012, 0.01, 0.01, 0.01, 0.011, 0.011, 0.011, 0.012, 0.011, 0.013, 0.012, 0.01, 0.011, 0.01, 0.01, 0.011, 0.013, 0.012, 0.012, 0.012, 0.011, 0.012, 0.011, 0.011, 0.011, 0.012, 0.013, 0.011, 0.012, 0.012, 0.011, 0.011, 0.012, 0.011, 0.01, 0.01, 0.013, 0.011, 0.01, 0.01, 0.012, 0.012, 0.012, 0.012, 0.011, 0.011, 0.012, 0.01, 0.011, 0.011, 0.011, 0.011, 0.011, 0.012, 0.01, 0.013, 0.011, 0.011, 0.012, 0.011, 0.01, 0.012, 0.012, 0.011, 0.012, 0.01, 0.01, 0.012, 0.012, 0.011, 0.011, 0.011, 0.011, 0.012, 0.011, 0.012, 0.011, 0.011, 0.012, 0.012, 0.011, 0.011, 0.01, 0.011, 0.011, 0.01, 0.011, 0.013, 0.01, 0.011, 0.01, 0.01, 0.011, 0.012, 0.011, 0.012, 0.014, 0.01, 0.012, 0.011, 0.011, 0.009, 0.01, 0.012, 0.009, 0.01, 0.01, 0.01, 0.01, 0.011, 0.011, 0.011, 0.01, 0.011, 0.012, 0.012, 0.01, 0.012, 0.012, 0.012, 0.01, 0.011, 0.01, 0.012, 0.011, 0.012, 0.012, 0.011, 0.01, 0.015, 0.01, 0.011, 0.01, 0.01, 0.011, 0.011, 0.012, 0.012, 0.013, 0.012, 0.011, 0.01, 0.011, 0.011, 0.011, 0.01, 0.012, 0.011, 0.011, 0.012, 0.012, 0.011, 0.01, 0.01, 0.012, 0.012, 0.01, 0.011, 0.011, 0.011, 0.011, 0.012, 0.01, 0.01, 0.011, 0.009, 0.011, 0.011, 0.011, 0.011, 0.012, 0.014, 0.012, 0.012, 0.011, 0.013, 0.011, 0.014, 0.011, 0.012, 0.01, 0.012, 0.013, 0.012, 0.011, 0.012, 0.011, 0.01, 0.01, 0.011, 0.011, 0.012, 0.012, 0.012, 0.011, 0.013, 0.012, 0.011, 0.012, 0.011, 0.01, 0.009, 0.012, 0.012, 0.013, 0.01, 0.011, 0.013, 0.01, 0.012, 0.01, 0.01, 0.011, 0.01, 0.01, 0.012, 0.011, 0.01, 0.011, 0.012, 0.01, 0.01, 0.01, 0.011, 0.011, 0.011, 0.012, 0.012, 0.011, 0.012, 0.011, 0.009, 0.011, 0.012, 0.01, 0.009, 0.012, 0.011, 0.011, 0.01, 0.013, 0.01, 0.01, 0.011, 0.01, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.012, 0.012, 0.011, 0.011, 0.011, 0.013, 0.012, 0.011, 0.011, 0.012, 0.01, 0.012, 0.011, 0.011, 0.011, 0.01, 0.011, 0.012, 0.011, 0.012, 0.011, 0.011, 0.013, 0.013, 0.011, 0.013, 0.012, 0.013, 0.01, 0.01, 0.012, 0.011, 0.01, 0.011, 0.012, 0.013, 0.01, 0.012, 0.014, 0.009, 0.014, 0.01, 0.013, 0.011, 0.011, 0.012, 0.01, 0.01, 0.011, 0.011, 0.011, 0.012, 0.011, 0.01, 0.012, 0.012, 0.011, 0.011, 0.011, 0.01, 0.012, 0.011, 0.011, 0.012, 0.012, 0.011, 0.012, 0.011, 0.011, 0.012, 0.011, 0.012, 0.011, 0.011, 0.009, 0.012, 0.011, 0.011, 0.011, 0.01, 0.011, 0.013, 0.011, 0.013, 0.009, 0.011, 0.01, 0.013, 0.01, 0.011, 0.01, 0.01, 0.01, 0.011, 0.01, 0.01, 0.01, 0.01, 0.01, 0.012, 0.01, 0.012, 0.012, 0.013, 0.01, 0.013, 0.01, 0.013, 0.009, 0.01, 0.011, 0.012, 0.012, 0.011, 0.012, 0.012, 0.01, 0.011, 0.011, 0.012, 0.012, 0.011, 0.011, 0.011, 0.01, 0.01, 0.013, 0.011, 0.011, 0.012, 0.011, 0.013, 0.009, 0.01, 0.012, 0.012, 0.012, 0.011, 0.013, 0.013, 0.012, 0.012, 0.01, 0.011, 0.01, 0.01, 0.012, 0.012, 0.013, 0.011, 0.011, 0.01, 0.013, 0.011, 0.012, 0.01, 0.012, 0.011, 0.01, 0.011, 0.012, 0.012, 0.011, 0.011, 0.011, 0.01, 0.011, 0.012, 0.011, 0.012, 0.012, 0.011, 0.012, 0.013, 0.01, 0.012, 0.01, 0.011, 0.013, 0.01, 0.011, 0.011, 0.011, 0.012, 0.011, 0.012, 0.011, 0.011, 0.01, 0.012, 0.011, 0.01, 0.012, 0.009, 0.012, 0.012, 0.011, 0.012, 0.012, 0.01, 0.012, 0.013, 0.012, 0.01, 0.013, 0.011, 0.01, 0.01, 0.012, 0.011, 0.011, 0.011, 0.013, 0.011, 0.01, 0.011, 0.011, 0.011, 0.013, 0.011, 0.014, 0.01, 0.011, 0.012, 0.012, 0.011, 0.011, 0.011, 0.012, 0.01, 0.011, 0.011, 0.011, 0.01, 0.012, 0.011, 0.01, 0.01, 0.01, 0.011, 0.011, 0.01, 0.012, 0.011, 0.012, 0.01, 0.01, 0.011, 0.011, 0.012, 0.012, 0.011, 0.012, 0.011, 0.012, 0.012, 0.011, 0.011, 0.012, 0.011, 0.01, 0.01, 0.01, 0.011, 0.011, 0.011, 0.012, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.012, 0.011, 0.012, 0.011, 0.012, 0.013, 0.011, 0.012, 0.012, 0.01, 0.012, 0.011, 0.012, 0.01, 0.011, 0.012, 0.01, 0.011, 0.012, 0.012, 0.012, 0.01, 0.011, 0.009, 0.012, 0.012, 0.01, 0.012, 0.012, 0.011, 0.01, 0.011, 0.011, 0.01, 0.01, 0.01, 0.01, 0.01, 0.013, 0.011, 0.011, 0.01, 0.011, 0.014, 0.01, 0.012, 0.012, 0.011, 0.01, 0.011, 0.012, 0.012, 0.011, 0.01, 0.012, 0.012, 0.011, 0.011, 0.011, 0.014, 0.011, 0.011, 0.01, 0.011, 0.012, 0.012, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.011, 0.012, 0.009, 0.011, 0.011, 0.013, 0.01, 0.012, 0.013, 0.011, 0.01, 0.012, 0.011, 0.012, 0.012, 0.012, 0.011, 0.013, 0.013, 0.01, 0.01, 0.01, 0.011, 0.012, 0.01, 0.012, 0.013, 0.011, 0.01, 0.01, 0.012, 0.013, 0.011, 0.011, 0.011, 0.011, 0.011, 0.01, 0.01, 0.01, 0.012, 0.01, 0.011, 0.011, 0.012, 0.01, 0.011, 0.012, 0.014, 0.01, 0.012, 0.011, 0.012, 0.009, 0.011, 0.012, 0.013, 0.012, 0.01, 0.011, 0.011, 0.011]\n",
      "[Feb 06, 17:52:51] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 06, 17:52:51] #> Got bucket_cutoffs = tensor([-7.5208e-03, -1.3013e-05,  7.4679e-03]) and bucket_weights = tensor([-0.0159, -0.0031,  0.0030,  0.0157])\n",
      "[Feb 06, 17:52:51] avg_residual = 0.011194181628525257\n",
      "[Feb 06, 17:52:51] [0] \t\t #> Encoding 847 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 1/14 [00:00<00:05,  2.19it/s]\u001b[A\n",
      " 14%|█▍        | 2/14 [00:00<00:05,  2.17it/s]\u001b[A\n",
      " 21%|██▏       | 3/14 [00:01<00:05,  2.17it/s]\u001b[A\n",
      " 29%|██▊       | 4/14 [00:01<00:04,  2.20it/s]\u001b[A\n",
      " 36%|███▌      | 5/14 [00:02<00:04,  2.24it/s]\u001b[A\n",
      " 43%|████▎     | 6/14 [00:02<00:03,  2.29it/s]\u001b[A\n",
      " 50%|█████     | 7/14 [00:03<00:03,  2.28it/s]\u001b[A\n",
      " 57%|█████▋    | 8/14 [00:03<00:02,  2.24it/s]\u001b[A\n",
      " 64%|██████▍   | 9/14 [00:04<00:02,  2.23it/s]\u001b[A\n",
      " 71%|███████▏  | 10/14 [00:04<00:01,  2.22it/s]\u001b[A\n",
      " 79%|███████▊  | 11/14 [00:04<00:01,  2.24it/s]\u001b[A\n",
      " 86%|████████▌ | 12/14 [00:05<00:00,  2.25it/s]\u001b[A\n",
      " 93%|█████████▎| 13/14 [00:05<00:00,  2.27it/s]\u001b[A\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 17:52:57] [0] \t\t #> Saving chunk 0: \t 847 passages and 8,812 embeddings. From #0 onward.\n",
      "[Feb 06, 17:52:57] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 06, 17:52:57] [0] \t\t Found all files!\n",
      "[Feb 06, 17:52:57] [0] \t\t #> Building IVF...\n",
      "[Feb 06, 17:52:57] [0] \t\t #> Loading codes...\n",
      "[Feb 06, 17:52:57] [0] \t\t Sorting codes...\n",
      "[Feb 06, 17:52:57] [0] \t\t Getting unique codes...\n",
      "[Feb 06, 17:52:57] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 06, 17:52:57] #> Building the emb2pid mapping..\n",
      "[Feb 06, 17:52:57] len(emb2pid) = 8812\n",
      "[Feb 06, 17:52:57] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3901_2bits/ivf.pid.pt\n",
      "[Feb 06, 17:52:57] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3901_2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.04s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2493.64it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 158147.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Feb 06, 17:52:58] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 06, 17:52:58] #> Note: Output directory /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3904_2bits already exists\n",
      "\n",
      "\n",
      "[Feb 06, 17:52:58] #> Will delete 10 files already at /home/sondors/Documents/price/ColBERT/experiments/tutorial/indexes/models_3904_2bits in 20 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m models_colbert \u001b[38;5;241m=\u001b[39m Collection(path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst_fld,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_models.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     18\u001b[0m index_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcat_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnbits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mbits\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 19\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43msave_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_pth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_maxlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnranks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_colbert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36msave_index\u001b[0;34m(ckpt_pth, doc_maxlen, nbits, nranks, experiment, collection, index_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m     config \u001b[38;5;241m=\u001b[39m ColBERTConfig(doc_maxlen\u001b[38;5;241m=\u001b[39mdoc_maxlen, nbits\u001b[38;5;241m=\u001b[39mnbits)\n\u001b[1;32m      4\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m Indexer(checkpoint\u001b[38;5;241m=\u001b[39mckpt_pth, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[0;32m~/Documents/price/ColBERT/colbert/indexer.py:71\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self, name, collection, overwrite)\u001b[0m\n\u001b[1;32m     68\u001b[0m create_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mindex_path_)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overwrite \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_does_not_exist \u001b[38;5;129;01mor\u001b[39;00m overwrite \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__launch(collection)\n",
      "File \u001b[0;32m~/Documents/price/ColBERT/colbert/indexer.py:51\u001b[0m, in \u001b[0;36mIndexer.erase\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(deleted):\n\u001b[1;32m     50\u001b[0m     print_message(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#> Will delete \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(deleted)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files already at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in 20 seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m deleted:\n\u001b[1;32m     54\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(filename)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def save_index(ckpt_pth, doc_maxlen, nbits, nranks, experiment, collection, index_name):\n",
    "    with Run().context(RunConfig(nranks=nranks, experiment=experiment)):\n",
    "        config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits)#, root=\"/path/to/experiments\")\n",
    "        indexer = Indexer(checkpoint=ckpt_pth, config=config)\n",
    "        indexer.index(name=index_name, collection=collection, overwrite=True)\n",
    "    return indexer\n",
    "\n",
    "ckpt_pth = \"/home/sondors/Documents/ColBERT_weights/bert-base-multilingual-cased_dim_768_bsize_230_lr04_use_ib_negatives/none/2024-01/27/16.55.29/checkpoints/colbert-2998-finish\"\n",
    "experiment = \"tutorial\"\n",
    "\n",
    "doc_maxlen = 300\n",
    "nbits = 2   # encode each dimension with 2 bits\n",
    "nranks = 1  # nranks specifies the number of GPUs to use.\n",
    "\n",
    "for cat_id in categories_id:\n",
    "\n",
    "    models_colbert = Collection(path=os.path.join(dst_fld,f\"{cat_id}_models.tsv\"))\n",
    "    index_name = f'models_{cat_id}_{nbits}bits'\n",
    "    indexer = save_index(ckpt_pth, doc_maxlen, nbits, nranks, experiment, models_colbert, index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск матча по индексу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 18:54:21] #> Loading collection...\n",
      "0M \n",
      "[Feb 06, 18:54:22] #> Loading codec...\n",
      "[Feb 06, 18:54:22] #> Loading IVF...\n",
      "[Feb 06, 18:54:22] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2264.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 06, 18:54:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 320.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Samsung Планшет Samsung Galaxy Tab S8, 8 ГБ/128 ГБ, Wi-Fi + Cellular, со стилусом, графит (Global), \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([   101,    100,  37077,    524,  19079, 105694,  37077,  29723,  14248,\n",
      "         10457,    156,  11396,    117,    129,    512,  18683,    120,  16196,\n",
      "           512,  18683,    117,  52742,    118,  36448,    116,  29494,  18062,\n",
      "           117,  10956,  67459,  19954,    102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 355.64it/s]\n"
     ]
    }
   ],
   "source": [
    "def top_n_similar(offers, experiment, index_name, model_ids, n):\n",
    "    with Run().context(RunConfig(experiment=experiment)):\n",
    "        # config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits)#, root=\"/path/to/experiments\")\n",
    "        searcher = Searcher(index=index_name, collection=model_ids)#, config=config)\n",
    "        offers = Queries(data=offers)\n",
    "        rankings = searcher.search_all(offers, k=n)\n",
    "        top_n = rankings_to_dict(rankings, searcher)\n",
    "    return top_n\n",
    "\n",
    "def rankings_to_dict(rankings, searcher):\n",
    "    result = []\n",
    "    for key, value in rankings.todict().items():\n",
    "        model_ids = [int(searcher.collection[item[0]]) for item in value]\n",
    "        similarity = [item[2] for item in value]\n",
    "        result.append({'model_ids': model_ids, 'similarity': similarity})\n",
    "    return result\n",
    "\n",
    "offers = {\n",
    "    0: 'Samsung Планшет Samsung Galaxy Tab S8, 8 ГБ/128 ГБ, Wi-Fi + Cellular, со стилусом, графит (Global)',\n",
    "    1: 'Планшет Samsung Galaxy Tab S8 128GB 5G Silver (SM-X706B)',\n",
    "    2: 'Планшет Samsung Galaxy Tab S8+ 128GB Wi-Fi Pink Gold (SM-X800)'\n",
    "    }\n",
    "\n",
    "experiment = \"tutorial\"\n",
    "doc_maxlen = 300\n",
    "nbits = 2   # encode each dimension with 2 bits\n",
    "nranks = 1  # nranks specifies the number of GPUs to use.\n",
    "cat_id = 2801 # мобильные телефоны\n",
    "cat_id = 510401 # планшеты\n",
    "index_name = f'models_{cat_id}_{nbits}bits'\n",
    "models_id_colbert = Collection(path=os.path.join(dst_fld,f\"{cat_id}_models_id.tsv\"))\n",
    "\n",
    "top_n = top_n_similar(offers, experiment, index_name, models_id_colbert, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем выдачу топ N моделей для каждого оффера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung Планшет Samsung Galaxy Tab S8, 8 ГБ/128 ГБ, Wi-Fi + Cellular, со стилусом, графит (Global)\n",
      "\t5144478: Samsung Galaxy Tab S8 --> 28.97\n",
      "\t5144477: Samsung Galaxy Tab S8+ --> 24.97\n",
      "\t937550: Samsung Galaxy Tab S2 9.7 SM-T813 --> 24.0\n",
      "\t5144479: Samsung Galaxy Tab S8 Ultra --> 23.98\n",
      "\t816746: Samsung Galaxy Tab S2 9.7 SM-T810 --> 23.64\n",
      "____________________________________________________________\n",
      "Планшет Samsung Galaxy Tab S8 128GB 5G Silver (SM-X706B)\n",
      "\t5144478: Samsung Galaxy Tab S8 --> 28.15\n",
      "\t5144477: Samsung Galaxy Tab S8+ --> 23.94\n",
      "\t937550: Samsung Galaxy Tab S2 9.7 SM-T813 --> 23.21\n",
      "\t623216: Samsung Galaxy Tab S 8.4 SM-T705 --> 22.82\n",
      "\t816746: Samsung Galaxy Tab S2 9.7 SM-T810 --> 22.65\n",
      "____________________________________________________________\n",
      "Планшет Samsung Galaxy Tab S8+ 128GB Wi-Fi Pink Gold (SM-X800)\n",
      "\t5144477: Samsung Galaxy Tab S8+ --> 26.03\n",
      "\t5144478: Samsung Galaxy Tab S8 --> 20.32\n",
      "\t4509798: Samsung Galaxy Tab S7+ 12.4 128Gb --> 18.63\n",
      "\t937550: Samsung Galaxy Tab S2 9.7 SM-T813 --> 18.35\n",
      "\t5144479: Samsung Galaxy Tab S8 Ultra --> 18.31\n",
      "____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top_n)):\n",
    "    print(offers[i])\n",
    "    for j in range(len(top_n[i]['model_ids'])):\n",
    "        id = top_n[i]['model_ids'][j]\n",
    "        sim = top_n[i]['similarity'][j]\n",
    "        model = list(df_models[df_models.model_id == id]['full_name'])[0]\n",
    "        print(f\"\\t{id}: {model} --> {round(float(sim), 2)}\")\n",
    "    print(\"_\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model_ids': [5144478, 5144477, 937550, 5144479, 816746], 'similarity': [28.973285675048828, 24.965259552001953, 23.999181747436523, 23.97533416748047, 23.638072967529297]}, {'model_ids': [5144478, 5144477, 937550, 623216, 816746], 'similarity': [28.152374267578125, 23.93535041809082, 23.20758819580078, 22.81966781616211, 22.648759841918945]}, {'model_ids': [5144477, 5144478, 4509798, 937550, 5144479], 'similarity': [26.02865982055664, 20.31949234008789, 18.63184928894043, 18.34659194946289, 18.30866813659668]}]\n"
     ]
    }
   ],
   "source": [
    "print(top_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
