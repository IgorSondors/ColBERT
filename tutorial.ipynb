{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты, параметры ColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interface import prepare_tsv, save_index, top_n_similar, Collection\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ckpt_pth = \"/home/sondors/Documents/ColBERT_weights/triples_X1_13_categories_use_ib_negatives/none/2024-01/26/10.49.44/checkpoints/colbert-5387-finish\"\n",
    "experiment = \"colbert-5387\"\n",
    "\n",
    "doc_maxlen = 300\n",
    "nbits = 2   # bits определяет количество битов у каждого измерения в семантическом пространстве во время индексации\n",
    "nranks = 1  # nranks определяет количество GPU для использования, если они доступны\n",
    "kmeans_niters = 4 # kmeans_niters указывает количество итераций k-means кластеризации; 4 — хороший и быстрый вариант по умолчанию.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка моделей\n",
    "\n",
    "В данном примере готовим модели в качестве того на что матчить оффера. Данные должны быть в формате, пригодном для индексации с помощью ColBERT. В общем случае в индексе может быть и смесь моделей и уже ранее моделизованных офферов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60661/17807022.py:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_models = pd.read_csv(pth_models, sep=\";\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>average_price</th>\n",
       "      <th>name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>comment</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>920-005619</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>Logitech 920-005619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>721952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zipper Bag</td>\n",
       "      <td>Hama</td>\n",
       "      <td>Hama Zipper Bag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>721970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC-3064</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>Nokia CC-3064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751488</td>\n",
       "      <td>990.0</td>\n",
       "      <td>CKS-X7/R</td>\n",
       "      <td>Sony</td>\n",
       "      <td>Sony CKS-X7/R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>751989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EP-031023</td>\n",
       "      <td>Era Pro</td>\n",
       "      <td>Era Pro EP-031023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103209</th>\n",
       "      <td>7049424</td>\n",
       "      <td>16459.0</td>\n",
       "      <td>MD-108</td>\n",
       "      <td>Mivo</td>\n",
       "      <td>Mivo MD-108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103210</th>\n",
       "      <td>7049425</td>\n",
       "      <td>8812.0</td>\n",
       "      <td>MD-165</td>\n",
       "      <td>Mivo</td>\n",
       "      <td>Mivo MD-165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103211</th>\n",
       "      <td>7049426</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>Boost 20W</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Rocket Boost 20W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103212</th>\n",
       "      <td>7049427</td>\n",
       "      <td>2990.0</td>\n",
       "      <td>Motion 10W</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Rocket Motion 10W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103213</th>\n",
       "      <td>7049428</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>Z1</td>\n",
       "      <td>SmartBuy</td>\n",
       "      <td>SmartBuy Z1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103214 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_id  average_price        name brand_name            full_name  \\\n",
       "0         623742            NaN  920-005619   Logitech  Logitech 920-005619   \n",
       "1         721952            NaN  Zipper Bag       Hama      Hama Zipper Bag   \n",
       "2         721970            NaN     CC-3064      Nokia        Nokia CC-3064   \n",
       "3         751488          990.0    CKS-X7/R       Sony        Sony CKS-X7/R   \n",
       "4         751989            NaN   EP-031023    Era Pro    Era Pro EP-031023   \n",
       "...          ...            ...         ...        ...                  ...   \n",
       "103209   7049424        16459.0      MD-108       Mivo          Mivo MD-108   \n",
       "103210   7049425         8812.0      MD-165       Mivo          Mivo MD-165   \n",
       "103211   7049426         4240.0   Boost 20W     Rocket     Rocket Boost 20W   \n",
       "103212   7049427         2990.0  Motion 10W     Rocket    Rocket Motion 10W   \n",
       "103213   7049428         8900.0          Z1   SmartBuy          SmartBuy Z1   \n",
       "\n",
       "       comment                                      category_name  category_id  \n",
       "0          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "1          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "2          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "3          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "4          NaN  чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "...        ...                                                ...          ...  \n",
       "103209     NaN                               портативная акустика         3904  \n",
       "103210     NaN                               портативная акустика         3904  \n",
       "103211     NaN                               портативная акустика         3904  \n",
       "103212     NaN                               портативная акустика         3904  \n",
       "103213     NaN                               портативная акустика         3904  \n",
       "\n",
       "[103214 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth_models = \"/home/sondors/Documents/price/ColBERT_data/18_categories/test/models_18_categories.csv\"\n",
    "df_models = pd.read_csv(pth_models, sep=\";\")\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_category = {\n",
    "    3902: 'диктофоны, портативные рекордеры',\n",
    "    510402: 'электронные книги',\n",
    "    4302: 'автомобильные телевизоры, мониторы',\n",
    "    2815: 'смарт-часы и браслеты',\n",
    "    3901: 'портативные медиаплееры',\n",
    "    3904: 'портативная акустика',\n",
    "    2801: 'мобильные телефоны',\n",
    "    3908: 'VR-гарнитуры (VR-очки, шлемы, очки виртуальной реальности, FPV очки для квадрокоптеров)',\n",
    "    510401: 'планшетные компьютеры и мини-планшеты',\n",
    "    2102: 'наушники, гарнитуры, наушники c микрофоном',\n",
    "    3903: 'радиоприемники, радиобудильники, радиочасы',\n",
    "    3907: 'магнитолы',\n",
    "    280801: 'GPS-навигаторы'\n",
    "    }\n",
    "\n",
    "dst_fld = \"/home/sondors/Documents/price/ColBERT/tutorial\"\n",
    "for cat_id in id_category.keys():\n",
    "    category_models = df_models[df_models.category_id == cat_id].reset_index(drop=True)\n",
    "    prepare_tsv(category_models, dst_fld, cat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Индексируем модели и сохраняем индекс на диск\n",
    "\n",
    "В id_category всего 13 категорий, в сумме 41037 шт моделей:\n",
    "\n",
    "- ColBERT bert-base-multilingual-cased_dim_768: индексация за 760 сек на CPU с 16 ядрами без GPU, вес индекса 109 Мб\n",
    "\n",
    "- ColBERTv2.0_dim_128: индексация за 790 сек на CPU с 16 ядрами без GPU, вес индекса 20.6 Мб"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:48:20] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:48:20] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3902_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/3902_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_3902_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:48:23] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:48:24] [0] \t\t # of sampled PIDs = 488 \t sampled_pids[:3] = [213, 375, 5]\n",
      "[Feb 07, 20:48:24] [0] \t\t #> Encoding 488 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.17it/s]\n",
      "WARNING clustering 4558 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:48:31] [0] \t\t avg_doclen_est = 9.829917907714844 \t len(local_sample) = 488\n",
      "[Feb 07, 20:48:31] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 07, 20:48:31] [0] \t\t *Estimated* 4,796 embeddings.\n",
      "[Feb 07, 20:48:31] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3902_2bits/plan.json ..\n",
      "Clustering 4558 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.01 s, search 0.01 s): objective=409.356 imbalance=1.531 nsplit=0       \n",
      "[0.022, 0.023, 0.02, 0.021, 0.021, 0.021, 0.023, 0.021, 0.017, 0.019, 0.019, 0.023, 0.02, 0.021, 0.02, 0.026, 0.02, 0.021, 0.022, 0.02, 0.021, 0.026, 0.022, 0.018, 0.02, 0.021, 0.023, 0.023, 0.024, 0.019, 0.02, 0.019, 0.018, 0.018, 0.024, 0.022, 0.019, 0.022, 0.022, 0.022, 0.02, 0.022, 0.023, 0.017, 0.021, 0.019, 0.018, 0.019, 0.019, 0.021, 0.025, 0.021, 0.024, 0.019, 0.022, 0.017, 0.018, 0.021, 0.023, 0.02, 0.019, 0.021, 0.024, 0.023, 0.019, 0.022, 0.019, 0.02, 0.017, 0.022, 0.02, 0.019, 0.022, 0.021, 0.02, 0.021, 0.019, 0.021, 0.022, 0.021, 0.021, 0.019, 0.022, 0.02, 0.021, 0.022, 0.022, 0.024, 0.023, 0.019, 0.019, 0.025, 0.023, 0.019, 0.021, 0.022, 0.019, 0.021, 0.022, 0.019, 0.017, 0.018, 0.02, 0.02, 0.023, 0.022, 0.022, 0.02, 0.021, 0.021, 0.021, 0.025, 0.019, 0.019, 0.022, 0.018, 0.02, 0.022, 0.017, 0.02, 0.025, 0.021, 0.02, 0.026, 0.02, 0.019, 0.023, 0.021]\n",
      "[Feb 07, 20:48:31] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:48:31] #> Got bucket_cutoffs = tensor([-0.0109,  0.0002,  0.0116]) and bucket_weights = tensor([-0.0270, -0.0042,  0.0047,  0.0282])\n",
      "[Feb 07, 20:48:31] avg_residual = 0.020863186568021774\n",
      "[Feb 07, 20:48:31] [0] \t\t #> Encoding 488 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▎        | 1/8 [00:00<00:05,  1.19it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:01<00:04,  1.21it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:02<00:04,  1.22it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:03<00:03,  1.16it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:04<00:02,  1.16it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:05<00:01,  1.17it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:05<00:00,  1.18it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.24it/s]\u001b[A\n",
      "1it [00:06,  6.46s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2294.48it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 164564.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:48:37] [0] \t\t #> Saving chunk 0: \t 488 passages and 4,797 embeddings. From #0 onward.\n",
      "[Feb 07, 20:48:37] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:48:37] [0] \t\t Found all files!\n",
      "[Feb 07, 20:48:37] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:48:37] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:48:37] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:48:37] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:48:37] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:48:37] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:48:37] len(emb2pid) = 4797\n",
      "[Feb 07, 20:48:37] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3902_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:48:37] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3902_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 20:48:38] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:48:38] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_510402_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/510402_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_510402_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:48:41] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:48:41] [0] \t\t # of sampled PIDs = 680 \t sampled_pids[:3] = [426, 10, 305]\n",
      "[Feb 07, 20:48:41] [0] \t\t #> Encoding 680 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:06<00:00,  1.76it/s]\n",
      "WARNING clustering 5855 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:48:47] [0] \t\t avg_doclen_est = 9.06323528289795 \t len(local_sample) = 680\n",
      "[Feb 07, 20:48:47] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 07, 20:48:47] [0] \t\t *Estimated* 6,162 embeddings.\n",
      "[Feb 07, 20:48:47] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_510402_2bits/plan.json ..\n",
      "Clustering 5855 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.02 s, search 0.01 s): objective=810.177 imbalance=1.552 nsplit=0       \n",
      "[0.029, 0.03, 0.03, 0.028, 0.03, 0.028, 0.027, 0.029, 0.026, 0.029, 0.031, 0.031, 0.031, 0.03, 0.029, 0.031, 0.029, 0.026, 0.026, 0.028, 0.03, 0.033, 0.029, 0.031, 0.029, 0.029, 0.034, 0.032, 0.03, 0.03, 0.026, 0.028, 0.03, 0.029, 0.031, 0.036, 0.027, 0.029, 0.031, 0.029, 0.025, 0.032, 0.033, 0.026, 0.028, 0.029, 0.028, 0.028, 0.028, 0.031, 0.028, 0.029, 0.029, 0.027, 0.032, 0.029, 0.031, 0.026, 0.029, 0.031, 0.025, 0.026, 0.031, 0.031, 0.028, 0.027, 0.027, 0.036, 0.026, 0.029, 0.029, 0.029, 0.031, 0.029, 0.026, 0.028, 0.032, 0.026, 0.028, 0.026, 0.03, 0.028, 0.033, 0.028, 0.029, 0.032, 0.03, 0.03, 0.031, 0.027, 0.029, 0.03, 0.03, 0.023, 0.028, 0.028, 0.027, 0.031, 0.03, 0.026, 0.027, 0.025, 0.03, 0.029, 0.03, 0.029, 0.029, 0.031, 0.03, 0.031, 0.029, 0.031, 0.028, 0.026, 0.027, 0.024, 0.029, 0.027, 0.026, 0.029, 0.029, 0.031, 0.03, 0.034, 0.028, 0.027, 0.032, 0.03]\n",
      "[Feb 07, 20:48:47] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:48:47] #> Got bucket_cutoffs = tensor([-0.0168,  0.0002,  0.0175]) and bucket_weights = tensor([-0.0399, -0.0064,  0.0069,  0.0407])\n",
      "[Feb 07, 20:48:47] avg_residual = 0.029046038165688515\n",
      "[Feb 07, 20:48:47] [0] \t\t #> Encoding 680 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 1/11 [00:00<00:05,  1.71it/s]\u001b[A\n",
      " 18%|█▊        | 2/11 [00:01<00:05,  1.71it/s]\u001b[A\n",
      " 27%|██▋       | 3/11 [00:01<00:04,  1.70it/s]\u001b[A\n",
      " 36%|███▋      | 4/11 [00:02<00:04,  1.72it/s]\u001b[A\n",
      " 45%|████▌     | 5/11 [00:02<00:03,  1.72it/s]\u001b[A\n",
      " 55%|█████▍    | 6/11 [00:03<00:02,  1.71it/s]\u001b[A\n",
      " 64%|██████▎   | 7/11 [00:04<00:02,  1.71it/s]\u001b[A\n",
      " 73%|███████▎  | 8/11 [00:04<00:01,  1.71it/s]\u001b[A\n",
      " 82%|████████▏ | 9/11 [00:05<00:01,  1.72it/s]\u001b[A\n",
      " 91%|█████████ | 10/11 [00:05<00:00,  1.73it/s]\u001b[A\n",
      "100%|██████████| 11/11 [00:06<00:00,  1.78it/s]\u001b[A\n",
      "1it [00:06,  6.21s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2211.02it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 159043.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:48:53] [0] \t\t #> Saving chunk 0: \t 680 passages and 6,163 embeddings. From #0 onward.\n",
      "[Feb 07, 20:48:53] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:48:53] [0] \t\t Found all files!\n",
      "[Feb 07, 20:48:53] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:48:53] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:48:53] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:48:53] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:48:53] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:48:53] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:48:53] len(emb2pid) = 6163\n",
      "[Feb 07, 20:48:53] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_510402_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:48:53] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_510402_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 20:48:54] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:48:54] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_4302_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/4302_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_4302_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:48:57] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:48:57] [0] \t\t # of sampled PIDs = 790 \t sampled_pids[:3] = [426, 750, 10]\n",
      "[Feb 07, 20:48:57] [0] \t\t #> Encoding 790 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:05<00:00,  2.34it/s]\n",
      "WARNING clustering 7045 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:49:03] [0] \t\t avg_doclen_est = 9.386075973510742 \t len(local_sample) = 790\n",
      "[Feb 07, 20:49:03] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 07, 20:49:03] [0] \t\t *Estimated* 7,415 embeddings.\n",
      "[Feb 07, 20:49:03] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_4302_2bits/plan.json ..\n",
      "Clustering 7045 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.02 s, search 0.02 s): objective=953.969 imbalance=1.533 nsplit=0       \n",
      "[0.024, 0.026, 0.025, 0.025, 0.025, 0.025, 0.025, 0.027, 0.023, 0.026, 0.025, 0.029, 0.025, 0.025, 0.025, 0.032, 0.025, 0.025, 0.025, 0.024, 0.023, 0.029, 0.024, 0.026, 0.026, 0.028, 0.029, 0.029, 0.026, 0.024, 0.024, 0.027, 0.027, 0.024, 0.031, 0.028, 0.023, 0.024, 0.03, 0.025, 0.022, 0.028, 0.028, 0.025, 0.025, 0.025, 0.024, 0.026, 0.023, 0.027, 0.028, 0.024, 0.029, 0.025, 0.024, 0.024, 0.028, 0.021, 0.026, 0.028, 0.026, 0.024, 0.031, 0.027, 0.026, 0.023, 0.024, 0.024, 0.021, 0.026, 0.024, 0.027, 0.025, 0.026, 0.02, 0.028, 0.023, 0.025, 0.029, 0.022, 0.026, 0.026, 0.029, 0.023, 0.026, 0.026, 0.025, 0.028, 0.027, 0.022, 0.027, 0.024, 0.027, 0.025, 0.026, 0.024, 0.023, 0.026, 0.028, 0.024, 0.023, 0.021, 0.024, 0.025, 0.027, 0.025, 0.026, 0.026, 0.026, 0.027, 0.022, 0.026, 0.027, 0.022, 0.026, 0.022, 0.024, 0.023, 0.022, 0.024, 0.027, 0.026, 0.026, 0.028, 0.025, 0.023, 0.03, 0.025]\n",
      "[Feb 07, 20:49:03] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:49:03] #> Got bucket_cutoffs = tensor([-0.0145,  0.0001,  0.0145]) and bucket_weights = tensor([-0.0357, -0.0053,  0.0055,  0.0354])\n",
      "[Feb 07, 20:49:03] avg_residual = 0.025463677942752838\n",
      "[Feb 07, 20:49:03] [0] \t\t #> Encoding 790 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 1/13 [00:00<00:06,  1.78it/s]\u001b[A\n",
      " 15%|█▌        | 2/13 [00:00<00:05,  2.06it/s]\u001b[A\n",
      " 23%|██▎       | 3/13 [00:01<00:04,  2.16it/s]\u001b[A\n",
      " 31%|███       | 4/13 [00:01<00:04,  2.07it/s]\u001b[A\n",
      " 38%|███▊      | 5/13 [00:02<00:03,  2.04it/s]\u001b[A\n",
      " 46%|████▌     | 6/13 [00:02<00:03,  2.00it/s]\u001b[A\n",
      " 54%|█████▍    | 7/13 [00:03<00:03,  1.99it/s]\u001b[A\n",
      " 62%|██████▏   | 8/13 [00:03<00:02,  2.02it/s]\u001b[A\n",
      " 69%|██████▉   | 9/13 [00:04<00:01,  2.04it/s]\u001b[A\n",
      " 77%|███████▋  | 10/13 [00:04<00:01,  2.07it/s]\u001b[A\n",
      " 85%|████████▍ | 11/13 [00:05<00:00,  2.11it/s]\u001b[A\n",
      " 92%|█████████▏| 12/13 [00:05<00:00,  2.11it/s]\u001b[A\n",
      "100%|██████████| 13/13 [00:05<00:00,  2.17it/s]\u001b[A\n",
      "1it [00:06,  6.03s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2435.72it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 158386.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:49:09] [0] \t\t #> Saving chunk 0: \t 790 passages and 7,415 embeddings. From #0 onward.\n",
      "[Feb 07, 20:49:09] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:49:09] [0] \t\t Found all files!\n",
      "[Feb 07, 20:49:09] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:49:09] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:49:09] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:49:09] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:49:09] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:49:09] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:49:09] len(emb2pid) = 7415\n",
      "[Feb 07, 20:49:09] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_4302_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:49:09] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_4302_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 20:49:09] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:49:09] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2815_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/2815_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_2815_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:49:12] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:49:13] [0] \t\t # of sampled PIDs = 2577 \t sampled_pids[:3] = [1706, 41, 1223]\n",
      "[Feb 07, 20:49:13] [0] \t\t #> Encoding 2577 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:41<00:00,  1.01s/it]\n",
      "WARNING clustering 24002 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:49:54] [0] \t\t avg_doclen_est = 9.804036140441895 \t len(local_sample) = 2,577\n",
      "[Feb 07, 20:49:54] [0] \t\t Creaing 2,048 partitions.\n",
      "[Feb 07, 20:49:54] [0] \t\t *Estimated* 25,265 embeddings.\n",
      "[Feb 07, 20:49:54] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2815_2bits/plan.json ..\n",
      "Clustering 24002 points in 128D to 2048 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.12 s, search 0.11 s): objective=4197.64 imbalance=1.559 nsplit=0       \n",
      "[0.03, 0.031, 0.03, 0.029, 0.031, 0.031, 0.03, 0.031, 0.025, 0.031, 0.029, 0.035, 0.031, 0.032, 0.028, 0.033, 0.028, 0.029, 0.029, 0.029, 0.03, 0.03, 0.03, 0.03, 0.029, 0.031, 0.032, 0.034, 0.034, 0.032, 0.026, 0.029, 0.032, 0.029, 0.032, 0.033, 0.03, 0.028, 0.034, 0.03, 0.028, 0.029, 0.032, 0.028, 0.03, 0.03, 0.028, 0.029, 0.031, 0.03, 0.029, 0.029, 0.033, 0.027, 0.034, 0.027, 0.031, 0.027, 0.032, 0.034, 0.029, 0.029, 0.034, 0.033, 0.029, 0.03, 0.026, 0.032, 0.026, 0.029, 0.028, 0.029, 0.031, 0.028, 0.026, 0.029, 0.028, 0.029, 0.03, 0.027, 0.031, 0.027, 0.029, 0.028, 0.029, 0.033, 0.032, 0.032, 0.031, 0.027, 0.031, 0.029, 0.033, 0.026, 0.032, 0.029, 0.03, 0.032, 0.032, 0.027, 0.027, 0.027, 0.029, 0.032, 0.033, 0.032, 0.034, 0.033, 0.028, 0.028, 0.029, 0.031, 0.028, 0.027, 0.029, 0.027, 0.028, 0.03, 0.03, 0.03, 0.033, 0.028, 0.029, 0.033, 0.028, 0.027, 0.031, 0.032]\n",
      "[Feb 07, 20:49:54] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:49:54] #> Got bucket_cutoffs = tensor([-1.9653e-02,  2.8189e-05,  1.9547e-02]) and bucket_weights = tensor([-0.0418, -0.0078,  0.0079,  0.0416])\n",
      "[Feb 07, 20:49:54] avg_residual = 0.0299469493329525\n",
      "[Feb 07, 20:49:54] [0] \t\t #> Encoding 2577 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/41 [00:01<00:40,  1.00s/it]\u001b[A\n",
      "  5%|▍         | 2/41 [00:02<00:39,  1.01s/it]\u001b[A\n",
      "  7%|▋         | 3/41 [00:03<00:38,  1.00s/it]\u001b[A\n",
      " 10%|▉         | 4/41 [00:04<00:37,  1.00s/it]\u001b[A\n",
      " 12%|█▏        | 5/41 [00:05<00:36,  1.01s/it]\u001b[A\n",
      " 15%|█▍        | 6/41 [00:06<00:35,  1.01s/it]\u001b[A\n",
      " 17%|█▋        | 7/41 [00:07<00:34,  1.01s/it]\u001b[A\n",
      " 20%|█▉        | 8/41 [00:08<00:32,  1.00it/s]\u001b[A\n",
      " 22%|██▏       | 9/41 [00:09<00:32,  1.00s/it]\u001b[A\n",
      " 24%|██▍       | 10/41 [00:10<00:31,  1.00s/it]\u001b[A\n",
      " 27%|██▋       | 11/41 [00:11<00:29,  1.01it/s]\u001b[A\n",
      " 29%|██▉       | 12/41 [00:11<00:28,  1.01it/s]\u001b[A\n",
      " 32%|███▏      | 13/41 [00:13<00:28,  1.00s/it]\u001b[A\n",
      " 34%|███▍      | 14/41 [00:14<00:27,  1.01s/it]\u001b[A\n",
      " 37%|███▋      | 15/41 [00:15<00:26,  1.01s/it]\u001b[A\n",
      " 39%|███▉      | 16/41 [00:16<00:25,  1.03s/it]\u001b[A\n",
      " 41%|████▏     | 17/41 [00:17<00:25,  1.08s/it]\u001b[A\n",
      " 44%|████▍     | 18/41 [00:18<00:24,  1.05s/it]\u001b[A\n",
      " 46%|████▋     | 19/41 [00:19<00:22,  1.03s/it]\u001b[A\n",
      " 49%|████▉     | 20/41 [00:20<00:21,  1.02s/it]\u001b[A\n",
      " 51%|█████     | 21/41 [00:21<00:20,  1.02s/it]\u001b[A\n",
      " 54%|█████▎    | 22/41 [00:22<00:19,  1.02s/it]\u001b[A\n",
      " 56%|█████▌    | 23/41 [00:23<00:18,  1.01s/it]\u001b[A\n",
      " 59%|█████▊    | 24/41 [00:24<00:17,  1.01s/it]\u001b[A\n",
      " 61%|██████    | 25/41 [00:25<00:16,  1.01s/it]\u001b[A\n",
      " 63%|██████▎   | 26/41 [00:26<00:15,  1.00s/it]\u001b[A\n",
      " 66%|██████▌   | 27/41 [00:27<00:14,  1.00s/it]\u001b[A\n",
      " 68%|██████▊   | 28/41 [00:28<00:13,  1.00s/it]\u001b[A\n",
      " 71%|███████   | 29/41 [00:29<00:12,  1.00s/it]\u001b[A\n",
      " 73%|███████▎  | 30/41 [00:30<00:10,  1.01it/s]\u001b[A\n",
      " 76%|███████▌  | 31/41 [00:31<00:09,  1.01it/s]\u001b[A\n",
      " 78%|███████▊  | 32/41 [00:32<00:09,  1.00s/it]\u001b[A\n",
      " 80%|████████  | 33/41 [00:33<00:08,  1.01s/it]\u001b[A\n",
      " 83%|████████▎ | 34/41 [00:34<00:07,  1.01s/it]\u001b[A\n",
      " 85%|████████▌ | 35/41 [00:35<00:05,  1.00it/s]\u001b[A\n",
      " 88%|████████▊ | 36/41 [00:36<00:04,  1.01it/s]\u001b[A\n",
      " 90%|█████████ | 37/41 [00:37<00:04,  1.01s/it]\u001b[A\n",
      " 93%|█████████▎| 38/41 [00:38<00:03,  1.01s/it]\u001b[A\n",
      " 95%|█████████▌| 39/41 [00:39<00:02,  1.00s/it]\u001b[A\n",
      " 98%|█████████▊| 40/41 [00:40<00:00,  1.00it/s]\u001b[A\n",
      "100%|██████████| 41/41 [00:40<00:00,  1.01it/s]\u001b[A\n",
      "1it [00:40, 40.80s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2387.20it/s]\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 148862.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:50:35] [0] \t\t #> Saving chunk 0: \t 2,577 passages and 25,265 embeddings. From #0 onward.\n",
      "[Feb 07, 20:50:35] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:50:35] [0] \t\t Found all files!\n",
      "[Feb 07, 20:50:35] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:50:35] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:50:35] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:50:35] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:50:35] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:50:35] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:50:35] len(emb2pid) = 25265\n",
      "[Feb 07, 20:50:35] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2815_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:50:35] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2815_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 20:50:36] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:50:36] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3901_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/3901_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_3901_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:50:39] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:50:39] [0] \t\t # of sampled PIDs = 847 \t sampled_pids[:3] = [426, 750, 10]\n",
      "[Feb 07, 20:50:39] [0] \t\t #> Encoding 847 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:05<00:00,  2.54it/s]\n",
      "WARNING clustering 7619 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:50:44] [0] \t\t avg_doclen_est = 9.46753215789795 \t len(local_sample) = 847\n",
      "[Feb 07, 20:50:44] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 07, 20:50:44] [0] \t\t *Estimated* 8,018 embeddings.\n",
      "[Feb 07, 20:50:44] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3901_2bits/plan.json ..\n",
      "Clustering 7619 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.02 s, search 0.02 s): objective=1212.13 imbalance=1.541 nsplit=0       \n",
      "[0.028, 0.032, 0.027, 0.032, 0.03, 0.03, 0.031, 0.03, 0.024, 0.029, 0.03, 0.032, 0.031, 0.033, 0.029, 0.032, 0.028, 0.028, 0.026, 0.028, 0.03, 0.031, 0.029, 0.03, 0.029, 0.032, 0.032, 0.033, 0.031, 0.029, 0.028, 0.031, 0.031, 0.028, 0.032, 0.031, 0.028, 0.03, 0.031, 0.032, 0.027, 0.028, 0.033, 0.03, 0.029, 0.027, 0.029, 0.028, 0.031, 0.029, 0.03, 0.031, 0.035, 0.027, 0.032, 0.025, 0.031, 0.029, 0.03, 0.034, 0.03, 0.026, 0.034, 0.034, 0.031, 0.029, 0.028, 0.031, 0.027, 0.028, 0.027, 0.03, 0.03, 0.029, 0.026, 0.027, 0.027, 0.028, 0.025, 0.027, 0.032, 0.026, 0.029, 0.028, 0.026, 0.031, 0.03, 0.033, 0.029, 0.025, 0.033, 0.031, 0.032, 0.024, 0.03, 0.031, 0.029, 0.03, 0.031, 0.026, 0.028, 0.024, 0.028, 0.029, 0.031, 0.029, 0.03, 0.029, 0.031, 0.029, 0.027, 0.029, 0.026, 0.024, 0.028, 0.024, 0.029, 0.028, 0.028, 0.03, 0.034, 0.028, 0.027, 0.033, 0.029, 0.026, 0.031, 0.032]\n",
      "[Feb 07, 20:50:45] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:50:45] #> Got bucket_cutoffs = tensor([-1.8490e-02,  8.7663e-05,  1.8948e-02]) and bucket_weights = tensor([-0.0402, -0.0072,  0.0075,  0.0417])\n",
      "[Feb 07, 20:50:45] avg_residual = 0.029325896874070168\n",
      "[Feb 07, 20:50:45] [0] \t\t #> Encoding 847 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/14 [00:00<00:05,  2.54it/s]\u001b[A\n",
      " 14%|█▍        | 2/14 [00:00<00:04,  2.53it/s]\u001b[A\n",
      " 21%|██▏       | 3/14 [00:01<00:04,  2.51it/s]\u001b[A\n",
      " 29%|██▊       | 4/14 [00:01<00:03,  2.51it/s]\u001b[A\n",
      " 36%|███▌      | 5/14 [00:01<00:03,  2.49it/s]\u001b[A\n",
      " 43%|████▎     | 6/14 [00:02<00:03,  2.48it/s]\u001b[A\n",
      " 50%|█████     | 7/14 [00:02<00:02,  2.47it/s]\u001b[A\n",
      " 57%|█████▋    | 8/14 [00:03<00:02,  2.45it/s]\u001b[A\n",
      " 64%|██████▍   | 9/14 [00:03<00:02,  2.46it/s]\u001b[A\n",
      " 71%|███████▏  | 10/14 [00:04<00:01,  2.48it/s]\u001b[A\n",
      " 79%|███████▊  | 11/14 [00:04<00:01,  2.49it/s]\u001b[A\n",
      " 86%|████████▌ | 12/14 [00:04<00:00,  2.51it/s]\u001b[A\n",
      " 93%|█████████▎| 13/14 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.63it/s]\u001b[A\n",
      "1it [00:05,  5.36s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2444.23it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 111464.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:50:50] [0] \t\t #> Saving chunk 0: \t 847 passages and 8,019 embeddings. From #0 onward.\n",
      "[Feb 07, 20:50:50] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:50:50] [0] \t\t Found all files!\n",
      "[Feb 07, 20:50:50] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:50:50] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:50:50] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:50:50] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:50:50] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:50:50] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:50:50] len(emb2pid) = 8019\n",
      "[Feb 07, 20:50:50] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3901_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:50:50] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3901_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 20:50:50] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:50:50] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3904_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/3904_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_3904_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:50:53] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:50:54] [0] \t\t # of sampled PIDs = 7399 \t sampled_pids[:3] = [3412, 6002, 83]\n",
      "[Feb 07, 20:50:54] [0] \t\t #> Encoding 7399 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:24<00:00,  2.04it/s]\n",
      "100%|██████████| 50/50 [00:37<00:00,  1.32it/s]\n",
      "100%|██████████| 16/16 [00:07<00:00,  2.03it/s]\n",
      "WARNING clustering 60044 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:52:04] [0] \t\t avg_doclen_est = 8.542235374450684 \t len(local_sample) = 7,399\n",
      "[Feb 07, 20:52:04] [0] \t\t Creaing 2,048 partitions.\n",
      "[Feb 07, 20:52:04] [0] \t\t *Estimated* 63,203 embeddings.\n",
      "[Feb 07, 20:52:04] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3904_2bits/plan.json ..\n",
      "Clustering 60044 points in 128D to 2048 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 3 (0.28 s, search 0.28 s): objective=14291.4 imbalance=1.556 nsplit=0        \n",
      "[0.033, 0.032, 0.033, 0.033, 0.036, 0.035, 0.034, 0.033, 0.027, 0.032, 0.032, 0.037, 0.033, 0.035, 0.03, 0.037, 0.03, 0.032, 0.032, 0.031, 0.032, 0.035, 0.034, 0.032, 0.031, 0.034, 0.034, 0.04, 0.035, 0.033, 0.031, 0.032, 0.034, 0.031, 0.035, 0.033, 0.031, 0.032, 0.039, 0.032, 0.029, 0.034, 0.037, 0.031, 0.033, 0.033, 0.033, 0.031, 0.032, 0.032, 0.032, 0.031, 0.035, 0.031, 0.035, 0.03, 0.033, 0.03, 0.033, 0.036, 0.031, 0.031, 0.038, 0.039, 0.032, 0.033, 0.029, 0.032, 0.03, 0.032, 0.03, 0.034, 0.034, 0.033, 0.029, 0.033, 0.032, 0.032, 0.033, 0.031, 0.034, 0.029, 0.032, 0.03, 0.033, 0.035, 0.033, 0.036, 0.033, 0.029, 0.036, 0.034, 0.035, 0.029, 0.033, 0.032, 0.032, 0.036, 0.036, 0.03, 0.031, 0.029, 0.031, 0.034, 0.034, 0.033, 0.034, 0.032, 0.033, 0.032, 0.031, 0.033, 0.029, 0.031, 0.032, 0.028, 0.031, 0.033, 0.03, 0.031, 0.036, 0.031, 0.032, 0.036, 0.031, 0.032, 0.036, 0.034]\n",
      "[Feb 07, 20:52:05] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:52:05] #> Got bucket_cutoffs = tensor([-0.0214,  0.0001,  0.0222]) and bucket_weights = tensor([-0.0457, -0.0081,  0.0086,  0.0472])\n",
      "[Feb 07, 20:52:05] avg_residual = 0.03265170380473137\n",
      "[Feb 07, 20:52:05] [0] \t\t #> Encoding 7399 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:22,  2.21it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:00<00:21,  2.22it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:21,  2.18it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:01<00:21,  2.19it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:02<00:20,  2.17it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:02<00:20,  2.15it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:03<00:20,  2.14it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:03<00:19,  2.15it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:04<00:18,  2.18it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:04<00:18,  2.18it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:05<00:18,  2.13it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:05<00:18,  2.10it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:06<00:20,  1.81it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:06<00:19,  1.87it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:07<00:18,  1.93it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:07<00:16,  2.00it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:08<00:16,  2.06it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:08<00:15,  2.05it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:09<00:15,  2.06it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:09<00:14,  2.10it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:10<00:13,  2.10it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:10<00:13,  2.12it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:11<00:12,  2.10it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:11<00:12,  2.12it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:11<00:11,  2.15it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:12<00:11,  2.17it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:12<00:10,  2.19it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:13<00:10,  2.20it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:13<00:09,  2.19it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:14<00:09,  2.18it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:14<00:08,  2.17it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:15<00:08,  2.15it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:15<00:07,  2.16it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:16<00:07,  2.16it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:16<00:06,  2.17it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:17<00:06,  2.18it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:17<00:05,  2.18it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:17<00:05,  2.18it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:18<00:05,  2.17it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:18<00:04,  2.14it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:19<00:04,  2.14it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:19<00:03,  2.14it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:20<00:03,  2.16it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:20<00:02,  2.18it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:21<00:02,  2.19it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:21<00:01,  2.19it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:22<00:01,  2.17it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:22<00:00,  2.17it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:23<00:00,  2.15it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:23<00:00,  2.13it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:35,  1.37it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:01<00:34,  1.38it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:02<00:34,  1.37it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:02<00:33,  1.36it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:03<00:33,  1.34it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:04<00:32,  1.35it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:05<00:31,  1.36it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:05<00:30,  1.37it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:06<00:30,  1.36it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:07<00:29,  1.35it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:08<00:28,  1.35it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:08<00:27,  1.37it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:09<00:26,  1.38it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:10<00:26,  1.36it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:11<00:25,  1.36it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:11<00:25,  1.35it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:12<00:24,  1.35it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:13<00:23,  1.37it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:13<00:22,  1.36it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:14<00:21,  1.36it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:15<00:21,  1.36it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:16<00:20,  1.36it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:16<00:19,  1.35it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:17<00:19,  1.36it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:18<00:18,  1.36it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:19<00:18,  1.32it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:19<00:17,  1.31it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:20<00:16,  1.34it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:21<00:15,  1.34it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:22<00:14,  1.35it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:22<00:14,  1.35it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:23<00:13,  1.34it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:24<00:12,  1.34it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:25<00:11,  1.35it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:25<00:11,  1.35it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:26<00:10,  1.33it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:27<00:09,  1.33it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:28<00:08,  1.33it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:28<00:08,  1.34it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:29<00:07,  1.35it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:30<00:06,  1.35it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:31<00:05,  1.34it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:31<00:05,  1.32it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:32<00:04,  1.31it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:33<00:03,  1.32it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:34<00:03,  1.33it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:34<00:02,  1.34it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:35<00:01,  1.33it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:36<00:00,  1.34it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:37<00:00,  1.35it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▋         | 1/16 [00:00<00:09,  1.60it/s]\u001b[A\n",
      " 12%|█▎        | 2/16 [00:01<00:07,  1.82it/s]\u001b[A\n",
      " 19%|█▉        | 3/16 [00:01<00:06,  1.91it/s]\u001b[A\n",
      " 25%|██▌       | 4/16 [00:02<00:06,  1.96it/s]\u001b[A\n",
      " 31%|███▏      | 5/16 [00:02<00:05,  1.98it/s]\u001b[A\n",
      " 38%|███▊      | 6/16 [00:03<00:04,  2.02it/s]\u001b[A\n",
      " 44%|████▍     | 7/16 [00:03<00:04,  2.04it/s]\u001b[A\n",
      " 50%|█████     | 8/16 [00:04<00:03,  2.05it/s]\u001b[A\n",
      " 56%|█████▋    | 9/16 [00:04<00:03,  2.04it/s]\u001b[A\n",
      " 62%|██████▎   | 10/16 [00:05<00:02,  2.03it/s]\u001b[A\n",
      " 69%|██████▉   | 11/16 [00:05<00:02,  2.03it/s]\u001b[A\n",
      " 75%|███████▌  | 12/16 [00:06<00:01,  2.02it/s]\u001b[A\n",
      " 81%|████████▏ | 13/16 [00:06<00:01,  2.01it/s]\u001b[A\n",
      " 88%|████████▊ | 14/16 [00:07<00:00,  2.02it/s]\u001b[A\n",
      " 94%|█████████▍| 15/16 [00:07<00:00,  2.04it/s]\u001b[A\n",
      "100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:53:13] [0] \t\t #> Saving chunk 0: \t 7,399 passages and 63,204 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:08, 68.98s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2366.99it/s]\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 104203.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:53:14] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:53:14] [0] \t\t Found all files!\n",
      "[Feb 07, 20:53:14] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:53:14] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:53:14] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:53:14] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:53:14] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:53:14] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:53:14] len(emb2pid) = 63204\n",
      "[Feb 07, 20:53:14] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3904_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:53:14] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3904_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 20:53:14] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:53:14] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2801_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/2801_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_2801_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:53:17] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:53:17] [0] \t\t # of sampled PIDs = 9494 \t sampled_pids[:3] = [6825, 166, 4892]\n",
      "[Feb 07, 20:53:17] [0] \t\t #> Encoding 9494 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:22<00:00,  2.21it/s]\n",
      "100%|██████████| 50/50 [00:25<00:00,  1.96it/s]\n",
      "100%|██████████| 49/49 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:54:32] [0] \t\t avg_doclen_est = 8.751526832580566 \t len(local_sample) = 9,494\n",
      "[Feb 07, 20:54:32] [0] \t\t Creaing 4,096 partitions.\n",
      "[Feb 07, 20:54:32] [0] \t\t *Estimated* 83,086 embeddings.\n",
      "[Feb 07, 20:54:32] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2801_2bits/plan.json ..\n",
      "Clustering 78933 points in 128D to 4096 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 78933 points to 4096 centroids: please provide at least 159744 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration 3 (0.73 s, search 0.72 s): objective=15881.7 imbalance=1.503 nsplit=0       \n",
      "[0.031, 0.032, 0.03, 0.032, 0.032, 0.033, 0.033, 0.031, 0.027, 0.032, 0.03, 0.034, 0.031, 0.034, 0.03, 0.034, 0.031, 0.03, 0.03, 0.029, 0.031, 0.035, 0.032, 0.031, 0.029, 0.034, 0.034, 0.036, 0.034, 0.033, 0.029, 0.03, 0.032, 0.029, 0.034, 0.034, 0.029, 0.029, 0.034, 0.03, 0.029, 0.032, 0.034, 0.031, 0.03, 0.031, 0.03, 0.029, 0.033, 0.031, 0.032, 0.03, 0.033, 0.029, 0.033, 0.029, 0.031, 0.029, 0.032, 0.034, 0.031, 0.031, 0.035, 0.039, 0.031, 0.03, 0.028, 0.031, 0.027, 0.029, 0.03, 0.033, 0.035, 0.033, 0.027, 0.03, 0.03, 0.03, 0.032, 0.028, 0.032, 0.028, 0.032, 0.028, 0.029, 0.034, 0.032, 0.032, 0.032, 0.027, 0.034, 0.034, 0.034, 0.027, 0.032, 0.029, 0.03, 0.035, 0.034, 0.028, 0.028, 0.028, 0.032, 0.031, 0.033, 0.031, 0.033, 0.032, 0.033, 0.03, 0.031, 0.033, 0.03, 0.029, 0.032, 0.028, 0.029, 0.031, 0.029, 0.031, 0.034, 0.03, 0.032, 0.038, 0.029, 0.03, 0.033, 0.033]\n",
      "[Feb 07, 20:54:33] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:54:33] #> Got bucket_cutoffs = tensor([-0.0208,  0.0001,  0.0211]) and bucket_weights = tensor([-0.0436, -0.0084,  0.0086,  0.0442])\n",
      "[Feb 07, 20:54:33] avg_residual = 0.03128911182284355\n",
      "[Feb 07, 20:54:33] [0] \t\t #> Encoding 9494 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:21,  2.31it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:00<00:20,  2.30it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:20,  2.27it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:01<00:20,  2.25it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:02<00:20,  2.22it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:02<00:20,  2.16it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:03<00:19,  2.18it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:03<00:19,  2.18it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:04<00:18,  2.21it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:04<00:17,  2.24it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:04<00:17,  2.24it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:05<00:17,  2.21it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:05<00:16,  2.22it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:06<00:16,  2.21it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:06<00:16,  2.18it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:07<00:15,  2.19it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:07<00:14,  2.22it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:08<00:14,  2.22it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:08<00:14,  2.19it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:09<00:13,  2.17it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:09<00:13,  2.20it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:09<00:12,  2.20it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:10<00:12,  2.20it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:10<00:11,  2.18it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:11<00:11,  2.22it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:11<00:10,  2.24it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:12<00:10,  2.26it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:12<00:09,  2.23it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:13<00:09,  2.25it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:13<00:08,  2.24it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:13<00:08,  2.25it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:14<00:07,  2.26it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:14<00:07,  2.26it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:15<00:07,  2.28it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:15<00:06,  2.31it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:16<00:06,  2.30it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:16<00:05,  2.28it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:17<00:05,  2.29it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:17<00:04,  2.26it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:17<00:04,  2.26it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:18<00:03,  2.25it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:18<00:03,  2.25it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:19<00:03,  2.27it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:19<00:02,  2.24it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:20<00:02,  2.25it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:20<00:01,  2.28it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:21<00:01,  2.29it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:21<00:00,  2.29it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:21<00:00,  2.29it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:22<00:00,  2.24it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:24,  1.99it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:00<00:23,  2.05it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:22,  2.07it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:01<00:22,  2.08it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:02<00:21,  2.07it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:02<00:21,  2.07it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:03<00:20,  2.06it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:03<00:20,  2.05it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:04<00:20,  2.04it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:04<00:19,  2.05it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:05<00:19,  2.04it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:05<00:19,  1.97it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:06<00:18,  1.95it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:06<00:18,  1.91it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:07<00:18,  1.92it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:08<00:18,  1.87it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:08<00:17,  1.84it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:09<00:17,  1.83it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:09<00:17,  1.80it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:10<00:16,  1.87it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:10<00:14,  1.94it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:11<00:14,  1.99it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:11<00:13,  2.03it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:12<00:12,  2.06it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:12<00:12,  2.07it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:13<00:11,  2.08it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:13<00:11,  2.00it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:14<00:11,  1.92it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:14<00:11,  1.87it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:15<00:10,  1.87it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:15<00:09,  1.91it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:16<00:09,  1.94it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:16<00:08,  1.95it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:17<00:08,  1.95it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:17<00:07,  1.95it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:18<00:07,  1.94it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:18<00:06,  1.94it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:19<00:06,  1.97it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:19<00:05,  1.99it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:20<00:04,  2.02it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:20<00:04,  2.03it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:21<00:03,  2.02it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:21<00:03,  2.02it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:22<00:02,  2.00it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:22<00:02,  1.99it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:23<00:01,  2.00it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:23<00:01,  2.02it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:24<00:00,  2.03it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:24<00:00,  2.02it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:25<00:00,  1.98it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/49 [00:00<00:35,  1.36it/s]\u001b[A\n",
      "  4%|▍         | 2/49 [00:01<00:29,  1.60it/s]\u001b[A\n",
      "  6%|▌         | 3/49 [00:01<00:27,  1.70it/s]\u001b[A\n",
      "  8%|▊         | 4/49 [00:02<00:25,  1.78it/s]\u001b[A\n",
      " 10%|█         | 5/49 [00:02<00:24,  1.83it/s]\u001b[A\n",
      " 12%|█▏        | 6/49 [00:03<00:23,  1.85it/s]\u001b[A\n",
      " 14%|█▍        | 7/49 [00:03<00:22,  1.86it/s]\u001b[A\n",
      " 16%|█▋        | 8/49 [00:04<00:22,  1.86it/s]\u001b[A\n",
      " 18%|█▊        | 9/49 [00:05<00:21,  1.86it/s]\u001b[A\n",
      " 20%|██        | 10/49 [00:05<00:21,  1.85it/s]\u001b[A\n",
      " 22%|██▏       | 11/49 [00:06<00:20,  1.87it/s]\u001b[A\n",
      " 24%|██▍       | 12/49 [00:06<00:19,  1.88it/s]\u001b[A\n",
      " 27%|██▋       | 13/49 [00:07<00:18,  1.90it/s]\u001b[A\n",
      " 29%|██▊       | 14/49 [00:07<00:18,  1.90it/s]\u001b[A\n",
      " 31%|███       | 15/49 [00:08<00:18,  1.88it/s]\u001b[A\n",
      " 33%|███▎      | 16/49 [00:08<00:17,  1.87it/s]\u001b[A\n",
      " 35%|███▍      | 17/49 [00:09<00:17,  1.86it/s]\u001b[A\n",
      " 37%|███▋      | 18/49 [00:09<00:16,  1.87it/s]\u001b[A\n",
      " 39%|███▉      | 19/49 [00:10<00:15,  1.90it/s]\u001b[A\n",
      " 41%|████      | 20/49 [00:10<00:15,  1.91it/s]\u001b[A\n",
      " 43%|████▎     | 21/49 [00:11<00:14,  1.92it/s]\u001b[A\n",
      " 45%|████▍     | 22/49 [00:11<00:14,  1.92it/s]\u001b[A\n",
      " 47%|████▋     | 23/49 [00:12<00:13,  1.92it/s]\u001b[A\n",
      " 49%|████▉     | 24/49 [00:12<00:13,  1.91it/s]\u001b[A\n",
      " 51%|█████     | 25/49 [00:13<00:12,  1.88it/s]\u001b[A\n",
      " 53%|█████▎    | 26/49 [00:13<00:12,  1.89it/s]\u001b[A\n",
      " 55%|█████▌    | 27/49 [00:14<00:11,  1.89it/s]\u001b[A\n",
      " 57%|█████▋    | 28/49 [00:15<00:11,  1.91it/s]\u001b[A\n",
      " 59%|█████▉    | 29/49 [00:15<00:10,  1.91it/s]\u001b[A\n",
      " 61%|██████    | 30/49 [00:16<00:09,  1.90it/s]\u001b[A\n",
      " 63%|██████▎   | 31/49 [00:16<00:09,  1.89it/s]\u001b[A\n",
      " 65%|██████▌   | 32/49 [00:17<00:09,  1.88it/s]\u001b[A\n",
      " 67%|██████▋   | 33/49 [00:17<00:08,  1.87it/s]\u001b[A\n",
      " 69%|██████▉   | 34/49 [00:18<00:07,  1.89it/s]\u001b[A\n",
      " 71%|███████▏  | 35/49 [00:18<00:07,  1.90it/s]\u001b[A\n",
      " 73%|███████▎  | 36/49 [00:19<00:06,  1.90it/s]\u001b[A\n",
      " 76%|███████▌  | 37/49 [00:19<00:06,  1.90it/s]\u001b[A\n",
      " 78%|███████▊  | 38/49 [00:20<00:05,  1.89it/s]\u001b[A\n",
      " 80%|███████▉  | 39/49 [00:20<00:05,  1.88it/s]\u001b[A\n",
      " 82%|████████▏ | 40/49 [00:21<00:04,  1.88it/s]\u001b[A\n",
      " 84%|████████▎ | 41/49 [00:21<00:04,  1.88it/s]\u001b[A\n",
      " 86%|████████▌ | 42/49 [00:22<00:03,  1.90it/s]\u001b[A\n",
      " 88%|████████▊ | 43/49 [00:22<00:03,  1.90it/s]\u001b[A\n",
      " 90%|████████▉ | 44/49 [00:23<00:02,  1.90it/s]\u001b[A\n",
      " 92%|█████████▏| 45/49 [00:24<00:02,  1.90it/s]\u001b[A\n",
      " 94%|█████████▍| 46/49 [00:24<00:01,  1.90it/s]\u001b[A\n",
      " 96%|█████████▌| 47/49 [00:25<00:01,  1.91it/s]\u001b[A\n",
      " 98%|█████████▊| 48/49 [00:25<00:00,  1.91it/s]\u001b[A\n",
      "100%|██████████| 49/49 [00:25<00:00,  1.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:55:47] [0] \t\t #> Saving chunk 0: \t 9,494 passages and 83,087 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:14, 74.52s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2084.64it/s]\n",
      "100%|██████████| 4096/4096 [00:00<00:00, 129369.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:55:47] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:55:47] [0] \t\t Found all files!\n",
      "[Feb 07, 20:55:47] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:55:47] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:55:47] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:55:48] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:55:48] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:55:48] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:55:48] len(emb2pid) = 83087\n",
      "[Feb 07, 20:55:48] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2801_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:55:48] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2801_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 20:55:48] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:55:48] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3908_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/3908_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_3908_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:55:51] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:55:51] [0] \t\t # of sampled PIDs = 146 \t sampled_pids[:3] = [106, 2, 76]\n",
      "[Feb 07, 20:55:51] [0] \t\t #> Encoding 146 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.04it/s]\n",
      "WARNING clustering 1216 points to 512 centroids: please provide at least 19968 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:55:52] [0] \t\t avg_doclen_est = 8.767123222351074 \t len(local_sample) = 146\n",
      "[Feb 07, 20:55:52] [0] \t\t Creaing 512 partitions.\n",
      "[Feb 07, 20:55:52] [0] \t\t *Estimated* 1,279 embeddings.\n",
      "[Feb 07, 20:55:52] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3908_2bits/plan.json ..\n",
      "Clustering 1216 points in 128D to 512 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.00 s, search 0.00 s): objective=85.2031 imbalance=1.402 nsplit=0       \n",
      "[0.024, 0.025, 0.03, 0.028, 0.029, 0.025, 0.026, 0.024, 0.025, 0.03, 0.029, 0.025, 0.03, 0.033, 0.027, 0.032, 0.026, 0.026, 0.03, 0.019, 0.025, 0.025, 0.028, 0.025, 0.027, 0.027, 0.031, 0.034, 0.03, 0.027, 0.022, 0.026, 0.026, 0.021, 0.031, 0.03, 0.027, 0.025, 0.034, 0.024, 0.023, 0.026, 0.034, 0.025, 0.026, 0.029, 0.025, 0.023, 0.033, 0.025, 0.027, 0.023, 0.03, 0.026, 0.024, 0.026, 0.026, 0.024, 0.025, 0.034, 0.026, 0.029, 0.029, 0.025, 0.029, 0.025, 0.022, 0.022, 0.023, 0.022, 0.027, 0.03, 0.027, 0.029, 0.022, 0.024, 0.022, 0.024, 0.03, 0.023, 0.026, 0.028, 0.027, 0.024, 0.029, 0.022, 0.028, 0.025, 0.033, 0.019, 0.028, 0.022, 0.03, 0.024, 0.022, 0.025, 0.025, 0.029, 0.029, 0.026, 0.024, 0.021, 0.024, 0.028, 0.028, 0.029, 0.029, 0.022, 0.022, 0.024, 0.033, 0.027, 0.023, 0.025, 0.026, 0.025, 0.024, 0.029, 0.028, 0.024, 0.033, 0.022, 0.028, 0.029, 0.024, 0.025, 0.023, 0.024]\n",
      "[Feb 07, 20:55:52] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:55:52] #> Got bucket_cutoffs = tensor([-0.0138, -0.0002,  0.0142]) and bucket_weights = tensor([-0.0356, -0.0051,  0.0051,  0.0366])\n",
      "[Feb 07, 20:55:52] avg_residual = 0.026383349671959877\n",
      "[Feb 07, 20:55:52] [0] \t\t #> Encoding 146 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.25it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.39it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.09it/s]\u001b[A\n",
      "1it [00:00,  1.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2546.63it/s]\n",
      "100%|██████████| 512/512 [00:00<00:00, 168933.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:55:53] [0] \t\t #> Saving chunk 0: \t 146 passages and 1,280 embeddings. From #0 onward.\n",
      "[Feb 07, 20:55:53] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:55:53] [0] \t\t Found all files!\n",
      "[Feb 07, 20:55:53] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:55:53] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:55:53] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:55:53] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:55:53] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:55:53] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:55:53] len(emb2pid) = 1280\n",
      "[Feb 07, 20:55:53] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3908_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:55:53] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3908_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 20:55:54] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:55:54] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_510401_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/510401_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_510401_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:55:57] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:55:57] [0] \t\t # of sampled PIDs = 3839 \t sampled_pids[:3] = [1706, 3001, 41]\n",
      "[Feb 07, 20:55:57] [0] \t\t #> Encoding 3839 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:27<00:00,  1.82it/s]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n",
      "WARNING clustering 37169 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:56:31] [0] \t\t avg_doclen_est = 10.191455841064453 \t len(local_sample) = 3,839\n",
      "[Feb 07, 20:56:31] [0] \t\t Creaing 2,048 partitions.\n",
      "[Feb 07, 20:56:31] [0] \t\t *Estimated* 39,124 embeddings.\n",
      "[Feb 07, 20:56:31] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_510401_2bits/plan.json ..\n",
      "Clustering 37169 points in 128D to 2048 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.28 s, search 0.27 s): objective=6985.24 imbalance=1.516 nsplit=0       \n",
      "[0.03, 0.032, 0.03, 0.03, 0.03, 0.031, 0.03, 0.03, 0.026, 0.031, 0.03, 0.034, 0.029, 0.035, 0.028, 0.033, 0.029, 0.029, 0.029, 0.029, 0.03, 0.031, 0.029, 0.029, 0.029, 0.029, 0.031, 0.034, 0.033, 0.031, 0.029, 0.028, 0.031, 0.028, 0.032, 0.033, 0.028, 0.029, 0.035, 0.031, 0.029, 0.031, 0.033, 0.03, 0.029, 0.03, 0.03, 0.028, 0.031, 0.031, 0.029, 0.031, 0.033, 0.027, 0.03, 0.029, 0.031, 0.028, 0.032, 0.031, 0.028, 0.029, 0.035, 0.037, 0.03, 0.029, 0.028, 0.031, 0.028, 0.03, 0.028, 0.031, 0.03, 0.029, 0.027, 0.03, 0.029, 0.029, 0.03, 0.028, 0.031, 0.026, 0.03, 0.028, 0.028, 0.032, 0.028, 0.032, 0.033, 0.028, 0.033, 0.033, 0.033, 0.026, 0.032, 0.03, 0.029, 0.033, 0.033, 0.027, 0.028, 0.026, 0.029, 0.029, 0.03, 0.029, 0.031, 0.033, 0.032, 0.029, 0.027, 0.03, 0.028, 0.026, 0.028, 0.026, 0.028, 0.03, 0.03, 0.032, 0.032, 0.028, 0.028, 0.037, 0.027, 0.028, 0.03, 0.031]\n",
      "[Feb 07, 20:56:32] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:56:32] #> Got bucket_cutoffs = tensor([-1.9799e-02,  4.5914e-06,  1.9990e-02]) and bucket_weights = tensor([-0.0418, -0.0080,  0.0081,  0.0419])\n",
      "[Feb 07, 20:56:32] avg_residual = 0.03000751882791519\n",
      "[Feb 07, 20:56:32] [0] \t\t #> Encoding 3839 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:31,  1.55it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:01<00:27,  1.73it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:26,  1.79it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:02<00:25,  1.78it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:02<00:24,  1.81it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:03<00:23,  1.85it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:03<00:22,  1.88it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:04<00:22,  1.89it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:04<00:21,  1.89it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:05<00:21,  1.87it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:05<00:20,  1.88it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:06<00:20,  1.88it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:07<00:19,  1.91it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:07<00:18,  1.93it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:08<00:18,  1.94it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:08<00:17,  1.94it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:09<00:17,  1.93it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:09<00:16,  1.92it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:10<00:16,  1.89it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:10<00:15,  1.88it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:11<00:15,  1.90it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:11<00:14,  1.90it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:12<00:14,  1.88it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:12<00:13,  1.87it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:13<00:13,  1.86it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:13<00:13,  1.84it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:14<00:12,  1.83it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:14<00:11,  1.85it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:15<00:11,  1.88it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:16<00:10,  1.88it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:16<00:10,  1.88it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:17<00:09,  1.87it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:17<00:09,  1.84it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:18<00:08,  1.83it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:18<00:08,  1.81it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:19<00:07,  1.85it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:19<00:06,  1.88it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:20<00:06,  1.90it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:20<00:05,  1.91it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:21<00:05,  1.91it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:21<00:04,  1.90it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:22<00:04,  1.89it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:22<00:03,  1.90it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:23<00:03,  1.93it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:23<00:02,  1.94it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:24<00:02,  1.94it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:25<00:01,  1.92it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:25<00:01,  1.89it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:26<00:00,  1.87it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:26<00:00,  1.88it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:06,  1.47it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
      " 30%|███       | 3/10 [00:01<00:04,  1.51it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:03<00:03,  1.47it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:04<00:02,  1.46it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:04<00:02,  1.41it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:05<00:01,  1.45it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
      "1it [00:33, 33.79s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2222.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:57:05] [0] \t\t #> Saving chunk 0: \t 3,839 passages and 39,125 embeddings. From #0 onward.\n",
      "[Feb 07, 20:57:06] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 20:57:06] [0] \t\t Found all files!\n",
      "[Feb 07, 20:57:06] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 20:57:06] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 20:57:06] [0] \t\t Sorting codes...\n",
      "[Feb 07, 20:57:06] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 20:57:06] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 20:57:06] #> Building the emb2pid mapping..\n",
      "[Feb 07, 20:57:06] len(emb2pid) = 39125\n",
      "[Feb 07, 20:57:06] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_510401_2bits/ivf.pid.pt\n",
      "[Feb 07, 20:57:06] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_510401_2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:00<00:00, 122267.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Feb 07, 20:57:06] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 20:57:06] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2102_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/2102_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_2102_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 20:57:09] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:57:10] [0] \t\t # of sampled PIDs = 11118 \t sampled_pids[:3] = [6825, 166, 4892]\n",
      "[Feb 07, 20:57:10] [0] \t\t #> Encoding 11118 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:27<00:00,  1.83it/s]\n",
      "100%|██████████| 50/50 [00:28<00:00,  1.76it/s]\n",
      "100%|██████████| 50/50 [00:26<00:00,  1.88it/s]\n",
      "100%|██████████| 24/24 [00:10<00:00,  2.22it/s]\n",
      "WARNING clustering 93384 points to 4096 centroids: please provide at least 159744 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 20:58:43] [0] \t\t avg_doclen_est = 8.841338157653809 \t len(local_sample) = 11,118\n",
      "[Feb 07, 20:58:43] [0] \t\t Creaing 4,096 partitions.\n",
      "[Feb 07, 20:58:43] [0] \t\t *Estimated* 98,297 embeddings.\n",
      "[Feb 07, 20:58:43] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2102_2bits/plan.json ..\n",
      "Clustering 93384 points in 128D to 4096 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 3 (0.88 s, search 0.87 s): objective=20497.2 imbalance=1.562 nsplit=0        \n",
      "[0.033, 0.032, 0.031, 0.033, 0.037, 0.035, 0.034, 0.032, 0.027, 0.033, 0.033, 0.036, 0.032, 0.034, 0.032, 0.034, 0.031, 0.032, 0.032, 0.031, 0.031, 0.034, 0.034, 0.032, 0.032, 0.034, 0.035, 0.038, 0.035, 0.034, 0.03, 0.031, 0.035, 0.031, 0.035, 0.034, 0.031, 0.033, 0.037, 0.031, 0.03, 0.033, 0.036, 0.031, 0.032, 0.033, 0.032, 0.031, 0.034, 0.033, 0.032, 0.031, 0.034, 0.032, 0.034, 0.031, 0.033, 0.031, 0.034, 0.035, 0.032, 0.032, 0.037, 0.037, 0.032, 0.031, 0.029, 0.033, 0.03, 0.031, 0.031, 0.034, 0.033, 0.032, 0.029, 0.032, 0.033, 0.033, 0.034, 0.031, 0.034, 0.031, 0.032, 0.03, 0.032, 0.034, 0.033, 0.036, 0.034, 0.028, 0.037, 0.033, 0.034, 0.028, 0.034, 0.032, 0.031, 0.034, 0.036, 0.029, 0.03, 0.029, 0.031, 0.032, 0.034, 0.033, 0.036, 0.033, 0.033, 0.032, 0.03, 0.032, 0.031, 0.028, 0.031, 0.029, 0.03, 0.033, 0.032, 0.033, 0.036, 0.03, 0.033, 0.036, 0.031, 0.031, 0.036, 0.035]\n",
      "[Feb 07, 20:58:44] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 20:58:44] #> Got bucket_cutoffs = tensor([-2.1565e-02,  4.9211e-06,  2.1662e-02]) and bucket_weights = tensor([-0.0458, -0.0085,  0.0086,  0.0460])\n",
      "[Feb 07, 20:58:44] avg_residual = 0.03256389871239662\n",
      "[Feb 07, 20:58:44] [0] \t\t #> Encoding 11118 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:26,  1.87it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:01<00:25,  1.87it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:25,  1.86it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:02<00:24,  1.87it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:02<00:23,  1.90it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:03<00:24,  1.83it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:03<00:25,  1.67it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:04<00:24,  1.74it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:04<00:22,  1.79it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:05<00:21,  1.82it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:06<00:21,  1.84it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:06<00:20,  1.87it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:07<00:19,  1.89it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:07<00:18,  1.91it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:08<00:18,  1.90it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:08<00:17,  1.89it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:09<00:17,  1.87it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:09<00:17,  1.85it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:10<00:16,  1.84it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:10<00:16,  1.87it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:11<00:16,  1.74it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:12<00:15,  1.78it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:12<00:14,  1.81it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:13<00:14,  1.82it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:13<00:13,  1.81it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:14<00:13,  1.80it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:14<00:12,  1.84it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:15<00:11,  1.88it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:15<00:11,  1.90it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:16<00:10,  1.91it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:16<00:09,  1.91it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:17<00:09,  1.90it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:17<00:09,  1.89it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:18<00:08,  1.89it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:18<00:07,  1.91it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:19<00:07,  1.91it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:19<00:06,  1.91it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:20<00:06,  1.89it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:21<00:05,  1.87it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:21<00:05,  1.85it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:22<00:04,  1.83it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:22<00:04,  1.85it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:23<00:03,  1.88it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:23<00:03,  1.89it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:24<00:02,  1.89it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:24<00:02,  1.87it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:25<00:01,  1.85it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:25<00:01,  1.83it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:26<00:00,  1.83it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:26<00:00,  1.85it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:27,  1.79it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:01<00:26,  1.79it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:26,  1.79it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:02<00:25,  1.79it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:02<00:25,  1.77it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:03<00:24,  1.78it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:03<00:23,  1.81it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:04<00:22,  1.83it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:04<00:22,  1.83it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:05<00:21,  1.83it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:06<00:21,  1.82it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:06<00:21,  1.81it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:07<00:20,  1.78it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:07<00:20,  1.80it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:08<00:19,  1.80it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:08<00:18,  1.81it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:09<00:18,  1.80it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:09<00:17,  1.80it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:10<00:17,  1.78it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:11<00:17,  1.76it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:11<00:16,  1.78it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:12<00:15,  1.80it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:12<00:14,  1.81it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:13<00:14,  1.80it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:13<00:13,  1.79it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:14<00:14,  1.66it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:15<00:13,  1.68it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:15<00:12,  1.71it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:16<00:12,  1.74it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:16<00:11,  1.76it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:17<00:10,  1.76it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:17<00:10,  1.75it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:18<00:09,  1.73it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:19<00:09,  1.71it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:19<00:08,  1.76it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:20<00:08,  1.71it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:20<00:07,  1.75it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:21<00:06,  1.79it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:21<00:06,  1.82it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:22<00:05,  1.83it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:23<00:04,  1.85it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:23<00:04,  1.86it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:24<00:03,  1.88it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:24<00:03,  1.88it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:25<00:02,  1.89it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:25<00:02,  1.88it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:26<00:01,  1.82it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:26<00:01,  1.82it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:27<00:00,  1.85it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:27<00:00,  1.80it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/50 [00:00<00:29,  1.63it/s]\u001b[A\n",
      "  4%|▍         | 2/50 [00:01<00:26,  1.79it/s]\u001b[A\n",
      "  6%|▌         | 3/50 [00:01<00:24,  1.89it/s]\u001b[A\n",
      "  8%|▊         | 4/50 [00:02<00:24,  1.85it/s]\u001b[A\n",
      " 10%|█         | 5/50 [00:02<00:24,  1.84it/s]\u001b[A\n",
      " 12%|█▏        | 6/50 [00:03<00:29,  1.50it/s]\u001b[A\n",
      " 14%|█▍        | 7/50 [00:04<00:31,  1.37it/s]\u001b[A\n",
      " 16%|█▌        | 8/50 [00:05<00:28,  1.48it/s]\u001b[A\n",
      " 18%|█▊        | 9/50 [00:05<00:26,  1.57it/s]\u001b[A\n",
      " 20%|██        | 10/50 [00:06<00:24,  1.65it/s]\u001b[A\n",
      " 22%|██▏       | 11/50 [00:06<00:22,  1.73it/s]\u001b[A\n",
      " 24%|██▍       | 12/50 [00:07<00:21,  1.80it/s]\u001b[A\n",
      " 26%|██▌       | 13/50 [00:07<00:21,  1.73it/s]\u001b[A\n",
      " 28%|██▊       | 14/50 [00:08<00:20,  1.79it/s]\u001b[A\n",
      " 30%|███       | 15/50 [00:08<00:19,  1.79it/s]\u001b[A\n",
      " 32%|███▏      | 16/50 [00:09<00:19,  1.71it/s]\u001b[A\n",
      " 34%|███▍      | 17/50 [00:10<00:19,  1.69it/s]\u001b[A\n",
      " 36%|███▌      | 18/50 [00:10<00:18,  1.71it/s]\u001b[A\n",
      " 38%|███▊      | 19/50 [00:11<00:17,  1.77it/s]\u001b[A\n",
      " 40%|████      | 20/50 [00:11<00:16,  1.80it/s]\u001b[A\n",
      " 42%|████▏     | 21/50 [00:12<00:15,  1.83it/s]\u001b[A\n",
      " 44%|████▍     | 22/50 [00:12<00:15,  1.81it/s]\u001b[A\n",
      " 46%|████▌     | 23/50 [00:13<00:15,  1.78it/s]\u001b[A\n",
      " 48%|████▊     | 24/50 [00:14<00:14,  1.75it/s]\u001b[A\n",
      " 50%|█████     | 25/50 [00:14<00:14,  1.73it/s]\u001b[A\n",
      " 52%|█████▏    | 26/50 [00:15<00:13,  1.73it/s]\u001b[A\n",
      " 54%|█████▍    | 27/50 [00:15<00:12,  1.81it/s]\u001b[A\n",
      " 56%|█████▌    | 28/50 [00:16<00:11,  1.87it/s]\u001b[A\n",
      " 58%|█████▊    | 29/50 [00:16<00:10,  1.92it/s]\u001b[A\n",
      " 60%|██████    | 30/50 [00:17<00:10,  1.94it/s]\u001b[A\n",
      " 62%|██████▏   | 31/50 [00:17<00:09,  1.97it/s]\u001b[A\n",
      " 64%|██████▍   | 32/50 [00:18<00:09,  1.98it/s]\u001b[A\n",
      " 66%|██████▌   | 33/50 [00:18<00:08,  2.00it/s]\u001b[A\n",
      " 68%|██████▊   | 34/50 [00:19<00:07,  2.00it/s]\u001b[A\n",
      " 70%|███████   | 35/50 [00:19<00:07,  2.01it/s]\u001b[A\n",
      " 72%|███████▏  | 36/50 [00:20<00:06,  2.02it/s]\u001b[A\n",
      " 74%|███████▍  | 37/50 [00:20<00:06,  2.01it/s]\u001b[A\n",
      " 76%|███████▌  | 38/50 [00:21<00:05,  2.02it/s]\u001b[A\n",
      " 78%|███████▊  | 39/50 [00:21<00:05,  1.98it/s]\u001b[A\n",
      " 80%|████████  | 40/50 [00:22<00:05,  1.94it/s]\u001b[A\n",
      " 82%|████████▏ | 41/50 [00:22<00:04,  1.88it/s]\u001b[A\n",
      " 84%|████████▍ | 42/50 [00:23<00:04,  1.85it/s]\u001b[A\n",
      " 86%|████████▌ | 43/50 [00:23<00:03,  1.90it/s]\u001b[A\n",
      " 88%|████████▊ | 44/50 [00:24<00:03,  1.93it/s]\u001b[A\n",
      " 90%|█████████ | 45/50 [00:24<00:02,  1.95it/s]\u001b[A\n",
      " 92%|█████████▏| 46/50 [00:25<00:02,  1.98it/s]\u001b[A\n",
      " 94%|█████████▍| 47/50 [00:25<00:01,  1.93it/s]\u001b[A\n",
      " 96%|█████████▌| 48/50 [00:26<00:01,  1.86it/s]\u001b[A\n",
      " 98%|█████████▊| 49/50 [00:26<00:00,  1.90it/s]\u001b[A\n",
      "100%|██████████| 50/50 [00:27<00:00,  1.82it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 1/24 [00:00<00:10,  2.25it/s]\u001b[A\n",
      "  8%|▊         | 2/24 [00:00<00:09,  2.27it/s]\u001b[A\n",
      " 12%|█▎        | 3/24 [00:01<00:09,  2.32it/s]\u001b[A\n",
      " 17%|█▋        | 4/24 [00:01<00:08,  2.34it/s]\u001b[A\n",
      " 21%|██        | 5/24 [00:02<00:08,  2.36it/s]\u001b[A\n",
      " 25%|██▌       | 6/24 [00:02<00:07,  2.38it/s]\u001b[A\n",
      " 29%|██▉       | 7/24 [00:02<00:07,  2.39it/s]\u001b[A\n",
      " 33%|███▎      | 8/24 [00:03<00:06,  2.40it/s]\u001b[A\n",
      " 38%|███▊      | 9/24 [00:03<00:06,  2.27it/s]\u001b[A\n",
      " 42%|████▏     | 10/24 [00:04<00:06,  2.15it/s]\u001b[A\n",
      " 46%|████▌     | 11/24 [00:04<00:06,  2.09it/s]\u001b[A\n",
      " 50%|█████     | 12/24 [00:05<00:05,  2.09it/s]\u001b[A\n",
      " 54%|█████▍    | 13/24 [00:05<00:05,  1.99it/s]\u001b[A\n",
      " 58%|█████▊    | 14/24 [00:06<00:04,  2.09it/s]\u001b[A\n",
      " 62%|██████▎   | 15/24 [00:06<00:04,  2.15it/s]\u001b[A\n",
      " 67%|██████▋   | 16/24 [00:07<00:03,  2.19it/s]\u001b[A\n",
      " 71%|███████   | 17/24 [00:07<00:03,  2.22it/s]\u001b[A\n",
      " 75%|███████▌  | 18/24 [00:08<00:02,  2.18it/s]\u001b[A\n",
      " 79%|███████▉  | 19/24 [00:08<00:02,  2.18it/s]\u001b[A\n",
      " 83%|████████▎ | 20/24 [00:09<00:01,  2.13it/s]\u001b[A\n",
      " 88%|████████▊ | 21/24 [00:09<00:01,  2.15it/s]\u001b[A\n",
      " 92%|█████████▏| 22/24 [00:10<00:00,  2.13it/s]\u001b[A\n",
      " 96%|█████████▌| 23/24 [00:10<00:00,  2.19it/s]\u001b[A\n",
      "100%|██████████| 24/24 [00:10<00:00,  2.23it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:00:18] [0] \t\t #> Saving chunk 0: \t 11,118 passages and 98,298 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:34, 94.38s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1705.69it/s]\n",
      "100%|██████████| 4096/4096 [00:00<00:00, 92308.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:00:19] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 21:00:19] [0] \t\t Found all files!\n",
      "[Feb 07, 21:00:19] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 21:00:19] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 21:00:19] [0] \t\t Sorting codes...\n",
      "[Feb 07, 21:00:19] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 21:00:19] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 21:00:19] #> Building the emb2pid mapping..\n",
      "[Feb 07, 21:00:19] len(emb2pid) = 98298\n",
      "[Feb 07, 21:00:19] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2102_2bits/ivf.pid.pt\n",
      "[Feb 07, 21:00:19] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_2102_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 21:00:19] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 21:00:19] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3903_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/3903_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_3903_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 21:00:22] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:00:23] [0] \t\t # of sampled PIDs = 1452 \t sampled_pids[:3] = [853, 20, 611]\n",
      "[Feb 07, 21:00:23] [0] \t\t #> Encoding 1452 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:10<00:00,  2.10it/s]\n",
      "WARNING clustering 11990 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:00:34] [0] \t\t avg_doclen_est = 8.69214916229248 \t len(local_sample) = 1,452\n",
      "[Feb 07, 21:00:34] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 07, 21:00:34] [0] \t\t *Estimated* 12,621 embeddings.\n",
      "[Feb 07, 21:00:34] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3903_2bits/plan.json ..\n",
      "Clustering 11990 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.03 s, search 0.03 s): objective=2513.27 imbalance=1.586 nsplit=0       \n",
      "[0.03, 0.032, 0.03, 0.033, 0.031, 0.03, 0.03, 0.032, 0.026, 0.031, 0.03, 0.034, 0.029, 0.035, 0.029, 0.035, 0.03, 0.028, 0.028, 0.029, 0.032, 0.033, 0.033, 0.03, 0.03, 0.033, 0.032, 0.034, 0.034, 0.03, 0.03, 0.031, 0.032, 0.027, 0.035, 0.034, 0.03, 0.031, 0.035, 0.03, 0.027, 0.031, 0.033, 0.029, 0.029, 0.032, 0.03, 0.03, 0.033, 0.032, 0.03, 0.031, 0.034, 0.03, 0.03, 0.029, 0.03, 0.028, 0.033, 0.029, 0.031, 0.031, 0.035, 0.037, 0.03, 0.029, 0.027, 0.032, 0.027, 0.028, 0.029, 0.03, 0.032, 0.028, 0.028, 0.032, 0.031, 0.032, 0.031, 0.029, 0.032, 0.028, 0.031, 0.03, 0.031, 0.035, 0.029, 0.034, 0.031, 0.028, 0.033, 0.031, 0.032, 0.026, 0.035, 0.031, 0.028, 0.033, 0.036, 0.029, 0.029, 0.025, 0.027, 0.028, 0.032, 0.03, 0.034, 0.031, 0.033, 0.029, 0.03, 0.032, 0.028, 0.027, 0.03, 0.026, 0.028, 0.033, 0.029, 0.03, 0.035, 0.032, 0.034, 0.034, 0.03, 0.029, 0.033, 0.029]\n",
      "[Feb 07, 21:00:34] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 21:00:34] #> Got bucket_cutoffs = tensor([-0.0181,  0.0001,  0.0191]) and bucket_weights = tensor([-0.0433, -0.0064,  0.0069,  0.0444])\n",
      "[Feb 07, 21:00:34] avg_residual = 0.030739063397049904\n",
      "[Feb 07, 21:00:34] [0] \t\t #> Encoding 1452 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 1/23 [00:00<00:14,  1.49it/s]\u001b[A\n",
      "  9%|▊         | 2/23 [00:01<00:11,  1.82it/s]\u001b[A\n",
      " 13%|█▎        | 3/23 [00:01<00:10,  1.98it/s]\u001b[A\n",
      " 17%|█▋        | 4/23 [00:02<00:09,  2.06it/s]\u001b[A\n",
      " 22%|██▏       | 5/23 [00:02<00:08,  2.11it/s]\u001b[A\n",
      " 26%|██▌       | 6/23 [00:03<00:08,  2.05it/s]\u001b[A\n",
      " 30%|███       | 7/23 [00:03<00:07,  2.03it/s]\u001b[A\n",
      " 35%|███▍      | 8/23 [00:04<00:07,  2.02it/s]\u001b[A\n",
      " 39%|███▉      | 9/23 [00:04<00:06,  2.01it/s]\u001b[A\n",
      " 43%|████▎     | 10/23 [00:05<00:06,  2.01it/s]\u001b[A\n",
      " 48%|████▊     | 11/23 [00:05<00:05,  2.07it/s]\u001b[A\n",
      " 52%|█████▏    | 12/23 [00:05<00:05,  2.06it/s]\u001b[A\n",
      " 57%|█████▋    | 13/23 [00:06<00:04,  2.03it/s]\u001b[A\n",
      " 61%|██████    | 14/23 [00:06<00:04,  2.07it/s]\u001b[A\n",
      " 65%|██████▌   | 15/23 [00:07<00:03,  2.10it/s]\u001b[A\n",
      " 70%|██████▉   | 16/23 [00:07<00:03,  2.04it/s]\u001b[A\n",
      " 74%|███████▍  | 17/23 [00:08<00:03,  1.98it/s]\u001b[A\n",
      " 78%|███████▊  | 18/23 [00:08<00:02,  2.00it/s]\u001b[A\n",
      " 83%|████████▎ | 19/23 [00:09<00:01,  2.04it/s]\u001b[A\n",
      " 87%|████████▋ | 20/23 [00:09<00:01,  2.09it/s]\u001b[A\n",
      " 91%|█████████▏| 21/23 [00:10<00:00,  2.13it/s]\u001b[A\n",
      " 96%|█████████▌| 22/23 [00:10<00:00,  2.15it/s]\u001b[A\n",
      "100%|██████████| 23/23 [00:11<00:00,  2.08it/s]\u001b[A\n",
      "1it [00:11, 11.15s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2322.43it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 138721.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:00:45] [0] \t\t #> Saving chunk 0: \t 1,452 passages and 12,621 embeddings. From #0 onward.\n",
      "[Feb 07, 21:00:45] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 21:00:45] [0] \t\t Found all files!\n",
      "[Feb 07, 21:00:45] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 21:00:45] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 21:00:45] [0] \t\t Sorting codes...\n",
      "[Feb 07, 21:00:45] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 21:00:45] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 21:00:45] #> Building the emb2pid mapping..\n",
      "[Feb 07, 21:00:45] len(emb2pid) = 12621\n",
      "[Feb 07, 21:00:45] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3903_2bits/ivf.pid.pt\n",
      "[Feb 07, 21:00:45] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3903_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 21:00:45] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 21:00:45] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3907_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/3907_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_3907_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 21:00:48] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:00:49] [0] \t\t # of sampled PIDs = 498 \t sampled_pids[:3] = [213, 375, 5]\n",
      "[Feb 07, 21:00:49] [0] \t\t #> Encoding 498 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n",
      "WARNING clustering 4294 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:00:53] [0] \t\t avg_doclen_est = 9.076305389404297 \t len(local_sample) = 498\n",
      "[Feb 07, 21:00:53] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 07, 21:00:53] [0] \t\t *Estimated* 4,520 embeddings.\n",
      "[Feb 07, 21:00:53] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3907_2bits/plan.json ..\n",
      "Clustering 4294 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.01 s, search 0.01 s): objective=412.164 imbalance=1.543 nsplit=0       \n",
      "[0.025, 0.028, 0.025, 0.028, 0.026, 0.026, 0.022, 0.027, 0.021, 0.025, 0.023, 0.032, 0.024, 0.025, 0.028, 0.03, 0.023, 0.025, 0.024, 0.025, 0.023, 0.027, 0.028, 0.028, 0.027, 0.028, 0.029, 0.027, 0.032, 0.025, 0.025, 0.025, 0.026, 0.024, 0.03, 0.026, 0.024, 0.025, 0.03, 0.027, 0.024, 0.023, 0.028, 0.022, 0.025, 0.025, 0.029, 0.025, 0.023, 0.03, 0.024, 0.023, 0.028, 0.027, 0.026, 0.023, 0.027, 0.025, 0.031, 0.026, 0.024, 0.023, 0.032, 0.028, 0.027, 0.025, 0.023, 0.025, 0.026, 0.023, 0.02, 0.027, 0.024, 0.024, 0.021, 0.024, 0.024, 0.028, 0.03, 0.027, 0.026, 0.025, 0.024, 0.028, 0.029, 0.028, 0.025, 0.026, 0.029, 0.02, 0.029, 0.025, 0.028, 0.024, 0.032, 0.023, 0.026, 0.031, 0.026, 0.022, 0.027, 0.025, 0.025, 0.025, 0.028, 0.023, 0.023, 0.027, 0.03, 0.028, 0.026, 0.028, 0.026, 0.023, 0.027, 0.023, 0.023, 0.027, 0.022, 0.027, 0.029, 0.024, 0.024, 0.025, 0.023, 0.023, 0.03, 0.029]\n",
      "[Feb 07, 21:00:53] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 21:00:53] #> Got bucket_cutoffs = tensor([-0.0125,  0.0002,  0.0138]) and bucket_weights = tensor([-0.0341, -0.0044,  0.0048,  0.0366])\n",
      "[Feb 07, 21:00:53] avg_residual = 0.025908371433615685\n",
      "[Feb 07, 21:00:53] [0] \t\t #> Encoding 498 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▎        | 1/8 [00:00<00:03,  2.05it/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:00<00:02,  2.19it/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  2.23it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:01<00:01,  2.25it/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  2.29it/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:02<00:00,  2.32it/s]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:03<00:00,  2.30it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.32it/s]\u001b[A\n",
      "1it [00:03,  3.47s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2026.23it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 156539.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:00:56] [0] \t\t #> Saving chunk 0: \t 498 passages and 4,520 embeddings. From #0 onward.\n",
      "[Feb 07, 21:00:56] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 21:00:56] [0] \t\t Found all files!\n",
      "[Feb 07, 21:00:56] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 21:00:56] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 21:00:56] [0] \t\t Sorting codes...\n",
      "[Feb 07, 21:00:56] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 21:00:56] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 21:00:56] #> Building the emb2pid mapping..\n",
      "[Feb 07, 21:00:56] len(emb2pid) = 4520\n",
      "[Feb 07, 21:00:56] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3907_2bits/ivf.pid.pt\n",
      "[Feb 07, 21:00:56] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_3907_2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Feb 07, 21:00:57] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Feb 07, 21:00:57] #> Creating directory /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_280801_2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 0.0001,\n",
      "    \"maxsteps\": 5387,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/sondors\\/Documents\\/ColBERT_weights\\/triples_X1_13_categories_use_ib_negatives\\/none\\/2024-01\\/26\\/10.49.44\\/checkpoints\\/colbert-5387-finish\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/triples_X1_13_categories_shuffle.json\",\n",
      "    \"collection\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\\/tsv\\/280801_models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT_data\\/13_categories\\/train\\/queries_train_13_categories.tsv\",\n",
      "    \"index_name\": \"models_280801_2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/sondors\\/Documents\\/price\\/ColBERT\\/tutorial\",\n",
      "    \"experiment\": \"colbert-5387\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-02\\/07\\/20.48.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Feb 07, 21:01:00] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:01:00] [0] \t\t # of sampled PIDs = 1709 \t sampled_pids[:3] = [853, 1500, 20]\n",
      "[Feb 07, 21:01:00] [0] \t\t #> Encoding 1709 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:15<00:00,  1.77it/s]\n",
      "WARNING clustering 14954 points to 1024 centroids: please provide at least 39936 training points\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:01:15] [0] \t\t avg_doclen_est = 9.210649490356445 \t len(local_sample) = 1,709\n",
      "[Feb 07, 21:01:15] [0] \t\t Creaing 1,024 partitions.\n",
      "[Feb 07, 21:01:15] [0] \t\t *Estimated* 15,740 embeddings.\n",
      "[Feb 07, 21:01:15] [0] \t\t #> Saving the indexing plan to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_280801_2bits/plan.json ..\n",
      "Clustering 14954 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.04 s, search 0.04 s): objective=3085.4 imbalance=1.547 nsplit=0        \n",
      "[0.032, 0.031, 0.029, 0.032, 0.034, 0.032, 0.031, 0.034, 0.028, 0.032, 0.031, 0.036, 0.032, 0.035, 0.031, 0.036, 0.03, 0.031, 0.028, 0.03, 0.031, 0.034, 0.032, 0.03, 0.03, 0.035, 0.034, 0.037, 0.034, 0.032, 0.03, 0.031, 0.032, 0.031, 0.034, 0.036, 0.029, 0.03, 0.037, 0.029, 0.03, 0.033, 0.036, 0.032, 0.034, 0.032, 0.032, 0.029, 0.032, 0.03, 0.032, 0.031, 0.034, 0.03, 0.035, 0.029, 0.034, 0.029, 0.034, 0.034, 0.03, 0.03, 0.035, 0.038, 0.032, 0.03, 0.029, 0.029, 0.029, 0.03, 0.03, 0.034, 0.034, 0.031, 0.029, 0.03, 0.034, 0.031, 0.035, 0.031, 0.031, 0.029, 0.035, 0.03, 0.031, 0.031, 0.032, 0.033, 0.034, 0.029, 0.034, 0.035, 0.033, 0.028, 0.031, 0.031, 0.029, 0.034, 0.035, 0.028, 0.03, 0.028, 0.031, 0.031, 0.032, 0.032, 0.034, 0.032, 0.033, 0.032, 0.03, 0.031, 0.03, 0.028, 0.03, 0.027, 0.029, 0.031, 0.029, 0.031, 0.036, 0.03, 0.033, 0.035, 0.03, 0.031, 0.033, 0.033]\n",
      "[Feb 07, 21:01:16] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500]) and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750])\n",
      "[Feb 07, 21:01:16] #> Got bucket_cutoffs = tensor([-1.9605e-02, -8.6965e-05,  1.9080e-02]) and bucket_weights = tensor([-0.0460, -0.0070,  0.0067,  0.0448])\n",
      "[Feb 07, 21:01:16] avg_residual = 0.031719207763671875\n",
      "[Feb 07, 21:01:16] [0] \t\t #> Encoding 1709 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 1/27 [00:00<00:15,  1.71it/s]\u001b[A\n",
      "  7%|▋         | 2/27 [00:01<00:14,  1.71it/s]\u001b[A\n",
      " 11%|█         | 3/27 [00:01<00:13,  1.73it/s]\u001b[A\n",
      " 15%|█▍        | 4/27 [00:02<00:13,  1.72it/s]\u001b[A\n",
      " 19%|█▊        | 5/27 [00:02<00:12,  1.71it/s]\u001b[A\n",
      " 22%|██▏       | 6/27 [00:03<00:12,  1.74it/s]\u001b[A\n",
      " 26%|██▌       | 7/27 [00:04<00:11,  1.77it/s]\u001b[A\n",
      " 30%|██▉       | 8/27 [00:04<00:10,  1.77it/s]\u001b[A\n",
      " 33%|███▎      | 9/27 [00:05<00:10,  1.78it/s]\u001b[A\n",
      " 37%|███▋      | 10/27 [00:05<00:09,  1.77it/s]\u001b[A\n",
      " 41%|████      | 11/27 [00:06<00:09,  1.75it/s]\u001b[A\n",
      " 44%|████▍     | 12/27 [00:06<00:08,  1.74it/s]\u001b[A\n",
      " 48%|████▊     | 13/27 [00:07<00:07,  1.75it/s]\u001b[A\n",
      " 52%|█████▏    | 14/27 [00:07<00:07,  1.76it/s]\u001b[A\n",
      " 56%|█████▌    | 15/27 [00:08<00:06,  1.77it/s]\u001b[A\n",
      " 59%|█████▉    | 16/27 [00:09<00:06,  1.77it/s]\u001b[A\n",
      " 63%|██████▎   | 17/27 [00:09<00:05,  1.76it/s]\u001b[A\n",
      " 67%|██████▋   | 18/27 [00:10<00:05,  1.72it/s]\u001b[A\n",
      " 70%|███████   | 19/27 [00:10<00:04,  1.70it/s]\u001b[A\n",
      " 74%|███████▍  | 20/27 [00:11<00:04,  1.67it/s]\u001b[A\n",
      " 78%|███████▊  | 21/27 [00:12<00:03,  1.70it/s]\u001b[A\n",
      " 81%|████████▏ | 22/27 [00:12<00:02,  1.68it/s]\u001b[A\n",
      " 85%|████████▌ | 23/27 [00:13<00:02,  1.64it/s]\u001b[A\n",
      " 89%|████████▉ | 24/27 [00:13<00:01,  1.65it/s]\u001b[A\n",
      " 93%|█████████▎| 25/27 [00:14<00:01,  1.66it/s]\u001b[A\n",
      " 96%|█████████▋| 26/27 [00:15<00:00,  1.67it/s]\u001b[A\n",
      "100%|██████████| 27/27 [00:15<00:00,  1.74it/s]\u001b[A\n",
      "1it [00:15, 15.61s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2295.73it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 137959.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:01:31] [0] \t\t #> Saving chunk 0: \t 1,709 passages and 15,741 embeddings. From #0 onward.\n",
      "[Feb 07, 21:01:31] [0] \t\t #> Checking all files were saved...\n",
      "[Feb 07, 21:01:31] [0] \t\t Found all files!\n",
      "[Feb 07, 21:01:31] [0] \t\t #> Building IVF...\n",
      "[Feb 07, 21:01:31] [0] \t\t #> Loading codes...\n",
      "[Feb 07, 21:01:31] [0] \t\t Sorting codes...\n",
      "[Feb 07, 21:01:31] [0] \t\t Getting unique codes...\n",
      "[Feb 07, 21:01:31] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Feb 07, 21:01:31] #> Building the emb2pid mapping..\n",
      "[Feb 07, 21:01:31] len(emb2pid) = 15741\n",
      "[Feb 07, 21:01:31] #> Saved optimized IVF to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_280801_2bits/ivf.pid.pt\n",
      "[Feb 07, 21:01:31] [0] \t\t #> Saving the indexing metadata to /home/sondors/Documents/price/ColBERT/tutorial/colbert-5387/indexes/models_280801_2bits/metadata.json ..\n",
      "#> Joined...\n"
     ]
    }
   ],
   "source": [
    "for cat_id in id_category.keys():\n",
    "    models_colbert = Collection(path=os.path.join(dst_fld, \"tsv\", f\"{cat_id}_models.tsv\"))\n",
    "    index_name = f'models_{cat_id}_{nbits}bits'\n",
    "    indexer = save_index(ckpt_pth, doc_maxlen, nbits, kmeans_niters, nranks, dst_fld, experiment, models_colbert, index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск матча по индексу\n",
    "\n",
    "Запуск 77к офферов на поиск матча среди 13 категорий или 41к шт моделей занимает 20 мин на CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:01:32] #> Loading collection...\n",
      "0M \n",
      "[Feb 07, 21:01:32] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 07, 21:01:32] #> Loading codec...\n",
      "[Feb 07, 21:01:32] #> Loading IVF...\n",
      "[Feb 07, 21:01:32] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:01:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3032.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:01:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 431.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:01:33] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 07, 21:01:33] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sondors/anaconda3/envs/colbert_cpu/lib/python3.8/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Samsung Планшет Samsung Galaxy Tab S8, 8 ГБ/128 ГБ, Wi-Fi + Cellular, со стилусом, графит (Global), \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 19102,  1194, 29436, 28995, 29753, 15290, 22919, 19102,\n",
      "         9088, 21628,  1055,  2620,  1010,  1022,  1183, 29740,  1013, 11899,\n",
      "         1183, 29740,  1010, 15536,  1011, 10882,  1009, 12562,  1010,  1196,\n",
      "        14150,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 367.22it/s]\n"
     ]
    }
   ],
   "source": [
    "offers = {\n",
    "    0: 'Samsung Планшет Samsung Galaxy Tab S8, 8 ГБ/128 ГБ, Wi-Fi + Cellular, со стилусом, графит (Global)',\n",
    "    1: 'Планшет Samsung Galaxy Tab S8 128GB 5G Silver (SM-X706B)',\n",
    "    2: 'Планшет Samsung Galaxy Tab S8+ 128GB Wi-Fi Pink Gold (SM-X800)'\n",
    "    }\n",
    "\n",
    "src_fld = \"/home/sondors/Documents/price/ColBERT/tutorial\"\n",
    "cat_id = 510401 # планшеты\n",
    "index_name = f'models_{cat_id}_{nbits}bits'\n",
    "models_id_colbert = Collection(path=os.path.join(src_fld, \"tsv\", f\"{cat_id}_models_id.tsv\"))\n",
    "\n",
    "top_n = top_n_similar(offers, src_fld, nranks, experiment, index_name, models_id_colbert, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем выдачу топ N моделей для каждого оффера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung Планшет Samsung Galaxy Tab S8, 8 ГБ/128 ГБ, Wi-Fi + Cellular, со стилусом, графит (Global)\n",
      "\t5144478: Samsung Galaxy Tab S8 --> 25.51\n",
      "\t5144479: Samsung Galaxy Tab S8 Ultra --> 22.29\n",
      "\t3843929: Samsung Galaxy Tab S4 10.5 SM-T835 --> 21.06\n",
      "\t4892891: Samsung Galaxy Tab A8 10.5 128Gb --> 19.64\n",
      "\t623215: Samsung Galaxy Tab S 8.4 SM-T700 --> 19.64\n",
      "____________________________________________________________\n",
      "Планшет Samsung Galaxy Tab S8 128GB 5G Silver (SM-X706B)\n",
      "\t5144478: Samsung Galaxy Tab S8 --> 25.12\n",
      "\t5144479: Samsung Galaxy Tab S8 Ultra --> 21.7\n",
      "\t3843929: Samsung Galaxy Tab S4 10.5 SM-T835 --> 21.3\n",
      "\t1464907: Samsung Galaxy Tab S3 9.7 SM-T820 --> 19.38\n",
      "\t623215: Samsung Galaxy Tab S 8.4 SM-T700 --> 19.34\n",
      "____________________________________________________________\n",
      "Планшет Samsung Galaxy Tab S8+ 128GB Wi-Fi Pink Gold (SM-X800)\n",
      "\t5144477: Samsung Galaxy Tab S8+ --> 23.26\n",
      "\t4509798: Samsung Galaxy Tab S7+ 12.4 128Gb --> 19.52\n",
      "\t5144478: Samsung Galaxy Tab S8 --> 19.51\n",
      "\t623213: Samsung Galaxy Tab S 10.5 SM-T800 --> 19.48\n",
      "\t5144479: Samsung Galaxy Tab S8 Ultra --> 18.19\n",
      "____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top_n)):\n",
    "    print(offers[i])\n",
    "    for j in range(len(top_n[i]['model_ids'])):\n",
    "        id = top_n[i]['model_ids'][j]\n",
    "        sim = top_n[i]['similarity'][j]\n",
    "        model = list(df_models[df_models.model_id == id]['full_name'])[0]\n",
    "        print(f\"\\t{id}: {model} --> {round(float(sim), 2)}\")\n",
    "    print(\"_\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Для эксперимента bert-base-multilingual-cased-2998:\n",
    "\n",
    "Samsung Планшет Samsung Galaxy Tab S8, 8 ГБ/128 ГБ, Wi-Fi + Cellular, со стилусом, графит (Global)\n",
    "\t5144478: Samsung Galaxy Tab S8 --> 28.97\n",
    "\t5144477: Samsung Galaxy Tab S8+ --> 24.97\n",
    "\t937550: Samsung Galaxy Tab S2 9.7 SM-T813 --> 24.0\n",
    "\t5144479: Samsung Galaxy Tab S8 Ultra --> 23.98\n",
    "\t816746: Samsung Galaxy Tab S2 9.7 SM-T810 --> 23.64\n",
    "____________________________________________________________\n",
    "Планшет Samsung Galaxy Tab S8 128GB 5G Silver (SM-X706B)\n",
    "\t5144478: Samsung Galaxy Tab S8 --> 28.15\n",
    "\t5144477: Samsung Galaxy Tab S8+ --> 23.94\n",
    "\t937550: Samsung Galaxy Tab S2 9.7 SM-T813 --> 23.21\n",
    "\t623216: Samsung Galaxy Tab S 8.4 SM-T705 --> 22.82\n",
    "\t816746: Samsung Galaxy Tab S2 9.7 SM-T810 --> 22.65\n",
    "____________________________________________________________\n",
    "Планшет Samsung Galaxy Tab S8+ 128GB Wi-Fi Pink Gold (SM-X800)\n",
    "\t5144477: Samsung Galaxy Tab S8+ --> 26.03\n",
    "\t5144478: Samsung Galaxy Tab S8 --> 20.32\n",
    "\t4509798: Samsung Galaxy Tab S7+ 12.4 128Gb --> 18.63\n",
    "\t937550: Samsung Galaxy Tab S2 9.7 SM-T813 --> 18.35\n",
    "\t5144479: Samsung Galaxy Tab S8 Ultra --> 18.31\n",
    "____________________________________________________________\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_ids': [5144478, 5144479, 3843929, 4892891, 623215],\n",
       "  'similarity': [25.507810592651367,\n",
       "   22.290096282958984,\n",
       "   21.059688568115234,\n",
       "   19.644437789916992,\n",
       "   19.64250946044922]},\n",
       " {'model_ids': [5144478, 5144479, 3843929, 1464907, 623215],\n",
       "  'similarity': [25.12063980102539,\n",
       "   21.704925537109375,\n",
       "   21.299270629882812,\n",
       "   19.382617950439453,\n",
       "   19.33898162841797]},\n",
       " {'model_ids': [5144477, 4509798, 5144478, 623213, 5144479],\n",
       "  'similarity': [23.25652503967285,\n",
       "   19.523971557617188,\n",
       "   19.506370544433594,\n",
       "   19.483131408691406,\n",
       "   18.18914794921875]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
