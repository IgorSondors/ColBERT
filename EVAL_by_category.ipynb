{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert import Indexer, Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2668/2656002276.py:3: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_models = pd.read_csv(pth_models, sep=\";\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Портативная акустика Hoco HC2 Xpress темно-зел...</td>\n",
       "      <td>4771613</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Акустическая система HYUNDAI Колонка порт. H-P...</td>\n",
       "      <td>4570006</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Кухонная мойка из искусственного камня Vigro V...</td>\n",
       "      <td>5769579</td>\n",
       "      <td>кухонные мойки</td>\n",
       "      <td>740101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Хиллс 604304 Puppy Large сух.д/щенков крупных ...</td>\n",
       "      <td>4386018</td>\n",
       "      <td>корм для собак</td>\n",
       "      <td>921401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Смартфон Xiaomi POCO M5 4/128 GB Global, серый</td>\n",
       "      <td>5506115</td>\n",
       "      <td>мобильные телефоны</td>\n",
       "      <td>2801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135891</th>\n",
       "      <td>Кухонная Мойка Zorg X-78-2-44</td>\n",
       "      <td>3601922</td>\n",
       "      <td>кухонные мойки</td>\n",
       "      <td>740101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135892</th>\n",
       "      <td>Balenciaga, Cristobal Pour Homme, 100 мл., туа...</td>\n",
       "      <td>3081853</td>\n",
       "      <td>парфюмерия</td>\n",
       "      <td>911906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135893</th>\n",
       "      <td>Умная колонка MAIL Капсула, белый [mrc01(white)]</td>\n",
       "      <td>4855069</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135894</th>\n",
       "      <td>Наушники беспроводные JBL Tune 750BTNC черные ...</td>\n",
       "      <td>4455835</td>\n",
       "      <td>наушники, гарнитуры, наушники c микрофоном</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135895</th>\n",
       "      <td>Кухонная мойка Granula GR-7804 Арктик</td>\n",
       "      <td>3601738</td>\n",
       "      <td>кухонные мойки</td>\n",
       "      <td>740101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135896 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  model_id   \n",
       "0       Портативная акустика Hoco HC2 Xpress темно-зел...   4771613  \\\n",
       "1       Акустическая система HYUNDAI Колонка порт. H-P...   4570006   \n",
       "2       Кухонная мойка из искусственного камня Vigro V...   5769579   \n",
       "3       Хиллс 604304 Puppy Large сух.д/щенков крупных ...   4386018   \n",
       "4          Смартфон Xiaomi POCO M5 4/128 GB Global, серый   5506115   \n",
       "...                                                   ...       ...   \n",
       "135891                      Кухонная Мойка Zorg X-78-2-44   3601922   \n",
       "135892  Balenciaga, Cristobal Pour Homme, 100 мл., туа...   3081853   \n",
       "135893   Умная колонка MAIL Капсула, белый [mrc01(white)]   4855069   \n",
       "135894  Наушники беспроводные JBL Tune 750BTNC черные ...   4455835   \n",
       "135895              Кухонная мойка Granula GR-7804 Арктик   3601738   \n",
       "\n",
       "                                     category_name  category_id  \n",
       "0                             портативная акустика         3904  \n",
       "1                             портативная акустика         3904  \n",
       "2                                   кухонные мойки       740101  \n",
       "3                                   корм для собак       921401  \n",
       "4                               мобильные телефоны         2801  \n",
       "...                                            ...          ...  \n",
       "135891                              кухонные мойки       740101  \n",
       "135892                                  парфюмерия       911906  \n",
       "135893                        портативная акустика         3904  \n",
       "135894  наушники, гарнитуры, наушники c микрофоном         2102  \n",
       "135895                              кухонные мойки       740101  \n",
       "\n",
       "[135896 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_df(pth_models, pth_offers):\n",
    "\n",
    "    df_models = pd.read_csv(pth_models, sep=\";\")\n",
    "    df_models = df_models.drop(columns=['average_price', 'comment'])\n",
    "    df_offers = pd.read_csv(pth_offers, sep=\";\")\n",
    "    df_offers = df_offers.drop(columns=['true_match', 'false_match'])\n",
    "\n",
    "    return df_models, df_offers\n",
    "\n",
    "pth_models = \"/mnt/vdb1/Datasets/ColBERT/18_categories/test/models_18_categories.csv\"\n",
    "pth_offers = \"/mnt/vdb1/Datasets/ColBERT/18_categories/test/triplets_test_18_categories.csv\"\n",
    "\n",
    "df_models, df_offers = read_df(pth_models, pth_offers)\n",
    "\n",
    "df_offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95201</th>\n",
       "      <td>Honor Беспроводные наушники Choice CE79 TWS Ea...</td>\n",
       "      <td>4564207</td>\n",
       "      <td>наушники, гарнитуры, наушники c микрофоном</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85579</th>\n",
       "      <td>Наушники беспроводные SMARTBUY SBH-001 I7 TWS ...</td>\n",
       "      <td>4533334</td>\n",
       "      <td>наушники, гарнитуры, наушники c микрофоном</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63579</th>\n",
       "      <td>Студийные наушники BEHRINGER HC 2000B</td>\n",
       "      <td>4731639</td>\n",
       "      <td>наушники, гарнитуры, наушники c микрофоном</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65798</th>\n",
       "      <td>Беспроводные наушники Edifier W600BT (Grey)</td>\n",
       "      <td>4783655</td>\n",
       "      <td>наушники, гарнитуры, наушники c микрофоном</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78081</th>\n",
       "      <td>Беспроводные наушники TWS i18, white (белый)</td>\n",
       "      <td>4802467</td>\n",
       "      <td>наушники, гарнитуры, наушники c микрофоном</td>\n",
       "      <td>2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117851</th>\n",
       "      <td>FRAIS CLASSIQUE ADULT DOG BEEF (сухой корм для...</td>\n",
       "      <td>4882472</td>\n",
       "      <td>корм для собак</td>\n",
       "      <td>921401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48513</th>\n",
       "      <td>Сухой корм для собак Nature's Table , индейка,...</td>\n",
       "      <td>4900326</td>\n",
       "      <td>корм для собак</td>\n",
       "      <td>921401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19529</th>\n",
       "      <td>Корм сухой для собак Корм сухой Chicopee Pro N...</td>\n",
       "      <td>6277381</td>\n",
       "      <td>корм для собак</td>\n",
       "      <td>921401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9078</th>\n",
       "      <td>Сухой корм для щенков Meglium курица 1 шт. х 1...</td>\n",
       "      <td>4388423</td>\n",
       "      <td>корм для собак</td>\n",
       "      <td>921401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98386</th>\n",
       "      <td>Корм сухой для собак Forza10 Maxi Diet сухой к...</td>\n",
       "      <td>4823283</td>\n",
       "      <td>корм для собак</td>\n",
       "      <td>921401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  model_id   \n",
       "95201   Honor Беспроводные наушники Choice CE79 TWS Ea...   4564207  \\\n",
       "85579   Наушники беспроводные SMARTBUY SBH-001 I7 TWS ...   4533334   \n",
       "63579               Студийные наушники BEHRINGER HC 2000B   4731639   \n",
       "65798         Беспроводные наушники Edifier W600BT (Grey)   4783655   \n",
       "78081        Беспроводные наушники TWS i18, white (белый)   4802467   \n",
       "...                                                   ...       ...   \n",
       "117851  FRAIS CLASSIQUE ADULT DOG BEEF (сухой корм для...   4882472   \n",
       "48513   Сухой корм для собак Nature's Table , индейка,...   4900326   \n",
       "19529   Корм сухой для собак Корм сухой Chicopee Pro N...   6277381   \n",
       "9078    Сухой корм для щенков Meglium курица 1 шт. х 1...   4388423   \n",
       "98386   Корм сухой для собак Forza10 Maxi Diet сухой к...   4823283   \n",
       "\n",
       "                                     category_name  category_id  \n",
       "95201   наушники, гарнитуры, наушники c микрофоном         2102  \n",
       "85579   наушники, гарнитуры, наушники c микрофоном         2102  \n",
       "63579   наушники, гарнитуры, наушники c микрофоном         2102  \n",
       "65798   наушники, гарнитуры, наушники c микрофоном         2102  \n",
       "78081   наушники, гарнитуры, наушники c микрофоном         2102  \n",
       "...                                            ...          ...  \n",
       "117851                              корм для собак       921401  \n",
       "48513                               корм для собак       921401  \n",
       "19529                               корм для собак       921401  \n",
       "9078                                корм для собак       921401  \n",
       "98386                               корм для собак       921401  \n",
       "\n",
       "[170 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ans = [y for x, y in df_offers.groupby('category_id')]\n",
    "# thresh_upper = 10\n",
    "# for i in range(len(ans)):\n",
    "#     #ans[i] = ans[i].drop_duplicates(subset='name', keep=\"last\")\n",
    "#     ans[i] = ans[i].sample(frac=1).sample(frac=1)[:thresh_upper]\n",
    "# df_new = pd.concat(ans, axis=0)\n",
    "# df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623742</td>\n",
       "      <td>920-005619</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>Logitech 920-005619</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>721952</td>\n",
       "      <td>Zipper Bag</td>\n",
       "      <td>Hama</td>\n",
       "      <td>Hama Zipper Bag</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>721970</td>\n",
       "      <td>CC-3064</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>Nokia CC-3064</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751488</td>\n",
       "      <td>CKS-X7/R</td>\n",
       "      <td>Sony</td>\n",
       "      <td>Sony CKS-X7/R</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>751989</td>\n",
       "      <td>EP-031023</td>\n",
       "      <td>Era Pro</td>\n",
       "      <td>Era Pro EP-031023</td>\n",
       "      <td>чехлы, обложки для гаджетов (телефонов, планше...</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103209</th>\n",
       "      <td>7049424</td>\n",
       "      <td>MD-108</td>\n",
       "      <td>Mivo</td>\n",
       "      <td>Mivo MD-108</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103210</th>\n",
       "      <td>7049425</td>\n",
       "      <td>MD-165</td>\n",
       "      <td>Mivo</td>\n",
       "      <td>Mivo MD-165</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103211</th>\n",
       "      <td>7049426</td>\n",
       "      <td>Boost 20W</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Rocket Boost 20W</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103212</th>\n",
       "      <td>7049427</td>\n",
       "      <td>Motion 10W</td>\n",
       "      <td>Rocket</td>\n",
       "      <td>Rocket Motion 10W</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103213</th>\n",
       "      <td>7049428</td>\n",
       "      <td>Z1</td>\n",
       "      <td>SmartBuy</td>\n",
       "      <td>SmartBuy Z1</td>\n",
       "      <td>портативная акустика</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_id        name brand_name            full_name   \n",
       "0         623742  920-005619   Logitech  Logitech 920-005619  \\\n",
       "1         721952  Zipper Bag       Hama      Hama Zipper Bag   \n",
       "2         721970     CC-3064      Nokia        Nokia CC-3064   \n",
       "3         751488    CKS-X7/R       Sony        Sony CKS-X7/R   \n",
       "4         751989   EP-031023    Era Pro    Era Pro EP-031023   \n",
       "...          ...         ...        ...                  ...   \n",
       "103209   7049424      MD-108       Mivo          Mivo MD-108   \n",
       "103210   7049425      MD-165       Mivo          Mivo MD-165   \n",
       "103211   7049426   Boost 20W     Rocket     Rocket Boost 20W   \n",
       "103212   7049427  Motion 10W     Rocket    Rocket Motion 10W   \n",
       "103213   7049428          Z1   SmartBuy          SmartBuy Z1   \n",
       "\n",
       "                                            category_name  category_id  \n",
       "0       чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "1       чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "2       чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "3       чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "4       чехлы, обложки для гаджетов (телефонов, планше...         3994  \n",
       "...                                                   ...          ...  \n",
       "103209                               портативная акустика         3904  \n",
       "103210                               портативная акустика         3904  \n",
       "103211                               портативная акустика         3904  \n",
       "103212                               портативная акустика         3904  \n",
       "103213                               портативная акустика         3904  \n",
       "\n",
       "[103214 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "диктофоны, портативные рекордеры\n",
      "[Jan 11, 16:26:23] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:26:23] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:26:23] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:26:23] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:26:23] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:26:51] [0] \t\t # of sampled PIDs = 488 \t sampled_pids[:3] = [213, 375, 5]\n",
      "[Jan 11, 16:26:51] [0] \t\t #> Encoding 488 passages..\n",
      "[Jan 11, 16:26:52] [0] \t\t avg_doclen_est = 9.829917907714844 \t len(local_sample) = 488\n",
      "[Jan 11, 16:26:52] [0] \t\t Creaing 1,024 partitions.\n",
      "[Jan 11, 16:26:52] [0] \t\t *Estimated* 4,796 embeddings.\n",
      "[Jan 11, 16:26:52] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 4558 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.00 s, search 0.00 s): objective=446.968 imbalance=1.515 nsplit=0       \n",
      "[Jan 11, 16:26:52] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 4558 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:26:52] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.027, 0.03, 0.025, 0.026, 0.023, 0.027, 0.021, 0.023, 0.027, 0.023, 0.022, 0.026, 0.025, 0.027, 0.022, 0.024, 0.025, 0.024, 0.021, 0.027, 0.024, 0.024, 0.027, 0.029, 0.023, 0.024, 0.023, 0.026, 0.024, 0.024, 0.024, 0.023, 0.022, 0.026, 0.029, 0.022, 0.027, 0.029, 0.028, 0.03, 0.023, 0.027, 0.023, 0.025, 0.025, 0.027, 0.026, 0.028, 0.023, 0.026, 0.029, 0.029, 0.024, 0.027, 0.025, 0.024, 0.023, 0.026, 0.027, 0.024, 0.026, 0.021, 0.025, 0.026, 0.024, 0.024, 0.025, 0.025, 0.024, 0.029, 0.023, 0.024, 0.029, 0.028, 0.03, 0.026, 0.023, 0.025, 0.028, 0.025, 0.028, 0.023, 0.027, 0.024, 0.026, 0.023, 0.029, 0.025, 0.029, 0.022, 0.019, 0.023, 0.023, 0.021, 0.024, 0.027, 0.023, 0.025, 0.025, 0.025, 0.024, 0.02, 0.021, 0.029, 0.029, 0.024, 0.026, 0.025, 0.027, 0.026, 0.025, 0.026, 0.024, 0.023, 0.023, 0.023, 0.027, 0.031, 0.025, 0.026, 0.028, 0.025, 0.028, 0.026, 0.023, 0.025, 0.026, 0.023]\n",
      "[Jan 11, 16:26:53] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:26:53] #> Got bucket_cutoffs = tensor([-0.0154,  0.0000,  0.0146], device='cuda:0') and bucket_weights = tensor([-0.0352, -0.0057,  0.0057,  0.0346], device='cuda:0')\n",
      "[Jan 11, 16:26:53] avg_residual = 0.02520751953125\n",
      "[Jan 11, 16:26:53] [0] \t\t #> Encoding 488 passages..\n",
      "[Jan 11, 16:26:53] [0] \t\t #> Saving chunk 0: \t 488 passages and 4,797 embeddings. From #0 onward.\n",
      "[Jan 11, 16:26:53] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:26:53] [0] \t\t Found all files!\n",
      "[Jan 11, 16:26:53] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:26:53] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:26:53] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:26:53] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:26:53] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:26:53] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:26:53] len(emb2pid) = 4797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1804.00it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 93948.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:26:53] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:26:53] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Jan 11, 16:26:54] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:26:57] #> Loading codec...\n",
      "[Jan 11, 16:26:57] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 16:26:58] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 16:26:58] #> Loading IVF...\n",
      "[Jan 11, 16:26:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4911.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:26:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 662.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Рекордер Zoom H6 Black H6/BLK, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1195, 15290, 23925, 14150, 16856, 29742, 15290, 16856,\n",
      "        24095,  1044,  2575,  2304,  1044,  2575,  1013,  1038, 13687,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:00, 134.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 1.1053271293640137\n",
      "\n",
      "электронные книги\n",
      "[Jan 11, 16:26:59] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:26:59] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:26:59] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:26:59] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:26:59] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:27:26] [0] \t\t # of sampled PIDs = 680 \t sampled_pids[:3] = [426, 10, 305]\n",
      "[Jan 11, 16:27:26] [0] \t\t #> Encoding 680 passages..\n",
      "[Jan 11, 16:27:27] [0] \t\t avg_doclen_est = 9.06323528289795 \t len(local_sample) = 680\n",
      "[Jan 11, 16:27:27] [0] \t\t Creaing 1,024 partitions.\n",
      "[Jan 11, 16:27:27] [0] \t\t *Estimated* 6,162 embeddings.\n",
      "[Jan 11, 16:27:27] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 5855 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.01 s, search 0.00 s): objective=841.082 imbalance=1.628 nsplit=0       \n",
      "[Jan 11, 16:27:28] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 5855 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:27:28] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.031, 0.035, 0.03, 0.03, 0.028, 0.028, 0.028, 0.029, 0.027, 0.028, 0.026, 0.031, 0.029, 0.032, 0.028, 0.027, 0.026, 0.027, 0.025, 0.031, 0.029, 0.031, 0.028, 0.031, 0.03, 0.033, 0.031, 0.032, 0.031, 0.029, 0.03, 0.029, 0.027, 0.029, 0.032, 0.025, 0.032, 0.033, 0.03, 0.034, 0.023, 0.028, 0.028, 0.026, 0.03, 0.028, 0.027, 0.033, 0.029, 0.029, 0.029, 0.031, 0.028, 0.03, 0.03, 0.028, 0.027, 0.026, 0.031, 0.028, 0.032, 0.028, 0.027, 0.031, 0.032, 0.028, 0.028, 0.029, 0.031, 0.027, 0.028, 0.033, 0.031, 0.028, 0.026, 0.03, 0.03, 0.028, 0.026, 0.027, 0.028, 0.03, 0.031, 0.031, 0.026, 0.03, 0.029, 0.024, 0.029, 0.028, 0.026, 0.03, 0.024, 0.028, 0.032, 0.031, 0.03, 0.028, 0.03, 0.028, 0.026, 0.027, 0.027, 0.028, 0.027, 0.031, 0.029, 0.027, 0.029, 0.028, 0.029, 0.029, 0.029, 0.026, 0.029, 0.029, 0.027, 0.027, 0.029, 0.027, 0.032, 0.027, 0.031, 0.033, 0.027, 0.028, 0.032, 0.024]\n",
      "[Jan 11, 16:27:28] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:27:28] #> Got bucket_cutoffs = tensor([-0.0170,  0.0003,  0.0178], device='cuda:0') and bucket_weights = tensor([-0.0393, -0.0064,  0.0072,  0.0402], device='cuda:0')\n",
      "[Jan 11, 16:27:28] avg_residual = 0.028900146484375\n",
      "[Jan 11, 16:27:28] [0] \t\t #> Encoding 680 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:27:29] [0] \t\t #> Saving chunk 0: \t 680 passages and 6,163 embeddings. From #0 onward.\n",
      "[Jan 11, 16:27:29] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:27:29] [0] \t\t Found all files!\n",
      "[Jan 11, 16:27:29] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:27:29] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:27:29] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:27:29] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:27:29] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:27:29] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:27:29] len(emb2pid) = 6163\n",
      "[Jan 11, 16:27:29] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:27:29] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1844.46it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 103835.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:27:30] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:27:31] #> Loading codec...\n",
      "[Jan 11, 16:27:31] #> Loading IVF...\n",
      "[Jan 11, 16:27:31] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1640.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:27:31] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 726.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . PocketBook 630 Fashion, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  4979,  8654, 23609,  4827,   102,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 130.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.15163588523864746\n",
      "\n",
      "автомобильные телевизоры, мониторы\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:27:32] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:27:32] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:27:32] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:27:32] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:27:32] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:27:59] [0] \t\t # of sampled PIDs = 790 \t sampled_pids[:3] = [426, 750, 10]\n",
      "[Jan 11, 16:27:59] [0] \t\t #> Encoding 790 passages..\n",
      "[Jan 11, 16:28:00] [0] \t\t avg_doclen_est = 9.386075973510742 \t len(local_sample) = 790\n",
      "[Jan 11, 16:28:00] [0] \t\t Creaing 1,024 partitions.\n",
      "[Jan 11, 16:28:00] [0] \t\t *Estimated* 7,415 embeddings.\n",
      "[Jan 11, 16:28:00] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 7045 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.01 s, search 0.00 s): objective=998.474 imbalance=1.558 nsplit=0       \n",
      "[Jan 11, 16:28:00] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 7045 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:28:01] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.029, 0.031, 0.029, 0.029, 0.027, 0.029, 0.026, 0.023, 0.026, 0.03, 0.027, 0.026, 0.027, 0.029, 0.026, 0.027, 0.024, 0.026, 0.025, 0.028, 0.028, 0.026, 0.029, 0.029, 0.027, 0.026, 0.027, 0.027, 0.027, 0.028, 0.026, 0.028, 0.027, 0.029, 0.027, 0.025, 0.028, 0.03, 0.028, 0.033, 0.027, 0.028, 0.027, 0.027, 0.029, 0.023, 0.027, 0.028, 0.028, 0.029, 0.031, 0.028, 0.03, 0.029, 0.028, 0.027, 0.026, 0.026, 0.027, 0.024, 0.031, 0.028, 0.028, 0.034, 0.029, 0.027, 0.028, 0.027, 0.03, 0.028, 0.027, 0.028, 0.031, 0.028, 0.028, 0.027, 0.027, 0.03, 0.029, 0.031, 0.028, 0.029, 0.029, 0.027, 0.025, 0.025, 0.029, 0.026, 0.027, 0.024, 0.023, 0.03, 0.025, 0.029, 0.028, 0.032, 0.026, 0.027, 0.027, 0.024, 0.026, 0.026, 0.023, 0.026, 0.027, 0.03, 0.031, 0.029, 0.026, 0.029, 0.029, 0.026, 0.027, 0.027, 0.025, 0.026, 0.029, 0.026, 0.026, 0.026, 0.028, 0.026, 0.029, 0.029, 0.025, 0.027, 0.028, 0.025]\n",
      "[Jan 11, 16:28:01] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:28:01] #> Got bucket_cutoffs = tensor([-1.7429e-02, -9.1553e-05,  1.7273e-02], device='cuda:0') and bucket_weights = tensor([-0.0380, -0.0071,  0.0071,  0.0374], device='cuda:0')\n",
      "[Jan 11, 16:28:01] avg_residual = 0.0274810791015625\n",
      "[Jan 11, 16:28:01] [0] \t\t #> Encoding 790 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:28:01] [0] \t\t #> Saving chunk 0: \t 790 passages and 7,415 embeddings. From #0 onward.\n",
      "[Jan 11, 16:28:01] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:28:01] [0] \t\t Found all files!\n",
      "[Jan 11, 16:28:01] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:28:01] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:28:01] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:28:01] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:28:01] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:28:01] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:28:01] len(emb2pid) = 7415\n",
      "[Jan 11, 16:28:01] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:28:01] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1790.91it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 97933.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:28:02] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:28:04] #> Loading codec...\n",
      "[Jan 11, 16:28:04] #> Loading IVF...\n",
      "[Jan 11, 16:28:04] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1394.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:28:04] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 441.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Навесной монитор ERGO ER11AN (Android 9), \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1192, 10260, 25529, 15290, 29747, 18947, 14150, 10325,\n",
      "         1191, 14150, 18947, 10325, 22919, 14150, 16856,  9413,  3995,  9413,\n",
      "        14526,  2319,  1006, 11924,  1023,  1007,   102,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 134.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.1385805606842041\n",
      "\n",
      "смарт-часы и браслеты\n",
      "[Jan 11, 16:28:04] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:28:04] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:28:04] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:28:04] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:28:04] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:28:32] [0] \t\t # of sampled PIDs = 2577 \t sampled_pids[:3] = [1706, 41, 1223]\n",
      "[Jan 11, 16:28:32] [0] \t\t #> Encoding 2577 passages..\n",
      "[Jan 11, 16:28:33] [0] \t\t avg_doclen_est = 9.804036140441895 \t len(local_sample) = 2,577\n",
      "[Jan 11, 16:28:33] [0] \t\t Creaing 2,048 partitions.\n",
      "[Jan 11, 16:28:33] [0] \t\t *Estimated* 25,265 embeddings.\n",
      "[Jan 11, 16:28:33] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 24002 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 24002 points in 128D to 2048 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.02 s, search 0.01 s): objective=3859.97 imbalance=1.593 nsplit=0       \n",
      "[Jan 11, 16:28:34] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 16:28:34] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.03, 0.032, 0.031, 0.029, 0.027, 0.03, 0.027, 0.027, 0.025, 0.03, 0.028, 0.029, 0.028, 0.033, 0.029, 0.03, 0.028, 0.03, 0.027, 0.029, 0.028, 0.029, 0.028, 0.03, 0.03, 0.029, 0.03, 0.029, 0.03, 0.031, 0.028, 0.03, 0.029, 0.028, 0.032, 0.027, 0.029, 0.03, 0.03, 0.029, 0.027, 0.028, 0.032, 0.028, 0.029, 0.028, 0.028, 0.03, 0.029, 0.03, 0.031, 0.031, 0.03, 0.032, 0.031, 0.029, 0.031, 0.03, 0.03, 0.028, 0.027, 0.029, 0.028, 0.031, 0.029, 0.029, 0.028, 0.031, 0.028, 0.029, 0.029, 0.03, 0.032, 0.028, 0.029, 0.03, 0.027, 0.031, 0.029, 0.03, 0.028, 0.028, 0.031, 0.028, 0.027, 0.028, 0.031, 0.028, 0.03, 0.027, 0.029, 0.028, 0.028, 0.027, 0.031, 0.032, 0.027, 0.029, 0.028, 0.029, 0.028, 0.027, 0.026, 0.03, 0.031, 0.029, 0.03, 0.027, 0.028, 0.028, 0.03, 0.026, 0.029, 0.029, 0.029, 0.025, 0.028, 0.03, 0.029, 0.03, 0.031, 0.025, 0.029, 0.03, 0.026, 0.029, 0.029, 0.027]\n",
      "[Jan 11, 16:28:35] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:28:35] #> Got bucket_cutoffs = tensor([-0.0187,  0.0000,  0.0187], device='cuda:0') and bucket_weights = tensor([-0.0394, -0.0078,  0.0078,  0.0396], device='cuda:0')\n",
      "[Jan 11, 16:28:35] avg_residual = 0.0289459228515625\n",
      "[Jan 11, 16:28:35] [0] \t\t #> Encoding 2577 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:28:36] [0] \t\t #> Saving chunk 0: \t 2,577 passages and 25,265 embeddings. From #0 onward.\n",
      "[Jan 11, 16:28:36] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:28:36] [0] \t\t Found all files!\n",
      "[Jan 11, 16:28:36] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:28:36] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:28:36] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:28:36] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:28:36] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:28:36] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:28:36] len(emb2pid) = 25265\n",
      "[Jan 11, 16:28:36] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:28:36] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1567.96it/s]\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 88739.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:28:37] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:28:38] #> Loading codec...\n",
      "[Jan 11, 16:28:38] #> Loading IVF...\n",
      "[Jan 11, 16:28:38] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3809.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:28:38] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 558.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Умные часы Ginzzu GZ-501 Pink, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1198, 29745, 18947, 29113, 15290,  1202, 10260, 29747,\n",
      "        29113, 18353, 13213,  2226,  1043,  2480,  1011, 16202,  5061,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 98.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.19153738021850586\n",
      "\n",
      "портативные медиаплееры\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:28:39] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:28:39] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:28:39] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:28:39] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:28:39] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:29:06] [0] \t\t # of sampled PIDs = 847 \t sampled_pids[:3] = [426, 750, 10]\n",
      "[Jan 11, 16:29:06] [0] \t\t #> Encoding 847 passages..\n",
      "[Jan 11, 16:29:07] [0] \t\t avg_doclen_est = 9.46753215789795 \t len(local_sample) = 847\n",
      "[Jan 11, 16:29:07] [0] \t\t Creaing 1,024 partitions.\n",
      "[Jan 11, 16:29:07] [0] \t\t *Estimated* 8,018 embeddings.\n",
      "[Jan 11, 16:29:07] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 7619 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 7619 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.01 s, search 0.00 s): objective=1221.25 imbalance=1.622 nsplit=0       \n",
      "[Jan 11, 16:29:08] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 16:29:08] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.03, 0.035, 0.029, 0.034, 0.027, 0.032, 0.029, 0.028, 0.03, 0.033, 0.029, 0.029, 0.031, 0.034, 0.029, 0.029, 0.027, 0.029, 0.027, 0.032, 0.029, 0.03, 0.034, 0.035, 0.027, 0.029, 0.031, 0.032, 0.03, 0.029, 0.032, 0.032, 0.033, 0.03, 0.031, 0.033, 0.028, 0.031, 0.031, 0.032, 0.025, 0.033, 0.03, 0.032, 0.03, 0.031, 0.033, 0.032, 0.033, 0.03, 0.032, 0.03, 0.031, 0.03, 0.032, 0.032, 0.027, 0.03, 0.031, 0.029, 0.03, 0.03, 0.03, 0.032, 0.032, 0.03, 0.031, 0.032, 0.031, 0.036, 0.029, 0.031, 0.03, 0.033, 0.031, 0.032, 0.028, 0.032, 0.03, 0.031, 0.031, 0.03, 0.033, 0.032, 0.028, 0.029, 0.03, 0.031, 0.031, 0.027, 0.026, 0.031, 0.027, 0.029, 0.028, 0.032, 0.029, 0.031, 0.028, 0.028, 0.03, 0.027, 0.026, 0.032, 0.029, 0.027, 0.032, 0.028, 0.03, 0.03, 0.029, 0.03, 0.027, 0.027, 0.029, 0.027, 0.031, 0.032, 0.031, 0.03, 0.031, 0.03, 0.029, 0.03, 0.028, 0.028, 0.029, 0.031]\n",
      "[Jan 11, 16:29:09] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:29:09] #> Got bucket_cutoffs = tensor([-1.8799e-02, -6.1035e-05,  1.9226e-02], device='cuda:0') and bucket_weights = tensor([-0.0420, -0.0074,  0.0074,  0.0424], device='cuda:0')\n",
      "[Jan 11, 16:29:09] avg_residual = 0.0301971435546875\n",
      "[Jan 11, 16:29:09] [0] \t\t #> Encoding 847 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:29:09] [0] \t\t #> Saving chunk 0: \t 847 passages and 8,019 embeddings. From #0 onward.\n",
      "[Jan 11, 16:29:09] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:29:09] [0] \t\t Found all files!\n",
      "[Jan 11, 16:29:09] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:29:09] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:29:09] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:29:09] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:29:09] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:29:09] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:29:09] len(emb2pid) = 8019\n",
      "[Jan 11, 16:29:09] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:29:09] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1889.33it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 93525.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:29:10] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:29:12] #> Loading codec...\n",
      "[Jan 11, 16:29:12] #> Loading IVF...\n",
      "[Jan 11, 16:29:12] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1906.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:29:12] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 720.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Apple iPod Shuffle 4th 2gb Slate New MD779RP/A, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  6207, 26322, 23046,  4343,  1016, 18259, 12796,  2047,\n",
      "         9108,  2581,  2581,  2683, 14536,  1013,  1037,   102,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 113.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.15857291221618652\n",
      "\n",
      "чехлы, обложки для гаджетов (телефонов, планшетов etc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:29:12] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:29:12] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:29:12] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:29:12] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:29:12] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:29:40] [0] \t\t # of sampled PIDs = 33735 \t sampled_pids[:3] = [27303, 666, 19571]\n",
      "[Jan 11, 16:29:40] [0] \t\t #> Encoding 33735 passages..\n",
      "[Jan 11, 16:30:05] [0] \t\t avg_doclen_est = 34.45175552368164 \t len(local_sample) = 33,735\n",
      "[Jan 11, 16:30:06] [0] \t\t Creaing 16,384 partitions.\n",
      "[Jan 11, 16:30:06] [0] \t\t *Estimated* 1,276,265 embeddings.\n",
      "[Jan 11, 16:30:06] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 1112230 points in 128D to 16384 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.16 s\n",
      "  Iteration 3 (2.35 s, search 2.11 s): objective=133938 imbalance=1.582 nsplit=0       \n",
      "[Jan 11, 16:30:10] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 16:30:10] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.022, 0.022, 0.021, 0.023, 0.022, 0.023, 0.021, 0.021, 0.02, 0.022, 0.021, 0.022, 0.021, 0.021, 0.021, 0.021, 0.021, 0.022, 0.022, 0.021, 0.022, 0.022, 0.022, 0.023, 0.022, 0.02, 0.024, 0.022, 0.023, 0.022, 0.021, 0.023, 0.021, 0.021, 0.022, 0.022, 0.023, 0.022, 0.023, 0.022, 0.022, 0.022, 0.023, 0.021, 0.022, 0.022, 0.022, 0.023, 0.022, 0.022, 0.022, 0.021, 0.021, 0.023, 0.024, 0.022, 0.022, 0.022, 0.023, 0.021, 0.021, 0.02, 0.022, 0.024, 0.024, 0.022, 0.021, 0.021, 0.021, 0.023, 0.022, 0.022, 0.022, 0.021, 0.021, 0.022, 0.021, 0.022, 0.021, 0.022, 0.022, 0.021, 0.021, 0.021, 0.02, 0.023, 0.022, 0.021, 0.021, 0.021, 0.021, 0.023, 0.021, 0.021, 0.02, 0.022, 0.021, 0.022, 0.022, 0.022, 0.02, 0.021, 0.021, 0.021, 0.021, 0.022, 0.023, 0.022, 0.023, 0.022, 0.022, 0.021, 0.022, 0.021, 0.022, 0.019, 0.021, 0.022, 0.023, 0.021, 0.022, 0.021, 0.022, 0.022, 0.019, 0.022, 0.022, 0.021]\n",
      "[Jan 11, 16:30:10] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:30:10] #> Got bucket_cutoffs = tensor([-0.0137,  0.0001,  0.0141], device='cuda:0') and bucket_weights = tensor([-0.0291, -0.0056,  0.0059,  0.0300], device='cuda:0')\n",
      "[Jan 11, 16:30:10] avg_residual = 0.021728515625\n",
      "[Jan 11, 16:30:10] [0] \t\t #> Encoding 25000 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:30:28] [0] \t\t #> Saving chunk 0: \t 25,000 passages and 842,718 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:17, 17.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:30:28] [0] \t\t #> Encoding 12045 passages..\n",
      "[Jan 11, 16:30:37] [0] \t\t #> Saving chunk 1: \t 12,045 passages and 433,758 embeddings. From #25,000 onward.\n",
      "[Jan 11, 16:30:37] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:30:37] [0] \t\t Found all files!\n",
      "[Jan 11, 16:30:37] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:30:37] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:30:37] [0] \t\t Sorting codes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:27, 13.52s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00, 737.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:30:38] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:30:38] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:30:38] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:30:38] len(emb2pid) = 1276476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [00:00<00:00, 48355.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:30:38] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:30:38] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Jan 11, 16:30:39] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:30:41] #> Loading codec...\n",
      "[Jan 11, 16:30:41] #> Loading IVF...\n",
      "[Jan 11, 16:30:41] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1003.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:30:41] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 78.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Аксессуар Чехол for PocketBook 614/615/624/625/626/640 Snoogy Cloth Grey SN-PB6X-GR-OXF, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1180, 23925, 29747, 15290, 29747, 29747, 29748, 10260,\n",
      "        16856,  1202, 15290, 29750, 14150, 29436,  2005,  4979,  8654,  6079,\n",
      "         2549,  1013,  6079,  2629,  1013,  5786,  2549,  1013, 22810,  1013,\n",
      "         5786,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 116.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.17845416069030762\n",
      "\n",
      "портативная акустика\n",
      "[Jan 11, 16:30:41] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:30:41] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:30:41] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:30:41] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:30:41] #> Will delete 14 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:31:08] [0] \t\t # of sampled PIDs = 7399 \t sampled_pids[:3] = [3412, 6002, 83]\n",
      "[Jan 11, 16:31:08] [0] \t\t #> Encoding 7399 passages..\n",
      "[Jan 11, 16:31:11] [0] \t\t avg_doclen_est = 8.542235374450684 \t len(local_sample) = 7,399\n",
      "[Jan 11, 16:31:12] [0] \t\t Creaing 2,048 partitions.\n",
      "[Jan 11, 16:31:12] [0] \t\t *Estimated* 63,203 embeddings.\n",
      "[Jan 11, 16:31:12] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 60044 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 60044 points in 128D to 2048 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 3 (0.05 s, search 0.03 s): objective=13320.1 imbalance=1.697 nsplit=0        \n",
      "[Jan 11, 16:31:12] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 16:31:12] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.033, 0.033, 0.033, 0.034, 0.032, 0.033, 0.033, 0.029, 0.03, 0.035, 0.032, 0.032, 0.032, 0.035, 0.032, 0.033, 0.032, 0.031, 0.029, 0.033, 0.03, 0.031, 0.033, 0.035, 0.033, 0.033, 0.032, 0.033, 0.033, 0.032, 0.03, 0.034, 0.032, 0.032, 0.035, 0.031, 0.032, 0.033, 0.032, 0.033, 0.029, 0.034, 0.034, 0.032, 0.032, 0.03, 0.033, 0.034, 0.032, 0.034, 0.034, 0.033, 0.033, 0.033, 0.033, 0.033, 0.032, 0.031, 0.034, 0.031, 0.031, 0.031, 0.032, 0.035, 0.035, 0.031, 0.032, 0.033, 0.032, 0.034, 0.033, 0.034, 0.033, 0.032, 0.031, 0.033, 0.031, 0.033, 0.031, 0.033, 0.032, 0.033, 0.034, 0.032, 0.029, 0.031, 0.034, 0.031, 0.033, 0.031, 0.032, 0.033, 0.03, 0.031, 0.032, 0.033, 0.031, 0.033, 0.033, 0.031, 0.031, 0.031, 0.029, 0.032, 0.032, 0.032, 0.031, 0.03, 0.033, 0.031, 0.032, 0.032, 0.032, 0.03, 0.032, 0.028, 0.031, 0.032, 0.031, 0.032, 0.033, 0.029, 0.031, 0.032, 0.029, 0.032, 0.032, 0.031]\n",
      "[Jan 11, 16:31:13] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:31:13] #> Got bucket_cutoffs = tensor([-0.0215,  0.0002,  0.0221], device='cuda:0') and bucket_weights = tensor([-0.0438, -0.0089,  0.0093,  0.0450], device='cuda:0')\n",
      "[Jan 11, 16:31:13] avg_residual = 0.032073974609375\n",
      "[Jan 11, 16:31:13] [0] \t\t #> Encoding 7399 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:31:15] [0] \t\t #> Saving chunk 0: \t 7,399 passages and 63,204 embeddings. From #0 onward.\n",
      "[Jan 11, 16:31:15] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:31:15] [0] \t\t Found all files!\n",
      "[Jan 11, 16:31:15] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:31:15] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:31:15] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:31:15] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:31:15] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:31:15] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:31:15] len(emb2pid) = 63204\n",
      "[Jan 11, 16:31:15] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:31:15] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.26s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1736.77it/s]\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 84293.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:31:16] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:31:18] #> Loading codec...\n",
      "[Jan 11, 16:31:18] #> Loading IVF...\n",
      "[Jan 11, 16:31:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1921.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:31:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 458.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Колонка Creative Muvo Mini White, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1189, 14150, 29436, 14150, 18947, 28598,  5541, 14163,\n",
      "         6767,  7163,  2317,   102,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 81.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.19108033180236816\n",
      "\n",
      "мобильные телефоны\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:31:18] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:31:18] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:31:18] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:31:18] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:31:18] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:31:45] [0] \t\t # of sampled PIDs = 9494 \t sampled_pids[:3] = [6825, 166, 4892]\n",
      "[Jan 11, 16:31:45] [0] \t\t #> Encoding 9494 passages..\n",
      "[Jan 11, 16:31:49] [0] \t\t avg_doclen_est = 8.751526832580566 \t len(local_sample) = 9,494\n",
      "[Jan 11, 16:31:49] [0] \t\t Creaing 4,096 partitions.\n",
      "[Jan 11, 16:31:49] [0] \t\t *Estimated* 83,086 embeddings.\n",
      "[Jan 11, 16:31:49] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 78933 points in 128D to 4096 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 3 (0.08 s, search 0.06 s): objective=13607.8 imbalance=1.705 nsplit=0        \n",
      "[Jan 11, 16:31:50] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 78933 points to 4096 centroids: please provide at least 159744 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:31:50] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.029, 0.029, 0.029, 0.029, 0.027, 0.029, 0.028, 0.026, 0.027, 0.031, 0.028, 0.03, 0.028, 0.031, 0.029, 0.028, 0.028, 0.028, 0.026, 0.029, 0.029, 0.029, 0.03, 0.031, 0.028, 0.029, 0.029, 0.03, 0.029, 0.031, 0.028, 0.03, 0.028, 0.029, 0.031, 0.028, 0.03, 0.029, 0.03, 0.028, 0.026, 0.03, 0.031, 0.029, 0.03, 0.029, 0.029, 0.03, 0.029, 0.029, 0.031, 0.029, 0.03, 0.03, 0.029, 0.029, 0.029, 0.028, 0.029, 0.028, 0.029, 0.029, 0.029, 0.031, 0.032, 0.029, 0.029, 0.029, 0.027, 0.03, 0.028, 0.029, 0.031, 0.029, 0.028, 0.029, 0.029, 0.03, 0.028, 0.029, 0.029, 0.028, 0.03, 0.027, 0.026, 0.028, 0.03, 0.029, 0.03, 0.027, 0.027, 0.031, 0.026, 0.028, 0.028, 0.03, 0.027, 0.031, 0.029, 0.029, 0.027, 0.028, 0.026, 0.029, 0.03, 0.029, 0.031, 0.029, 0.03, 0.028, 0.028, 0.029, 0.029, 0.026, 0.029, 0.026, 0.028, 0.029, 0.029, 0.029, 0.029, 0.026, 0.029, 0.029, 0.026, 0.029, 0.029, 0.028]\n",
      "[Jan 11, 16:31:50] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:31:50] #> Got bucket_cutoffs = tensor([-1.9073e-02,  4.5776e-05,  1.9180e-02], device='cuda:0') and bucket_weights = tensor([-0.0392, -0.0081,  0.0081,  0.0394], device='cuda:0')\n",
      "[Jan 11, 16:31:50] avg_residual = 0.0288238525390625\n",
      "[Jan 11, 16:31:50] [0] \t\t #> Encoding 9494 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:31:53] [0] \t\t #> Saving chunk 0: \t 9,494 passages and 83,087 embeddings. From #0 onward.\n",
      "[Jan 11, 16:31:53] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:31:53] [0] \t\t Found all files!\n",
      "[Jan 11, 16:31:53] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:31:53] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:31:53] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:31:53] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:31:53] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:31:53] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:31:53] len(emb2pid) = 83087\n",
      "[Jan 11, 16:31:53] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:31:53] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.96s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1514.74it/s]\n",
      "100%|██████████| 4096/4096 [00:00<00:00, 88748.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:31:54] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:31:56] #> Loading codec...\n",
      "[Jan 11, 16:31:56] #> Loading IVF...\n",
      "[Jan 11, 16:31:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1285.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:31:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 269.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Смартфон Huawei P9 LITE VNS-L21 золотистый, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1196, 29745, 10260, 16856, 22919, 29749, 14150, 18947,\n",
      "        23064, 19845,  1052,  2683,  5507,  2063,  1058,  3619,  1011,  1048,\n",
      "        17465,  1187, 14150, 29436, 14150, 22919, 10325, 29747, 22919, 29113,\n",
      "        10325,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 121.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.15213775634765625\n",
      "\n",
      "VR-гарнитуры (VR-очки, шлемы, очки виртуальной реальности, FPV очки для квадрокоптеров)\n",
      "[Jan 11, 16:31:56] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:31:56] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:31:56] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:31:56] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:31:56] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:32:23] [0] \t\t # of sampled PIDs = 146 \t sampled_pids[:3] = [106, 2, 76]\n",
      "[Jan 11, 16:32:23] [0] \t\t #> Encoding 146 passages..\n",
      "[Jan 11, 16:32:24] [0] \t\t avg_doclen_est = 8.767123222351074 \t len(local_sample) = 146\n",
      "[Jan 11, 16:32:24] [0] \t\t Creaing 512 partitions.\n",
      "[Jan 11, 16:32:24] [0] \t\t *Estimated* 1,279 embeddings.\n",
      "[Jan 11, 16:32:24] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 1216 points to 512 centroids: please provide at least 19968 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 1216 points in 128D to 512 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.00 s, search 0.00 s): objective=96.2673 imbalance=1.360 nsplit=0       \n",
      "[Jan 11, 16:32:25] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 16:32:25] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.039, 0.033, 0.03, 0.028, 0.027, 0.032, 0.033, 0.027, 0.03, 0.03, 0.029, 0.032, 0.037, 0.037, 0.024, 0.035, 0.03, 0.032, 0.029, 0.039, 0.033, 0.037, 0.03, 0.03, 0.027, 0.03, 0.031, 0.031, 0.028, 0.035, 0.028, 0.033, 0.027, 0.032, 0.039, 0.031, 0.03, 0.03, 0.03, 0.04, 0.026, 0.035, 0.037, 0.034, 0.031, 0.031, 0.028, 0.034, 0.034, 0.042, 0.032, 0.035, 0.028, 0.034, 0.031, 0.043, 0.032, 0.032, 0.029, 0.028, 0.035, 0.032, 0.027, 0.029, 0.03, 0.036, 0.036, 0.033, 0.026, 0.035, 0.031, 0.033, 0.037, 0.031, 0.033, 0.035, 0.035, 0.047, 0.022, 0.031, 0.028, 0.027, 0.036, 0.029, 0.025, 0.037, 0.027, 0.029, 0.03, 0.036, 0.027, 0.026, 0.027, 0.028, 0.034, 0.029, 0.027, 0.031, 0.029, 0.026, 0.037, 0.024, 0.034, 0.041, 0.031, 0.027, 0.024, 0.026, 0.035, 0.023, 0.031, 0.035, 0.032, 0.029, 0.027, 0.032, 0.022, 0.033, 0.033, 0.031, 0.03, 0.025, 0.028, 0.034, 0.025, 0.03, 0.033, 0.03]\n",
      "[Jan 11, 16:32:25] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:32:25] #> Got bucket_cutoffs = tensor([-0.0210,  0.0001,  0.0213], device='cuda:0') and bucket_weights = tensor([-0.0424, -0.0083,  0.0088,  0.0449], device='cuda:0')\n",
      "[Jan 11, 16:32:25] avg_residual = 0.031280517578125\n",
      "[Jan 11, 16:32:26] [0] \t\t #> Encoding 146 passages..\n",
      "[Jan 11, 16:32:26] [0] \t\t #> Saving chunk 0: \t 146 passages and 1,280 embeddings. From #0 onward.\n",
      "[Jan 11, 16:32:26] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:32:26] [0] \t\t Found all files!\n",
      "[Jan 11, 16:32:26] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:32:26] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:32:26] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:32:26] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:32:26] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:32:26] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:32:26] len(emb2pid) = 1280\n",
      "[Jan 11, 16:32:26] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:32:26] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 15.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2233.39it/s]\n",
      "100%|██████████| 512/512 [00:00<00:00, 111836.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:32:27] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:32:28] #> Loading codec...\n",
      "[Jan 11, 16:32:28] #> Loading IVF...\n",
      "[Jan 11, 16:32:28] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2221.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:32:28] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 787.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Персональный экран-очки TCL NXTWEAR G, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1194, 15290, 16856, 29747, 14150, 19865, 29436, 23742,\n",
      "        18947, 29113, 10325,  1208, 23925, 16856, 28995,  1011,  1193, 29752,\n",
      "        23925, 10325, 22975,  2140,  1050, 18413, 16689,  1043,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 130.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.13994526863098145\n",
      "\n",
      "планшетные компьютеры и мини-планшеты\n",
      "[Jan 11, 16:32:28] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:32:28] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:32:28] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:32:28] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:32:28] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:32:56] [0] \t\t # of sampled PIDs = 3839 \t sampled_pids[:3] = [1706, 3001, 41]\n",
      "[Jan 11, 16:32:56] [0] \t\t #> Encoding 3839 passages..\n",
      "[Jan 11, 16:32:58] [0] \t\t avg_doclen_est = 10.191455841064453 \t len(local_sample) = 3,839\n",
      "[Jan 11, 16:32:58] [0] \t\t Creaing 2,048 partitions.\n",
      "[Jan 11, 16:32:58] [0] \t\t *Estimated* 39,124 embeddings.\n",
      "[Jan 11, 16:32:58] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 37169 points in 128D to 2048 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 3 (0.03 s, search 0.02 s): objective=6513.8 imbalance=1.660 nsplit=1         \n",
      "[Jan 11, 16:32:58] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 37169 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:32:58] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.028, 0.031, 0.029, 0.029, 0.029, 0.029, 0.028, 0.026, 0.026, 0.03, 0.028, 0.029, 0.028, 0.033, 0.026, 0.028, 0.028, 0.027, 0.025, 0.029, 0.027, 0.026, 0.029, 0.031, 0.028, 0.026, 0.032, 0.031, 0.03, 0.03, 0.028, 0.029, 0.026, 0.028, 0.03, 0.028, 0.029, 0.029, 0.031, 0.03, 0.027, 0.03, 0.03, 0.029, 0.028, 0.027, 0.028, 0.03, 0.028, 0.029, 0.029, 0.031, 0.029, 0.03, 0.03, 0.028, 0.031, 0.028, 0.029, 0.028, 0.029, 0.029, 0.028, 0.032, 0.031, 0.028, 0.027, 0.029, 0.029, 0.031, 0.028, 0.03, 0.03, 0.028, 0.027, 0.029, 0.028, 0.029, 0.028, 0.03, 0.029, 0.029, 0.029, 0.028, 0.026, 0.028, 0.028, 0.029, 0.032, 0.027, 0.028, 0.03, 0.027, 0.027, 0.029, 0.032, 0.029, 0.029, 0.029, 0.028, 0.026, 0.026, 0.027, 0.029, 0.028, 0.03, 0.032, 0.028, 0.029, 0.028, 0.029, 0.028, 0.03, 0.025, 0.029, 0.026, 0.027, 0.027, 0.028, 0.029, 0.028, 0.026, 0.028, 0.03, 0.027, 0.029, 0.026, 0.026]\n",
      "[Jan 11, 16:32:59] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:32:59] #> Got bucket_cutoffs = tensor([-1.8173e-02,  6.1035e-05,  1.8066e-02], device='cuda:0') and bucket_weights = tensor([-0.0393, -0.0074,  0.0074,  0.0392], device='cuda:0')\n",
      "[Jan 11, 16:32:59] avg_residual = 0.0285186767578125\n",
      "[Jan 11, 16:32:59] [0] \t\t #> Encoding 3839 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:33:00] [0] \t\t #> Saving chunk 0: \t 3,839 passages and 39,125 embeddings. From #0 onward.\n",
      "[Jan 11, 16:33:00] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:33:00] [0] \t\t Found all files!\n",
      "[Jan 11, 16:33:00] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:33:00] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:33:00] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:33:00] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:33:00] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:33:00] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:33:00] len(emb2pid) = 39125\n",
      "[Jan 11, 16:33:00] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:33:00] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.35s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1816.50it/s]\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 90281.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:33:01] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:33:03] #> Loading codec...\n",
      "[Jan 11, 16:33:03] #> Loading IVF...\n",
      "[Jan 11, 16:33:03] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1364.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:33:03] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 528.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Планшет Samsung Galaxy Tab A 8.0 SM-T290 32Gb Wi-Fi (SM-T290NZSASER, серебристый), \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1194, 29436, 28995, 29753, 15290, 22919, 19102,  9088,\n",
      "        21628,  1037,  1022,  1012,  1014, 15488,  1011,  1056, 24594,  2692,\n",
      "         3590, 18259, 15536,  1011, 10882,  1006, 15488,  1011,  1056, 24594,\n",
      "         2692,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 111.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.15790057182312012\n",
      "\n",
      "наушники, гарнитуры, наушники c микрофоном\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:33:03] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:33:03] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:33:03] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:33:03] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:33:03] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:33:30] [0] \t\t # of sampled PIDs = 11118 \t sampled_pids[:3] = [6825, 166, 4892]\n",
      "[Jan 11, 16:33:30] [0] \t\t #> Encoding 11118 passages..\n",
      "[Jan 11, 16:33:35] [0] \t\t avg_doclen_est = 8.841338157653809 \t len(local_sample) = 11,118\n",
      "[Jan 11, 16:33:35] [0] \t\t Creaing 4,096 partitions.\n",
      "[Jan 11, 16:33:35] [0] \t\t *Estimated* 98,297 embeddings.\n",
      "[Jan 11, 16:33:35] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 93384 points in 128D to 4096 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.01 s\n",
      "  Iteration 3 (0.10 s, search 0.08 s): objective=18060 imbalance=1.681 nsplit=0          \n",
      "[Jan 11, 16:33:35] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 93384 points to 4096 centroids: please provide at least 159744 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:33:36] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.03, 0.031, 0.03, 0.03, 0.03, 0.03, 0.029, 0.026, 0.028, 0.031, 0.03, 0.03, 0.029, 0.031, 0.029, 0.029, 0.029, 0.03, 0.027, 0.03, 0.031, 0.029, 0.031, 0.032, 0.029, 0.03, 0.031, 0.03, 0.031, 0.03, 0.029, 0.031, 0.029, 0.029, 0.03, 0.029, 0.031, 0.03, 0.031, 0.031, 0.028, 0.031, 0.031, 0.031, 0.031, 0.029, 0.03, 0.032, 0.03, 0.03, 0.033, 0.031, 0.03, 0.033, 0.031, 0.031, 0.03, 0.029, 0.03, 0.029, 0.029, 0.029, 0.03, 0.032, 0.034, 0.029, 0.029, 0.03, 0.03, 0.031, 0.029, 0.031, 0.031, 0.029, 0.029, 0.03, 0.03, 0.031, 0.03, 0.03, 0.029, 0.03, 0.03, 0.029, 0.028, 0.029, 0.031, 0.029, 0.03, 0.028, 0.028, 0.03, 0.028, 0.029, 0.03, 0.031, 0.029, 0.03, 0.03, 0.03, 0.028, 0.028, 0.026, 0.03, 0.031, 0.03, 0.032, 0.029, 0.03, 0.029, 0.03, 0.029, 0.031, 0.028, 0.03, 0.027, 0.029, 0.03, 0.028, 0.031, 0.03, 0.028, 0.029, 0.031, 0.027, 0.03, 0.029, 0.029]\n",
      "[Jan 11, 16:33:36] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:33:36] #> Got bucket_cutoffs = tensor([-1.9531e-02,  6.7711e-05,  1.9730e-02], device='cuda:0') and bucket_weights = tensor([-0.0407, -0.0081,  0.0083,  0.0410], device='cuda:0')\n",
      "[Jan 11, 16:33:36] avg_residual = 0.02978515625\n",
      "[Jan 11, 16:33:36] [0] \t\t #> Encoding 11118 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:33:39] [0] \t\t #> Saving chunk 0: \t 11,118 passages and 98,298 embeddings. From #0 onward.\n",
      "[Jan 11, 16:33:39] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:33:39] [0] \t\t Found all files!\n",
      "[Jan 11, 16:33:40] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:33:40] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:33:40] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:33:40] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:33:40] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:33:40] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:33:40] len(emb2pid) = 98298\n",
      "[Jan 11, 16:33:40] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:33:40] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.49s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1366.22it/s]\n",
      "100%|██████████| 4096/4096 [00:00<00:00, 90592.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:33:41] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:33:42] #> Loading codec...\n",
      "[Jan 11, 16:33:42] #> Loading IVF...\n",
      "[Jan 11, 16:33:42] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1608.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:33:42] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 309.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Honor Беспроводные наушники Choice CE79 TWS Earbuds (White), \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  3932,  1181, 15290, 29747, 29746, 16856, 19259, 14150,\n",
      "        29742, 18947, 29113, 15290,  1192, 10260, 29748, 29753, 18947, 10325,\n",
      "        23925, 10325,  3601,  8292,  2581,  2683,  1056,  9333,  4540,  8569,\n",
      "         5104,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 119.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.15329599380493164\n",
      "\n",
      "радиоприемники, радиобудильники, радиочасы\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:33:42] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:33:42] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:33:42] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:33:42] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:33:42] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:34:10] [0] \t\t # of sampled PIDs = 1452 \t sampled_pids[:3] = [853, 20, 611]\n",
      "[Jan 11, 16:34:10] [0] \t\t #> Encoding 1452 passages..\n",
      "[Jan 11, 16:34:11] [0] \t\t avg_doclen_est = 8.69214916229248 \t len(local_sample) = 1,452\n",
      "[Jan 11, 16:34:11] [0] \t\t Creaing 1,024 partitions.\n",
      "[Jan 11, 16:34:11] [0] \t\t *Estimated* 12,621 embeddings.\n",
      "[Jan 11, 16:34:11] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 11990 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.01 s, search 0.01 s): objective=2301.44 imbalance=1.677 nsplit=0       \n",
      "[Jan 11, 16:34:11] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 11990 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:34:12] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.033, 0.035, 0.034, 0.035, 0.032, 0.034, 0.03, 0.029, 0.03, 0.036, 0.03, 0.033, 0.031, 0.037, 0.033, 0.031, 0.033, 0.032, 0.026, 0.034, 0.031, 0.032, 0.032, 0.033, 0.031, 0.034, 0.035, 0.032, 0.035, 0.033, 0.032, 0.033, 0.032, 0.033, 0.033, 0.033, 0.031, 0.032, 0.034, 0.035, 0.03, 0.034, 0.033, 0.032, 0.035, 0.03, 0.032, 0.033, 0.031, 0.036, 0.033, 0.034, 0.037, 0.032, 0.036, 0.033, 0.031, 0.033, 0.031, 0.03, 0.033, 0.033, 0.033, 0.034, 0.035, 0.031, 0.033, 0.032, 0.031, 0.033, 0.031, 0.033, 0.034, 0.032, 0.031, 0.034, 0.031, 0.033, 0.035, 0.034, 0.033, 0.032, 0.033, 0.032, 0.032, 0.03, 0.036, 0.031, 0.034, 0.031, 0.03, 0.033, 0.029, 0.031, 0.033, 0.036, 0.032, 0.031, 0.031, 0.031, 0.031, 0.03, 0.028, 0.036, 0.033, 0.033, 0.034, 0.029, 0.035, 0.034, 0.033, 0.033, 0.034, 0.031, 0.033, 0.027, 0.033, 0.032, 0.031, 0.031, 0.033, 0.029, 0.033, 0.031, 0.028, 0.032, 0.035, 0.031]\n",
      "[Jan 11, 16:34:12] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:34:12] #> Got bucket_cutoffs = tensor([-0.0206,  0.0002,  0.0215], device='cuda:0') and bucket_weights = tensor([-0.0446, -0.0082,  0.0088,  0.0460], device='cuda:0')\n",
      "[Jan 11, 16:34:12] avg_residual = 0.032379150390625\n",
      "[Jan 11, 16:34:12] [0] \t\t #> Encoding 1452 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:34:13] [0] \t\t #> Saving chunk 0: \t 1,452 passages and 12,621 embeddings. From #0 onward.\n",
      "[Jan 11, 16:34:13] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:34:13] [0] \t\t Found all files!\n",
      "[Jan 11, 16:34:13] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:34:13] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:34:13] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:34:13] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:34:13] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:34:13] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:34:13] len(emb2pid) = 12621\n",
      "[Jan 11, 16:34:13] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:34:13] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1570.90it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 99122.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:34:13] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:34:15] #> Loading codec...\n",
      "[Jan 11, 16:34:15] #> Loading IVF...\n",
      "[Jan 11, 16:34:15] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1902.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:34:15] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 633.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Радиоприемник Tivoli Model One Classic Walnut, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1195, 10260, 29742, 10325, 14150, 29746, 16856, 10325,\n",
      "        15290, 29745, 18947, 10325, 23925, 14841,  6767,  3669,  2944,  2028,\n",
      "         4438, 18489,   102,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 103.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.16929411888122559\n",
      "\n",
      "магнитолы\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:34:15] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:34:15] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:34:15] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:34:15] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:34:15] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:34:43] [0] \t\t # of sampled PIDs = 498 \t sampled_pids[:3] = [213, 375, 5]\n",
      "[Jan 11, 16:34:43] [0] \t\t #> Encoding 498 passages..\n",
      "[Jan 11, 16:34:44] [0] \t\t avg_doclen_est = 9.076305389404297 \t len(local_sample) = 498\n",
      "[Jan 11, 16:34:44] [0] \t\t Creaing 1,024 partitions.\n",
      "[Jan 11, 16:34:44] [0] \t\t *Estimated* 4,520 embeddings.\n",
      "[Jan 11, 16:34:44] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 4294 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 4294 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.00 s, search 0.00 s): objective=423.616 imbalance=1.568 nsplit=0       \n",
      "[Jan 11, 16:34:44] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 16:34:44] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.028, 0.025, 0.025, 0.028, 0.026, 0.03, 0.026, 0.02, 0.021, 0.025, 0.026, 0.029, 0.025, 0.027, 0.024, 0.026, 0.022, 0.022, 0.021, 0.029, 0.024, 0.022, 0.026, 0.03, 0.025, 0.026, 0.026, 0.027, 0.024, 0.023, 0.024, 0.025, 0.027, 0.028, 0.026, 0.026, 0.026, 0.025, 0.03, 0.03, 0.022, 0.028, 0.025, 0.025, 0.028, 0.022, 0.024, 0.026, 0.026, 0.025, 0.025, 0.023, 0.029, 0.027, 0.027, 0.029, 0.022, 0.028, 0.025, 0.027, 0.025, 0.026, 0.024, 0.028, 0.029, 0.025, 0.027, 0.026, 0.025, 0.027, 0.022, 0.024, 0.028, 0.025, 0.026, 0.025, 0.024, 0.025, 0.023, 0.025, 0.025, 0.026, 0.026, 0.024, 0.021, 0.025, 0.024, 0.024, 0.028, 0.023, 0.023, 0.026, 0.023, 0.027, 0.023, 0.029, 0.026, 0.025, 0.023, 0.023, 0.026, 0.02, 0.021, 0.028, 0.026, 0.024, 0.025, 0.025, 0.024, 0.024, 0.022, 0.026, 0.026, 0.025, 0.028, 0.022, 0.026, 0.024, 0.025, 0.024, 0.025, 0.021, 0.024, 0.026, 0.023, 0.023, 0.026, 0.023]\n",
      "[Jan 11, 16:34:45] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:34:45] #> Got bucket_cutoffs = tensor([-1.4648e-02, -4.9591e-05,  1.4841e-02], device='cuda:0') and bucket_weights = tensor([-0.0339, -0.0057,  0.0057,  0.0347], device='cuda:0')\n",
      "[Jan 11, 16:34:45] avg_residual = 0.0251617431640625\n",
      "[Jan 11, 16:34:45] [0] \t\t #> Encoding 498 passages..\n",
      "[Jan 11, 16:34:45] [0] \t\t #> Saving chunk 0: \t 498 passages and 4,520 embeddings. From #0 onward.\n",
      "[Jan 11, 16:34:45] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:34:45] [0] \t\t Found all files!\n",
      "[Jan 11, 16:34:45] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:34:45] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:34:45] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:34:45] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:34:45] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:34:45] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:34:45] len(emb2pid) = 4520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1867.46it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 83111.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:34:45] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:34:45] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Jan 11, 16:34:46] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:34:47] #> Loading codec...\n",
      "[Jan 11, 16:34:47] #> Loading IVF...\n",
      "[Jan 11, 16:34:47] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4271.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:34:47] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 735.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Магнитола Telefunken TF-CSRP 3494 B синий, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1191, 10260, 29741, 18947, 10325, 22919, 14150, 29436,\n",
      "        10260, 10093, 12879, 16814,  2368,  1056,  2546,  1011, 20116, 14536,\n",
      "         4090,  2683,  2549,  1038,  1196, 10325, 18947, 15414,   102,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 131.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.141038179397583\n",
      "\n",
      "GPS-навигаторы\n",
      "[Jan 11, 16:34:48] #> Loading the queries from /mnt/vdb1/ColBERT/tmp/offers.tsv ...\n",
      "[Jan 11, 16:34:48] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Jan 11, 16:34:48] #> Loading collection...\n",
      "0M \n",
      "\n",
      "\n",
      "[Jan 11, 16:34:48] #> Note: Output directory /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits already exists\n",
      "\n",
      "\n",
      "[Jan 11, 16:34:48] #> Will delete 10 files already at /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits in 20 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 9555,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 0,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\\/HYPERPARAM_shuffle\\/none\\/2024-01\\/10\\/13.34.30\\/checkpoints\\/colbert-9555\",\n",
      "    \"triples\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/triples_shuffle.json\",\n",
      "    \"collection\": \"\\/mnt\\/vdb1\\/ColBERT\\/tmp\\/models.tsv\",\n",
      "    \"queries\": \"\\/mnt\\/vdb1\\/Datasets\\/ColBERT\\/18_categories\\/train\\/queries_train.tsv\",\n",
      "    \"index_name\": \"models.18_categories.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/mnt\\/vdb1\\/ColBERT\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-01\\/11\\/16.26.20\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jan 11, 16:35:15] [0] \t\t # of sampled PIDs = 1709 \t sampled_pids[:3] = [853, 1500, 20]\n",
      "[Jan 11, 16:35:15] [0] \t\t #> Encoding 1709 passages..\n",
      "[Jan 11, 16:35:16] [0] \t\t avg_doclen_est = 9.210649490356445 \t len(local_sample) = 1,709\n",
      "[Jan 11, 16:35:16] [0] \t\t Creaing 1,024 partitions.\n",
      "[Jan 11, 16:35:16] [0] \t\t *Estimated* 15,740 embeddings.\n",
      "[Jan 11, 16:35:16] [0] \t\t #> Saving the indexing plan to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/plan.json ..\n",
      "Clustering 14954 points in 128D to 1024 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 3 (0.01 s, search 0.01 s): objective=2916.61 imbalance=1.603 nsplit=0       \n",
      "[Jan 11, 16:35:17] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 14954 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:35:17] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.032, 0.031, 0.03, 0.03, 0.03, 0.034, 0.032, 0.027, 0.029, 0.033, 0.03, 0.033, 0.03, 0.035, 0.03, 0.031, 0.029, 0.03, 0.028, 0.03, 0.028, 0.029, 0.033, 0.032, 0.031, 0.032, 0.031, 0.03, 0.033, 0.03, 0.027, 0.033, 0.03, 0.029, 0.032, 0.03, 0.031, 0.032, 0.032, 0.032, 0.028, 0.033, 0.032, 0.031, 0.034, 0.029, 0.03, 0.033, 0.032, 0.03, 0.032, 0.031, 0.034, 0.031, 0.032, 0.031, 0.03, 0.03, 0.031, 0.03, 0.031, 0.029, 0.032, 0.034, 0.036, 0.029, 0.032, 0.03, 0.029, 0.031, 0.03, 0.031, 0.031, 0.03, 0.031, 0.033, 0.029, 0.031, 0.031, 0.032, 0.029, 0.031, 0.032, 0.03, 0.028, 0.031, 0.03, 0.028, 0.031, 0.029, 0.028, 0.032, 0.026, 0.028, 0.033, 0.034, 0.027, 0.033, 0.033, 0.033, 0.029, 0.029, 0.028, 0.031, 0.031, 0.03, 0.034, 0.028, 0.034, 0.03, 0.031, 0.031, 0.033, 0.027, 0.031, 0.027, 0.031, 0.031, 0.029, 0.032, 0.031, 0.028, 0.031, 0.031, 0.029, 0.03, 0.031, 0.029]\n",
      "[Jan 11, 16:35:17] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Jan 11, 16:35:17] #> Got bucket_cutoffs = tensor([-0.0200, -0.0001,  0.0196], device='cuda:0') and bucket_weights = tensor([-0.0427, -0.0080,  0.0078,  0.0423], device='cuda:0')\n",
      "[Jan 11, 16:35:17] avg_residual = 0.030670166015625\n",
      "[Jan 11, 16:35:17] [0] \t\t #> Encoding 1709 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:35:18] [0] \t\t #> Saving chunk 0: \t 1,709 passages and 15,741 embeddings. From #0 onward.\n",
      "[Jan 11, 16:35:18] [0] \t\t #> Checking all files were saved...\n",
      "[Jan 11, 16:35:18] [0] \t\t Found all files!\n",
      "[Jan 11, 16:35:18] [0] \t\t #> Building IVF...\n",
      "[Jan 11, 16:35:18] [0] \t\t #> Loading codes...\n",
      "[Jan 11, 16:35:18] [0] \t\t Sorting codes...\n",
      "[Jan 11, 16:35:18] [0] \t\t Getting unique codes...\n",
      "[Jan 11, 16:35:18] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 16:35:18] #> Building the emb2pid mapping..\n",
      "[Jan 11, 16:35:18] len(emb2pid) = 15741\n",
      "[Jan 11, 16:35:18] #> Saved optimized IVF to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/ivf.pid.pt\n",
      "[Jan 11, 16:35:18] [0] \t\t #> Saving the indexing metadata to /mnt/vdb1/ColBERT/experiments/notebook/indexes/models.18_categories.2bits/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2046.00it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 91079.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "[Jan 11, 16:35:19] #> Loading collection...\n",
      "0M \n",
      "[Jan 11, 16:35:21] #> Loading codec...\n",
      "[Jan 11, 16:35:21] #> Loading IVF...\n",
      "[Jan 11, 16:35:21] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1576.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 16:35:21] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 549.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Навигатор Garmin gpsmap 66st, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  1192, 10260, 25529, 10325, 29741, 10260, 22919, 14150,\n",
      "        16856, 11721, 27512, 14658,  2863,  2361,  5764,  3367,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 123.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_spent = 0.14594554901123047\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    \"диктофоны, портативные рекордеры\",\n",
    "    \"электронные книги\",\n",
    "    \"автомобильные телевизоры, мониторы\",\n",
    "    \"смарт-часы и браслеты\",\n",
    "    \"портативные медиаплееры\",\n",
    "    \"чехлы, обложки для гаджетов (телефонов, планшетов etc)\",\n",
    "    \"портативная акустика\",\n",
    "    \"мобильные телефоны\",\n",
    "    \"VR-гарнитуры (VR-очки, шлемы, очки виртуальной реальности, FPV очки для квадрокоптеров)\",\n",
    "    \"планшетные компьютеры и мини-планшеты\",\n",
    "    \"наушники, гарнитуры, наушники c микрофоном\",\n",
    "    \"радиоприемники, радиобудильники, радиочасы\",\n",
    "    \"магнитолы\",\n",
    "    \"GPS-навигаторы\"\n",
    "    ]\n",
    "\n",
    "def search(checkpoint, offers, models, nbits, doc_maxlen):\n",
    "    index_name = f'models.18_categories.{nbits}bits'\n",
    "\n",
    "    offers = Queries(path=offers)\n",
    "    models = Collection(path=models)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with Run().context(RunConfig(nranks=1, experiment='notebook')):  # nranks specifies the number of GPUs to use.\n",
    "        config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits)\n",
    "\n",
    "        indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "        indexer.index(name=index_name, collection=models, overwrite=True)\n",
    "    indexer.get_index() # You can get the absolute path of the index, if needed.\n",
    "\n",
    "    with Run().context(RunConfig(experiment='notebook')):\n",
    "        searcher = Searcher(index=index_name)\n",
    "    with open(\"/mnt/vdb1/ColBERT/tmp/logs.txt\", \"a\") as txt:\n",
    "        txt.write(f\"Подготовка моделей категории: time_spent = {time.time() - start_time}\\n\")\n",
    "    print(f\"Подготовка моделей категории: time_spent = {time.time() - start_time}\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    rankings = searcher.search_all(offers, k=5).todict()\n",
    "    with open(\"/mnt/vdb1/ColBERT/tmp/logs.txt\", \"a\") as txt:\n",
    "        txt.write(f\"Инференс на всех офферах категории: time_spent = {time.time() - start_time}\\n\")\n",
    "    print(f\"Инференс на всех офферах категории: time_spent = {time.time() - start_time}\\n\\n\\n\")\n",
    "    return rankings\n",
    "\n",
    "def ranking_index(rankings, category_rankings, df, index_of_first):\n",
    "    \"\"\"\n",
    "    сделать сдвиг passage_id на величину index_of_first для приведения к формату в котором поиск оффера ведется среди моделей всех категорий \n",
    "    упорядочить (passage_id, rank, score) в rankings согласно изначальным индексам в df_offers\n",
    "    \"\"\"\n",
    "\n",
    "    for i in category_rankings:\n",
    "        for j in range(5):\n",
    "            category_rankings[i][j] = (category_rankings[i][j][0] + index_of_first, category_rankings[i][j][1], category_rankings[i][j][2])\n",
    "            \n",
    "    i = -1\n",
    "    for index, row in df.iterrows():\n",
    "        i += 1\n",
    "        rankings[index] = category_rankings[i]\n",
    "    return rankings\n",
    "\n",
    "def df_split(df, col=\"name\"):\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    df1[\"id\"], df1[col] = [i for i in range(len(df))], df[col]\n",
    "    \n",
    "    df2 = pd.DataFrame()\n",
    "    df2[\"id\"], df2[\"model_id\"] = [i for i in range(len(df))], df['model_id']\n",
    "    return df1, df2\n",
    "\n",
    "def prepare_tsv(category_offers, category_models, pth_offers, pth_models):\n",
    "    query, query_id = df_split(category_offers, col=\"name\")\n",
    "    query.to_csv(pth_offers, sep='\\t', header=False, index=False)\n",
    "\n",
    "    document, document_id = df_split(category_models, col=\"full_name\")\n",
    "    document.to_csv(pth_models, sep='\\t', header=False, index=False)\n",
    "    \n",
    "tmp_fld = \"/mnt/vdb1/ColBERT/tmp\"\n",
    "ckpt_pth = \"/mnt/vdb1/ColBERT/experiments/HYPERPARAM_shuffle/none/2024-01/10/13.34.30/checkpoints/colbert-9555\"\n",
    "pth_dst_json = \"/mnt/vdb1/Datasets/ColBERT/18_categories/metrics_data/EVAL/categories_one_by_one/triples_shuffle_colbert-9555.json\"\n",
    "doc_maxlen = 300\n",
    "nbits = 2   # encode each dimension with 2 bits\n",
    "rankings = {}\n",
    "for category in categories:\n",
    "    with open(\"/mnt/vdb1/ColBERT/tmp/logs.txt\", \"a\") as txt:\n",
    "        txt.write(f\"{category}:\\n\")\n",
    "    print(category)\n",
    "    index_of_first = df_models.index[df_models['category_name'] == category].tolist()[0]\n",
    "\n",
    "    category_models = df_models[df_models['category_name'] == category]\n",
    "    category_offers = df_offers[df_offers['category_name'] == category]\n",
    "\n",
    "    pth_models = f'{tmp_fld}/models.tsv'\n",
    "    pth_offers = f'{tmp_fld}/offers.tsv'\n",
    "    prepare_tsv(category_offers, category_models, pth_offers, pth_models)\n",
    "\n",
    "    category_rankings = search(ckpt_pth, pth_offers, pth_models, nbits, doc_maxlen)\n",
    "    rankings = ranking_index(rankings, category_rankings, category_offers, index_of_first)\n",
    "\n",
    "with open(pth_dst_json, 'w') as fp:\n",
    "    json.dump(rankings, fp)\n",
    "\n",
    "with open(\"/mnt/vdb1/ColBERT/tmp/logs.txt\", \"a\") as txt:\n",
    "    txt.write(f\"Save pth: {pth_dst_json}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{104561: [(57717, 1, 26.078125),\n",
       "  (57758, 2, 17.015625),\n",
       "  (57747, 3, 15.8828125),\n",
       "  (57672, 4, 15.609375),\n",
       "  (57849, 5, 15.359375)],\n",
       " 131559: [(57699, 1, 18.609375),\n",
       "  (57737, 2, 15.6015625),\n",
       "  (57698, 3, 15.46875),\n",
       "  (57662, 4, 15.3671875),\n",
       "  (57569, 5, 14.6640625)],\n",
       " 113853: [(57797, 1, 23.515625),\n",
       "  (57824, 2, 18.578125),\n",
       "  (57745, 3, 18.1875),\n",
       "  (57463, 4, 18.171875),\n",
       "  (57716, 5, 18.109375)],\n",
       " 63102: [(57705, 1, 27.671875),\n",
       "  (57703, 2, 22.265625),\n",
       "  (57706, 3, 21.765625),\n",
       "  (57406, 4, 21.75),\n",
       "  (57690, 5, 18.78125)],\n",
       " 118019: [(57510, 1, 25.53125),\n",
       "  (57812, 2, 21.046875),\n",
       "  (57470, 3, 20.78125),\n",
       "  (57471, 4, 20.546875),\n",
       "  (57511, 5, 20.078125)],\n",
       " 10140: [(57549, 1, 20.484375),\n",
       "  (57619, 2, 19.578125),\n",
       "  (57597, 3, 15.640625),\n",
       "  (57685, 4, 15.4765625),\n",
       "  (57795, 5, 12.96875)],\n",
       " 101021: [(57753, 1, 29.53125),\n",
       "  (57703, 2, 23.53125),\n",
       "  (57408, 3, 22.359375),\n",
       "  (57752, 4, 20.515625),\n",
       "  (57692, 5, 20.46875)],\n",
       " 64464: [(57844, 1, 23.84375),\n",
       "  (57845, 2, 17.515625),\n",
       "  (57852, 3, 14.1796875),\n",
       "  (57774, 4, 10.9296875),\n",
       "  (57797, 5, 10.4765625)],\n",
       " 92708: [(57777, 1, 27.234375),\n",
       "  (57730, 2, 22.453125),\n",
       "  (57394, 3, 22.21875),\n",
       "  (57401, 4, 22.078125),\n",
       "  (57708, 5, 21.96875)],\n",
       " 17476: [(57758, 1, 27.078125),\n",
       "  (57692, 2, 18.40625),\n",
       "  (57690, 3, 18.359375),\n",
       "  (57691, 4, 15.1875),\n",
       "  (57739, 5, 14.9921875)],\n",
       " 102307: [(40133, 1, 29.578125),\n",
       "  (40223, 2, 22.046875),\n",
       "  (40271, 3, 18.71875),\n",
       "  (40239, 4, 17.71875),\n",
       "  (40225, 5, 16.75)],\n",
       " 70247: [(40084, 1, 22.0625),\n",
       "  (40188, 2, 19.375),\n",
       "  (40252, 3, 17.203125),\n",
       "  (40103, 4, 14.7109375),\n",
       "  (40029, 5, 14.484375)],\n",
       " 99910: [(40286, 1, 22.453125),\n",
       "  (40212, 2, 19.28125),\n",
       "  (40239, 3, 18.734375),\n",
       "  (39916, 4, 15.5703125),\n",
       "  (40076, 5, 14.890625)],\n",
       " 19392: [(40054, 1, 16.25),\n",
       "  (39921, 2, 15.09375),\n",
       "  (40131, 3, 14.9140625),\n",
       "  (40127, 4, 14.6484375),\n",
       "  (40257, 5, 12.8671875)],\n",
       " 37563: [(40054, 1, 19.234375),\n",
       "  (40127, 2, 17.65625),\n",
       "  (40131, 3, 17.21875),\n",
       "  (39864, 4, 12.7421875),\n",
       "  (39886, 5, 12.609375)],\n",
       " 88822: [(40289, 1, 23.328125),\n",
       "  (40274, 2, 13.6171875),\n",
       "  (40268, 3, 13.3515625),\n",
       "  (40267, 4, 12.65625),\n",
       "  (40227, 5, 12.5078125)],\n",
       " 16297: [(40054, 1, 17.5),\n",
       "  (40131, 2, 16.0),\n",
       "  (40127, 3, 15.6171875),\n",
       "  (39921, 4, 14.4765625),\n",
       "  (39885, 5, 12.5859375)],\n",
       " 2859: [(40271, 1, 28.015625),\n",
       "  (40239, 2, 21.609375),\n",
       "  (39984, 3, 20.9375),\n",
       "  (40199, 4, 18.59375),\n",
       "  (39927, 5, 18.265625)],\n",
       " 18165: [(40212, 1, 19.640625),\n",
       "  (39648, 2, 13.6796875),\n",
       "  (40007, 3, 13.6484375),\n",
       "  (40065, 4, 13.4453125),\n",
       "  (39849, 5, 13.1484375)],\n",
       " 49648: [(39651, 1, 17.0),\n",
       "  (39990, 2, 15.0234375),\n",
       "  (39657, 3, 14.3671875),\n",
       "  (40263, 4, 13.890625),\n",
       "  (40136, 5, 13.8125)],\n",
       " 86942: [(55951, 1, 25.09375),\n",
       "  (55984, 2, 22.125),\n",
       "  (55989, 3, 19.484375),\n",
       "  (55978, 4, 18.203125),\n",
       "  (55967, 5, 17.75)],\n",
       " 62309: [(55784, 1, 27.3125),\n",
       "  (55648, 2, 22.765625),\n",
       "  (55629, 3, 20.0625),\n",
       "  (55439, 4, 17.828125),\n",
       "  (55676, 5, 17.734375)],\n",
       " 5746: [(55361, 1, 21.140625),\n",
       "  (55799, 2, 17.3125),\n",
       "  (55440, 3, 15.3046875),\n",
       "  (55347, 4, 15.25),\n",
       "  (56002, 5, 14.8828125)],\n",
       " 53420: [(55847, 1, 24.75),\n",
       "  (56009, 2, 18.234375),\n",
       "  (55393, 3, 17.109375),\n",
       "  (55870, 4, 16.640625),\n",
       "  (55970, 5, 16.484375)],\n",
       " 3399: [(55777, 1, 22.28125),\n",
       "  (55687, 2, 19.484375),\n",
       "  (55688, 3, 19.0),\n",
       "  (55684, 4, 18.859375),\n",
       "  (55686, 5, 18.75)],\n",
       " 38073: [(55892, 1, 17.8125),\n",
       "  (55891, 2, 17.6875),\n",
       "  (55890, 3, 17.40625),\n",
       "  (55889, 4, 17.3125),\n",
       "  (55441, 5, 14.921875)],\n",
       " 123211: [(55838, 1, 27.90625),\n",
       "  (55773, 2, 25.46875),\n",
       "  (55837, 3, 22.484375),\n",
       "  (55565, 4, 21.34375),\n",
       "  (55824, 5, 20.859375)],\n",
       " 103390: [(55555, 1, 25.390625),\n",
       "  (56001, 2, 17.71875),\n",
       "  (55512, 3, 17.390625),\n",
       "  (55919, 4, 15.21875),\n",
       "  (55769, 5, 14.53125)],\n",
       " 30761: [(55538, 1, 10.2421875),\n",
       "  (55384, 2, 10.2109375),\n",
       "  (55426, 3, 10.125),\n",
       "  (55702, 4, 10.109375),\n",
       "  (55522, 5, 10.0859375)],\n",
       " 7179: [(55948, 1, 24.609375),\n",
       "  (55882, 2, 22.75),\n",
       "  (55883, 3, 22.125),\n",
       "  (55235, 4, 14.96875),\n",
       "  (55881, 5, 14.8359375)],\n",
       " 1477: [(37308, 1, 26.4375),\n",
       "  (37086, 2, 17.59375),\n",
       "  (37375, 3, 16.59375),\n",
       "  (37309, 4, 16.109375),\n",
       "  (37376, 5, 15.453125)],\n",
       " 41868: [(39534, 1, 23.109375),\n",
       "  (39528, 2, 22.5),\n",
       "  (39564, 3, 21.9375),\n",
       "  (39531, 4, 21.90625),\n",
       "  (39606, 5, 17.0)],\n",
       " 101355: [(39419, 1, 26.75),\n",
       "  (39498, 2, 22.609375),\n",
       "  (38721, 3, 22.0),\n",
       "  (39467, 4, 21.421875),\n",
       "  (39470, 5, 21.203125)],\n",
       " 26342: [(38128, 1, 19.671875),\n",
       "  (39298, 2, 18.53125),\n",
       "  (37540, 3, 16.59375),\n",
       "  (37055, 4, 16.1875),\n",
       "  (38277, 5, 15.5703125)],\n",
       " 82554: [(39211, 1, 23.828125),\n",
       "  (38142, 2, 17.75),\n",
       "  (37869, 3, 17.15625),\n",
       "  (37395, 4, 16.953125),\n",
       "  (37649, 5, 16.90625)],\n",
       " 26761: [(39220, 1, 21.75),\n",
       "  (39544, 2, 19.71875),\n",
       "  (39221, 3, 19.421875),\n",
       "  (39228, 4, 18.75),\n",
       "  (38173, 5, 18.4375)],\n",
       " 34526: [(37488, 1, 20.875),\n",
       "  (37558, 2, 15.8359375),\n",
       "  (37362, 3, 15.7265625),\n",
       "  (37559, 4, 15.5703125),\n",
       "  (38260, 5, 15.375)],\n",
       " 81040: [(38061, 1, 22.453125),\n",
       "  (38062, 2, 18.453125),\n",
       "  (38342, 3, 17.015625),\n",
       "  (37156, 4, 16.9375),\n",
       "  (37960, 5, 16.59375)],\n",
       " 37888: [(37458, 1, 17.21875),\n",
       "  (37245, 2, 16.578125),\n",
       "  (37246, 3, 16.0625),\n",
       "  (37247, 4, 15.6328125),\n",
       "  (37460, 5, 15.5234375)],\n",
       " 16855: [(39257, 1, 21.71875),\n",
       "  (39266, 2, 18.25),\n",
       "  (39267, 3, 16.953125),\n",
       "  (39260, 4, 16.421875),\n",
       "  (39258, 5, 16.046875)],\n",
       " 70486: [(56031, 1, 20.671875),\n",
       "  (56030, 2, 16.171875),\n",
       "  (56035, 3, 13.125),\n",
       "  (56034, 4, 12.59375),\n",
       "  (56503, 5, 12.5625)],\n",
       " 35979: [(56581, 1, 20.203125),\n",
       "  (56640, 2, 16.59375),\n",
       "  (56582, 3, 15.296875),\n",
       "  (56721, 4, 15.0859375),\n",
       "  (56754, 5, 14.984375)],\n",
       " 94683: [(56745, 1, 25.203125),\n",
       "  (56095, 2, 22.71875),\n",
       "  (56088, 3, 21.90625),\n",
       "  (56762, 4, 21.828125),\n",
       "  (56701, 5, 21.3125)],\n",
       " 40669: [(56606, 1, 19.78125),\n",
       "  (56036, 2, 19.765625),\n",
       "  (56818, 3, 19.328125),\n",
       "  (56033, 4, 19.21875),\n",
       "  (56325, 5, 14.7421875)],\n",
       " 44969: [(56751, 1, 21.25),\n",
       "  (56752, 2, 15.1640625),\n",
       "  (56580, 3, 13.5625),\n",
       "  (56735, 4, 12.7265625),\n",
       "  (56603, 5, 12.5078125)],\n",
       " 11787: [(56640, 1, 22.296875),\n",
       "  (56754, 2, 19.640625),\n",
       "  (56581, 3, 19.515625),\n",
       "  (56778, 4, 19.15625),\n",
       "  (56779, 5, 19.0)],\n",
       " 35273: [(56830, 1, 27.234375),\n",
       "  (56831, 2, 24.671875),\n",
       "  (56464, 3, 24.09375),\n",
       "  (56729, 4, 23.359375),\n",
       "  (56465, 5, 22.625)],\n",
       " 97786: [(56659, 1, 22.34375),\n",
       "  (56502, 2, 20.5),\n",
       "  (56147, 3, 19.28125),\n",
       "  (56660, 4, 18.953125),\n",
       "  (56585, 5, 18.765625)],\n",
       " 101629: [(56783, 1, 23.6875),\n",
       "  (56767, 2, 15.484375),\n",
       "  (56840, 3, 15.40625),\n",
       "  (56713, 4, 14.5859375),\n",
       "  (56833, 5, 14.53125)],\n",
       " 102488: [(56817, 1, 14.921875),\n",
       "  (56605, 2, 12.9453125),\n",
       "  (56032, 3, 12.859375),\n",
       "  (56607, 4, 12.015625),\n",
       "  (56315, 5, 11.6484375)],\n",
       " 64444: [(7337, 1, 21.921875),\n",
       "  (12348, 2, 21.90625),\n",
       "  (7336, 3, 21.828125),\n",
       "  (12347, 4, 21.8125),\n",
       "  (25470, 5, 21.6875)],\n",
       " 54628: [(4171, 1, 23.109375),\n",
       "  (18337, 2, 22.6875),\n",
       "  (4177, 3, 22.671875),\n",
       "  (19861, 4, 22.46875),\n",
       "  (4193, 5, 22.453125)],\n",
       " 107640: [(23042, 1, 21.875),\n",
       "  (23041, 2, 19.875),\n",
       "  (23742, 3, 19.453125),\n",
       "  (17685, 4, 18.03125),\n",
       "  (17631, 5, 17.484375)],\n",
       " 20355: [(35669, 1, 23.484375),\n",
       "  (25152, 2, 23.3125),\n",
       "  (4666, 3, 21.203125),\n",
       "  (30100, 4, 20.515625),\n",
       "  (25151, 5, 20.484375)],\n",
       " 77072: [(7643, 1, 25.3125),\n",
       "  (23150, 2, 23.6875),\n",
       "  (23151, 3, 23.515625),\n",
       "  (7612, 4, 23.5),\n",
       "  (9366, 5, 23.328125)],\n",
       " 72926: [(25057, 1, 22.421875),\n",
       "  (27625, 2, 18.609375),\n",
       "  (27609, 3, 18.59375),\n",
       "  (28092, 4, 18.546875),\n",
       "  (30845, 5, 18.5)],\n",
       " 70957: [(34646, 1, 20.28125),\n",
       "  (34651, 2, 20.140625),\n",
       "  (20721, 3, 20.046875),\n",
       "  (34650, 4, 20.046875),\n",
       "  (8587, 5, 19.796875)],\n",
       " 32953: [(9929, 1, 22.421875),\n",
       "  (9888, 2, 22.0625),\n",
       "  (9903, 3, 21.21875),\n",
       "  (9930, 4, 21.09375),\n",
       "  (9897, 5, 20.765625)],\n",
       " 63002: [(20367, 1, 18.34375),\n",
       "  (29362, 2, 17.984375),\n",
       "  (35953, 3, 17.453125),\n",
       "  (20666, 4, 17.421875),\n",
       "  (23008, 5, 16.65625)],\n",
       " 63809: [(10089, 1, 19.59375),\n",
       "  (5366, 2, 19.390625),\n",
       "  (5334, 3, 18.828125),\n",
       "  (12268, 4, 17.6875),\n",
       "  (11154, 5, 17.40625)],\n",
       " 24046: [(72009, 1, 26.5),\n",
       "  (75710, 2, 26.5),\n",
       "  (74351, 3, 21.8125),\n",
       "  (78029, 4, 21.640625),\n",
       "  (72052, 5, 21.265625)],\n",
       " 12885: [(72924, 1, 22.65625),\n",
       "  (76603, 2, 22.65625),\n",
       "  (72380, 3, 17.5625),\n",
       "  (76075, 4, 17.5625),\n",
       "  (71713, 5, 17.234375)],\n",
       " 26883: [(73237, 1, 23.828125),\n",
       "  (76900, 2, 23.828125),\n",
       "  (73236, 3, 15.6328125),\n",
       "  (76899, 4, 15.625),\n",
       "  (71914, 5, 11.859375)],\n",
       " 31038: [(72535, 1, 25.484375),\n",
       "  (76229, 2, 25.484375),\n",
       "  (72177, 3, 23.328125),\n",
       "  (75875, 4, 23.328125),\n",
       "  (71925, 5, 20.21875)],\n",
       " 81415: [(73160, 1, 19.921875),\n",
       "  (76828, 2, 19.921875),\n",
       "  (72297, 3, 16.0),\n",
       "  (75993, 4, 16.0),\n",
       "  (72451, 5, 14.171875)],\n",
       " 55727: [(71824, 1, 16.84375),\n",
       "  (75525, 2, 16.828125),\n",
       "  (71183, 3, 16.78125),\n",
       "  (74885, 4, 16.78125),\n",
       "  (70811, 5, 16.234375)],\n",
       " 6210: [(71875, 1, 25.453125),\n",
       "  (75576, 2, 25.453125),\n",
       "  (74345, 3, 21.109375),\n",
       "  (74522, 4, 20.53125),\n",
       "  (70820, 5, 20.515625)],\n",
       " 72182: [(72825, 1, 19.875),\n",
       "  (76508, 2, 19.875),\n",
       "  (76516, 3, 18.140625),\n",
       "  (72834, 4, 18.125),\n",
       "  (74354, 5, 17.6875)],\n",
       " 29240: [(72750, 1, 29.265625),\n",
       "  (76438, 2, 29.265625),\n",
       "  (74314, 3, 26.828125),\n",
       "  (77928, 4, 26.828125),\n",
       "  (72083, 5, 25.578125)],\n",
       " 49177: [(72634, 1, 21.421875),\n",
       "  (76325, 2, 21.421875),\n",
       "  (72632, 3, 20.734375),\n",
       "  (76323, 4, 20.734375),\n",
       "  (72633, 5, 20.3125)],\n",
       " 76163: [(46725, 1, 22.6875),\n",
       "  (46448, 2, 20.75),\n",
       "  (47629, 3, 20.515625),\n",
       "  (48383, 4, 20.515625),\n",
       "  (46722, 5, 19.859375)],\n",
       " 59216: [(46407, 1, 24.75),\n",
       "  (49243, 2, 24.71875),\n",
       "  (49029, 3, 22.28125),\n",
       "  (47785, 4, 21.65625),\n",
       "  (49519, 5, 21.109375)],\n",
       " 28626: [(49415, 1, 25.90625),\n",
       "  (49414, 2, 21.53125),\n",
       "  (49275, 3, 20.859375),\n",
       "  (49322, 4, 20.609375),\n",
       "  (46517, 5, 20.359375)],\n",
       " 22316: [(44806, 1, 23.265625),\n",
       "  (45524, 2, 17.9375),\n",
       "  (45064, 3, 17.921875),\n",
       "  (45862, 4, 17.90625),\n",
       "  (45065, 5, 17.78125)],\n",
       " 95582: [(49150, 1, 20.28125),\n",
       "  (49389, 2, 18.5),\n",
       "  (49755, 3, 18.03125),\n",
       "  (49275, 4, 17.84375),\n",
       "  (48569, 5, 15.9140625)],\n",
       " 62090: [(49530, 1, 25.5),\n",
       "  (49791, 2, 21.578125),\n",
       "  (48805, 3, 20.0625),\n",
       "  (49621, 4, 18.5),\n",
       "  (49125, 5, 18.328125)],\n",
       " 121519: [(48092, 1, 22.125),\n",
       "  (48973, 2, 22.109375),\n",
       "  (49452, 3, 22.046875),\n",
       "  (49689, 4, 21.296875),\n",
       "  (49269, 5, 21.296875)],\n",
       " 40494: [(49261, 1, 26.28125),\n",
       "  (49678, 2, 23.84375),\n",
       "  (49750, 3, 22.234375),\n",
       "  (48763, 4, 20.921875),\n",
       "  (49366, 5, 19.9375)],\n",
       " 10814: [(48764, 1, 24.34375),\n",
       "  (47112, 2, 21.75),\n",
       "  (49409, 3, 20.90625),\n",
       "  (47779, 4, 20.234375),\n",
       "  (46753, 5, 20.140625)],\n",
       " 90070: [(48931, 1, 20.125),\n",
       "  (44578, 2, 17.4375),\n",
       "  (41259, 3, 16.890625),\n",
       "  (42192, 4, 16.8125),\n",
       "  (45345, 5, 16.359375)],\n",
       " 118674: [(55211, 1, 23.890625),\n",
       "  (55104, 2, 10.1484375),\n",
       "  (55212, 3, 9.9609375),\n",
       "  (55116, 4, 9.0390625),\n",
       "  (55098, 5, 8.953125)],\n",
       " 62112: [(55119, 1, 20.46875),\n",
       "  (55120, 2, 10.6875),\n",
       "  (55122, 3, 9.8046875),\n",
       "  (55172, 4, 9.7109375),\n",
       "  (55118, 5, 8.875)],\n",
       " 20354: [(55127, 1, 16.203125),\n",
       "  (55124, 2, 13.4609375),\n",
       "  (55126, 3, 12.4609375),\n",
       "  (55152, 4, 10.4609375),\n",
       "  (55128, 5, 10.1796875)],\n",
       " 81774: [(55115, 1, 19.8125),\n",
       "  (55109, 2, 14.4140625),\n",
       "  (55112, 3, 14.2734375),\n",
       "  (55116, 4, 13.546875),\n",
       "  (55113, 5, 13.34375)],\n",
       " 36049: [(55201, 1, 17.640625),\n",
       "  (55202, 2, 17.328125),\n",
       "  (55203, 3, 17.125),\n",
       "  (55157, 4, 14.5078125),\n",
       "  (55189, 5, 14.359375)],\n",
       " 112222: [(55126, 1, 22.59375),\n",
       "  (55124, 2, 16.75),\n",
       "  (55158, 3, 15.5390625),\n",
       "  (55183, 4, 13.875),\n",
       "  (55147, 5, 13.6953125)],\n",
       " 135799: [(55229, 1, 17.125),\n",
       "  (55109, 2, 10.6328125),\n",
       "  (55221, 3, 9.984375),\n",
       "  (55216, 4, 9.4609375),\n",
       "  (55090, 5, 9.2109375)],\n",
       " 98427: [(55130, 1, 17.71875),\n",
       "  (55204, 2, 15.0078125),\n",
       "  (55131, 3, 13.28125),\n",
       "  (55132, 4, 13.2265625),\n",
       "  (55129, 5, 11.5234375)],\n",
       " 32585: [(55229, 1, 13.359375),\n",
       "  (55109, 2, 12.0859375),\n",
       "  (55114, 3, 12.078125),\n",
       "  (55222, 4, 12.046875),\n",
       "  (55116, 5, 11.9296875)],\n",
       " 54842: [(55230, 1, 15.65625),\n",
       "  (55231, 2, 14.7578125),\n",
       "  (55232, 3, 12.6328125),\n",
       "  (55152, 4, 12.546875),\n",
       "  (55165, 5, 12.2734375)],\n",
       " 121953: [(53486, 1, 18.71875),\n",
       "  (52106, 2, 18.6875),\n",
       "  (50012, 3, 17.890625),\n",
       "  (53310, 4, 17.609375),\n",
       "  (53444, 5, 16.734375)],\n",
       " 90654: [(53323, 1, 25.0625),\n",
       "  (53470, 2, 25.046875),\n",
       "  (52872, 3, 24.953125),\n",
       "  (53556, 4, 24.90625),\n",
       "  (53170, 5, 24.734375)],\n",
       " 78481: [(53417, 1, 19.859375),\n",
       "  (53631, 2, 16.515625),\n",
       "  (53605, 3, 15.8515625),\n",
       "  (53630, 4, 15.5625),\n",
       "  (53381, 5, 15.2421875)],\n",
       " 126464: [(53295, 1, 21.1875),\n",
       "  (51654, 2, 20.65625),\n",
       "  (52919, 3, 19.609375),\n",
       "  (52275, 4, 19.40625),\n",
       "  (52243, 5, 19.375)],\n",
       " 35237: [(53467, 1, 25.171875),\n",
       "  (53553, 2, 24.875),\n",
       "  (53168, 3, 24.71875),\n",
       "  (53328, 4, 24.640625),\n",
       "  (53475, 5, 22.953125)],\n",
       " 117175: [(53378, 1, 23.046875),\n",
       "  (53313, 2, 18.6875),\n",
       "  (53487, 3, 18.546875),\n",
       "  (53561, 4, 18.1875),\n",
       "  (53456, 5, 18.15625)],\n",
       " 94373: [(53549, 1, 25.203125),\n",
       "  (53372, 2, 24.515625),\n",
       "  (53470, 3, 24.0),\n",
       "  (53453, 4, 23.703125),\n",
       "  (52350, 5, 23.65625)],\n",
       " 15211: [(53273, 1, 25.453125),\n",
       "  (53369, 2, 24.546875),\n",
       "  (52658, 3, 23.71875),\n",
       "  (52859, 4, 20.421875),\n",
       "  (50997, 5, 20.375)],\n",
       " 59883: [(53615, 1, 25.015625),\n",
       "  (53216, 2, 20.3125),\n",
       "  (53507, 3, 19.96875),\n",
       "  (53616, 4, 19.734375),\n",
       "  (53214, 5, 17.71875)],\n",
       " 85058: [(53485, 1, 22.15625),\n",
       "  (53526, 2, 17.15625),\n",
       "  (53486, 3, 17.0625),\n",
       "  (53478, 4, 15.84375),\n",
       "  (53633, 5, 15.4609375)],\n",
       " 95201: [(68054, 1, 22.25),\n",
       "  (70164, 2, 17.40625),\n",
       "  (67792, 3, 16.234375),\n",
       "  (70022, 4, 15.734375),\n",
       "  (66059, 5, 15.390625)],\n",
       " 85579: [(70477, 1, 16.5),\n",
       "  (68848, 2, 15.515625),\n",
       "  (70663, 3, 15.4765625),\n",
       "  (62832, 4, 15.3359375),\n",
       "  (62826, 5, 15.3046875)],\n",
       " 63579: [(68566, 1, 27.8125),\n",
       "  (69189, 2, 21.9375),\n",
       "  (67464, 3, 21.390625),\n",
       "  (69712, 4, 17.703125),\n",
       "  (62723, 5, 17.09375)],\n",
       " 65798: [(69160, 1, 27.453125),\n",
       "  (67065, 2, 23.734375),\n",
       "  (63948, 3, 22.796875),\n",
       "  (66292, 4, 21.484375),\n",
       "  (68606, 5, 19.40625)],\n",
       " 78081: [(69291, 1, 26.0),\n",
       "  (69751, 2, 23.25),\n",
       "  (70453, 3, 22.40625),\n",
       "  (60929, 4, 22.3125),\n",
       "  (66209, 5, 22.296875)],\n",
       " 69473: [(67988, 1, 22.71875),\n",
       "  (67989, 2, 19.34375),\n",
       "  (67991, 3, 18.296875),\n",
       "  (67983, 4, 18.03125),\n",
       "  (59686, 5, 17.96875)],\n",
       " 132108: [(65909, 1, 13.734375),\n",
       "  (66607, 2, 13.6640625),\n",
       "  (65910, 3, 13.53125),\n",
       "  (65911, 4, 13.1953125),\n",
       "  (66608, 5, 12.9375)],\n",
       " 131931: [(66133, 1, 26.390625),\n",
       "  (60462, 2, 22.265625),\n",
       "  (64028, 3, 22.171875),\n",
       "  (64032, 4, 20.78125),\n",
       "  (62858, 5, 19.9375)],\n",
       " 118106: [(63165, 1, 27.015625),\n",
       "  (65245, 2, 26.328125),\n",
       "  (70645, 3, 19.34375),\n",
       "  (66480, 4, 19.203125),\n",
       "  (62641, 5, 19.1875)],\n",
       " 41288: [(70337, 1, 26.140625),\n",
       "  (70341, 2, 21.9375),\n",
       "  (70338, 3, 18.921875),\n",
       "  (67939, 4, 18.28125),\n",
       "  (65974, 5, 17.859375)],\n",
       " 72679: [(53883, 1, 20.59375),\n",
       "  (53881, 2, 19.375),\n",
       "  (53789, 3, 13.59375),\n",
       "  (53884, 4, 13.4296875),\n",
       "  (53882, 5, 12.796875)],\n",
       " 71680: [(54416, 1, 22.875),\n",
       "  (54415, 2, 19.109375),\n",
       "  (54543, 3, 18.5625),\n",
       "  (55083, 4, 18.171875),\n",
       "  (54745, 5, 17.5)],\n",
       " 2359: [(54928, 1, 18.75),\n",
       "  (54421, 2, 14.375),\n",
       "  (55048, 3, 14.0234375),\n",
       "  (54929, 4, 13.7421875),\n",
       "  (53635, 5, 13.2734375)],\n",
       " 94934: [(54530, 1, 27.125),\n",
       "  (54613, 2, 24.578125),\n",
       "  (54561, 3, 24.015625),\n",
       "  (54614, 4, 23.46875),\n",
       "  (54651, 5, 19.765625)],\n",
       " 134515: [(54924, 1, 25.109375),\n",
       "  (54789, 2, 21.875),\n",
       "  (55073, 3, 20.34375),\n",
       "  (54771, 4, 18.9375),\n",
       "  (54051, 5, 18.265625)],\n",
       " 18992: [(54952, 1, 24.546875),\n",
       "  (55005, 2, 21.34375),\n",
       "  (54604, 3, 20.1875),\n",
       "  (55006, 4, 20.078125),\n",
       "  (55069, 5, 19.046875)],\n",
       " 106142: [(54648, 1, 25.625),\n",
       "  (54649, 2, 24.625),\n",
       "  (54714, 3, 19.953125),\n",
       "  (54650, 4, 18.515625),\n",
       "  (54956, 5, 15.875)],\n",
       " 63219: [(53760, 1, 12.4140625),\n",
       "  (53775, 2, 12.3984375),\n",
       "  (53975, 3, 12.3984375),\n",
       "  (53774, 4, 12.3359375),\n",
       "  (53874, 5, 12.3203125)],\n",
       " 17569: [(54892, 1, 27.515625),\n",
       "  (53920, 2, 22.640625),\n",
       "  (54285, 3, 21.859375),\n",
       "  (54190, 4, 21.40625),\n",
       "  (54535, 5, 20.921875)],\n",
       " 2446: [(53883, 1, 20.4375),\n",
       "  (53881, 2, 19.6875),\n",
       "  (53789, 3, 11.9453125),\n",
       "  (53793, 4, 11.90625),\n",
       "  (54233, 5, 11.1953125)],\n",
       " 12846: [(57303, 1, 22.078125),\n",
       "  (57234, 2, 18.1875),\n",
       "  (57354, 3, 17.90625),\n",
       "  (57282, 4, 17.890625),\n",
       "  (57333, 5, 17.796875)],\n",
       " 27223: [(57244, 1, 22.328125),\n",
       "  (57223, 2, 19.546875),\n",
       "  (57258, 3, 16.90625),\n",
       "  (57226, 4, 16.46875),\n",
       "  (57281, 5, 15.640625)],\n",
       " 71792: [(57280, 1, 26.4375),\n",
       "  (57233, 2, 18.546875),\n",
       "  (57178, 3, 17.6875),\n",
       "  (57198, 4, 16.59375),\n",
       "  (57165, 5, 16.40625)],\n",
       " 68362: [(57352, 1, 27.15625),\n",
       "  (57354, 2, 20.625),\n",
       "  (57333, 3, 20.484375),\n",
       "  (57220, 4, 20.46875),\n",
       "  (57353, 5, 20.28125)],\n",
       " 43786: [(57303, 1, 27.640625),\n",
       "  (57333, 2, 22.484375),\n",
       "  (57282, 3, 22.375),\n",
       "  (57234, 4, 22.28125),\n",
       "  (57354, 5, 22.234375)],\n",
       " 17736: [(56915, 1, 26.515625),\n",
       "  (56944, 2, 22.78125),\n",
       "  (56936, 3, 22.03125),\n",
       "  (56922, 4, 21.984375),\n",
       "  (56920, 5, 18.40625)],\n",
       " 130816: [(57360, 1, 25.109375),\n",
       "  (56981, 2, 20.171875),\n",
       "  (56980, 3, 14.6015625),\n",
       "  (56979, 4, 11.3125),\n",
       "  (56982, 5, 10.609375)],\n",
       " 29293: [(57334, 1, 26.53125),\n",
       "  (57335, 2, 22.96875),\n",
       "  (57336, 3, 21.796875),\n",
       "  (57359, 4, 21.21875),\n",
       "  (57234, 5, 19.0625)],\n",
       " 124194: [(56928, 1, 28.453125),\n",
       "  (56921, 2, 22.9375),\n",
       "  (56942, 3, 21.96875),\n",
       "  (56927, 4, 20.640625),\n",
       "  (56926, 5, 19.6875)],\n",
       " 20792: [(57249, 1, 26.828125),\n",
       "  (57268, 2, 19.34375),\n",
       "  (57256, 3, 18.953125),\n",
       "  (57267, 4, 18.421875),\n",
       "  (57300, 5, 17.96875)],\n",
       " 42402: [(59525, 1, 26.6875),\n",
       "  (59546, 2, 21.875),\n",
       "  (59554, 3, 20.515625),\n",
       "  (59243, 4, 19.3125),\n",
       "  (59440, 5, 17.234375)],\n",
       " 36077: [(58677, 1, 22.375),\n",
       "  (59445, 2, 17.21875),\n",
       "  (59296, 3, 14.875),\n",
       "  (59431, 4, 14.703125),\n",
       "  (58150, 5, 14.5703125)],\n",
       " 91013: [(59505, 1, 23.3125),\n",
       "  (59205, 2, 19.125),\n",
       "  (58243, 3, 17.421875),\n",
       "  (59361, 4, 16.734375),\n",
       "  (59303, 5, 16.53125)],\n",
       " 31447: [(58533, 1, 24.875),\n",
       "  (58532, 2, 22.125),\n",
       "  (59536, 3, 19.09375),\n",
       "  (59535, 4, 18.0625),\n",
       "  (58821, 5, 16.0625)],\n",
       " 31993: [(59158, 1, 28.765625),\n",
       "  (59157, 2, 23.9375),\n",
       "  (59193, 3, 18.984375),\n",
       "  (59025, 4, 18.0),\n",
       "  (59057, 5, 18.0)],\n",
       " 43626: [(59493, 1, 25.34375),\n",
       "  (59443, 2, 22.75),\n",
       "  (59503, 3, 21.859375),\n",
       "  (59421, 4, 21.625),\n",
       "  (59419, 5, 20.921875)],\n",
       " 76909: [(59536, 1, 15.4375),\n",
       "  (58953, 2, 15.3359375),\n",
       "  (58986, 3, 14.53125),\n",
       "  (58859, 4, 13.8125),\n",
       "  (59148, 5, 13.7734375)],\n",
       " 105827: [(59541, 1, 21.65625),\n",
       "  (59542, 2, 20.71875),\n",
       "  (59344, 3, 17.421875),\n",
       "  (59064, 4, 16.28125),\n",
       "  (59248, 5, 16.1875)],\n",
       " 60952: [(59557, 1, 26.59375),\n",
       "  (59242, 2, 21.0625),\n",
       "  (59243, 3, 19.84375),\n",
       "  (59560, 4, 18.890625),\n",
       "  (59297, 5, 18.671875)],\n",
       " 110132: [(59413, 1, 19.75),\n",
       "  (59406, 2, 15.1015625),\n",
       "  (58518, 3, 14.71875),\n",
       "  (59553, 4, 14.6484375),\n",
       "  (59407, 5, 14.5859375)]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a99ac6d2deb03d0b7ced3594556c328848678d7cea021ae1b9990e15d3ad5c49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
